{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea0dc51-9574-43a5-9926-57256fa1b887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code_cell.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code_cell.py\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "#For e-autoMFIS, we import all of them.\n",
    "from eautoMFIS_V2 import autoMFIS\n",
    "from fuzzyfication import Fuzzification\n",
    "from preprocessing import Preprocess\n",
    "from utils import *\n",
    "\n",
    "from pymoo.core.problem import  ElementwiseProblem\n",
    "from pymoo.core.variable import Real, Integer, Choice\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2, RankAndCrowdingSurvival\n",
    "from pymoo.core.mixed import MixedVariableMating, MixedVariableGA, MixedVariableSampling, MixedVariableDuplicateElimination\n",
    "from pymoo.optimize import minimize\n",
    "import sys\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "data = pd.read_csv('AirQualityUCI.csv',sep=';',decimal='.')\n",
    "\n",
    "data.dropna(thresh=1, inplace=True)\n",
    "data.drop(labels=['Unnamed: 15', 'Unnamed: 16'],axis=1,inplace=True)\n",
    "\n",
    "data.fillna(method='bfill',inplace=True)\n",
    "\n",
    "def convert_object_to_float(data,datanames):\n",
    "    for name in datanames:\n",
    "        dname = data[name].values.astype('str')\n",
    "        dname = [new_value.replace(',','.') for new_value in dname]\n",
    "        data[name] = dname\n",
    "        data[name] = data[name].astype(float)\n",
    "    return data\n",
    "\n",
    "inames = ['CO(GT)', 'C6H6(GT)', 'T', 'RH', 'AH']\n",
    "\n",
    "data = convert_object_to_float(data,inames)\n",
    "\n",
    "data = data.select_dtypes(include=['float'])\n",
    "   \n",
    "data = data.where(data != -200)\n",
    "\n",
    "# Preenchimento de dados faltantes\n",
    "data.fillna(method='bfill',inplace=True)\n",
    "\n",
    "# Preenchimento de dados faltantes\n",
    "data.fillna(method='bfill',inplace=True)\n",
    "\n",
    "data.drop(labels=['NMHC(GT)', 'PT08.S1(CO)','PT08.S2(NMHC)','PT08.S3(NOx)','PT08.S4(NO2)','PT08.S5(O3)'],axis=1,inplace=True)\n",
    "\n",
    "data = data[9000:-24]\n",
    "data = data[['NO2(GT)', 'C6H6(GT)', 'NOx(GT)', 'T', 'CO(GT)']]\n",
    "dataset = data.values\n",
    "\n",
    "lag = 24\n",
    "h_teste = 24\n",
    "h_validation = 24\n",
    "h_train = dataset.shape[0] - h_teste - h_validation\n",
    "\n",
    "a = dataset.shape[0]\n",
    "all_data = dataset[lag:,:]\n",
    "training_data = dataset[lag:lag+h_train,:]\n",
    "test_data = dataset[a - h_teste:a,:]\n",
    "\n",
    "n_predictors = 60\n",
    "num_input = 12\n",
    "lag_notused = np.array([[4,5],[4,5],[4],[4,5]])\n",
    "not_used_lag = False\n",
    "\n",
    "#Actually, lag stands for all inputs for each serie. Example, lag = 2 uses s(t) and s(t-1) to predict s(t+1)\n",
    "diff_series = False\n",
    "detrend_series = False\n",
    "\n",
    "num_series = training_data.shape[1]  #Numero de series do problema, extraído dos dados\n",
    "\n",
    "# max_rulesize = 5 #Max numbers of premises rules.\n",
    "# min_activation = 0.58 #Minimum activation\n",
    "\n",
    "form_method = 'nmean'\n",
    "split_method = 'FCD'\n",
    "solve_method = 'mqr'\n",
    "#####Definicao de funcoes######\n",
    "#detrend_method = ''\n",
    "#bin_method = ''\n",
    "\n",
    "fuzzy_method = 'mfdef_cluster'\n",
    "# num_groups = 7\n",
    "\n",
    "defuzz_method = 'height'\n",
    "\n",
    "ensemble_rules = None\n",
    "\n",
    "total_number = training_data.shape[1]*lag\n",
    "\n",
    "\n",
    "filepath = 'results V2'\n",
    "\n",
    "target_position = 4\n",
    "\n",
    "def fuzzy_external(fuzzy_method, num_series, training_set, num_groups, yp, yt, yp_lagged, lag):\n",
    "    ###############Fuzzificacao\n",
    "\n",
    "    Fuzzyfy = Fuzzification(fuzzy_method)\n",
    "\n",
    "    #Lembrete: \n",
    "    #axis 0 - Registros da série\n",
    "    #axis 1 - Valor de pertinência ao conjunto Fuzzy\n",
    "    #axis 2 - Numero de séries\n",
    "\n",
    "    first_time = True\n",
    "    # print(f'Serie fuzzification')\n",
    "    for n in range(num_series):\n",
    "        _, mf_params = Fuzzyfy.fuzzify(training_set[:,n],np.array([]),num_groups=num_groups)\n",
    "        mX, _ = Fuzzyfy.fuzzify(yp[:,n],mf_params,num_groups=num_groups)\n",
    "        mY, _ = Fuzzyfy.fuzzify(yt[:,n],mf_params,num_groups=num_groups)\n",
    "        if first_time:\n",
    "            mX_ = np.ndarray([mX.shape[0],mX.shape[1], num_series])\n",
    "            mY_ = np.ndarray([mY.shape[0],mY.shape[1], num_series])\n",
    "            mf_params_ = np.ndarray([mf_params.shape[0],num_series])\n",
    "            first_time = False\n",
    "        mX_[:,:,n] = mX\n",
    "        mY_[:,:,n] = mY\n",
    "        mf_params_[:,n] = mf_params.ravel()\n",
    "        #print(mf_params)\n",
    "        #print(mX.shape)\n",
    "\n",
    "    # print('Creating for lag values')\n",
    "    mX_lagged_ = np.ndarray([mX_.shape[0],mX_.shape[1],yp_lagged.shape[1]])\n",
    "    for i in range(num_series):\n",
    "        # print(f'Serie {i}')\n",
    "        mf_params = mf_params_[:,i]\n",
    "        for j in range(lag):\n",
    "            mX, _ = Fuzzyfy.fuzzify(yp_lagged[:,i*lag+j],mf_params,num_groups=num_groups)\n",
    "            mX_lagged_[:,:,i*lag+j] = mX\n",
    "            #print(i*lag+j)\n",
    "\n",
    "\n",
    "    #mX_lagged_[:,:,not_select_subsample] = 0\n",
    "\n",
    "    #print(mX_lagged_[:,:,not_select_subsample])\n",
    "    ############## Formulacao\n",
    "    if not_used_lag:\n",
    "        new_mX, lags_used = remove_lags(mX_lagged_,lag_notused,num_series,lag)\n",
    "    else:\n",
    "        new_mX = mX_lagged_\n",
    "\n",
    "    return Fuzzyfy, mX_, mY_, mf_params_, mX_lagged_\n",
    "\n",
    "class Air_Quality_Problem(ElementwiseProblem):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "            \n",
    "            vars = {\n",
    "                # \"lag\": Integer(bounds=(16,24)),\n",
    "                # \"n_inputs\": Integer(bounds=(10,20)),\n",
    "                \"max_rulesize\": Integer(bounds=(5, 7)),\n",
    "                \"min_activation\": Real(bounds=(0.5, 0.655)),\n",
    "                # \"form_method\": Choice(options=[\"nmean\", \"freq\", \"mean\"]),\n",
    "                # \"split_method\": Choice(options=[\"FCD\", \"voting\"]),\n",
    "                # \"solve_method\": Choice(options=['mqr', 'None']),\n",
    "                # \"fuzzy_method\": Choice(options=['mfdef_cluster', 'mfdef_triangle',  'mfdef_tukkey']),\n",
    "                \"num_groups\": Choice(options=[3, 5, 7, 9]),\n",
    "                # \"defuzz_method\": Choice(options=[\"height\", \"cog\", \"mom\" ])\n",
    "            }\n",
    "            super().__init__(vars=vars, n_obj=3)\n",
    "\n",
    "\n",
    "    def _evaluate(self, x,  out, *args, **kwargs):\n",
    "        # cont = 0\n",
    "        # if cont == 0:\n",
    "        #     x = {'max_rulesize': 6, 'min_activation': 0.5709066532065377, 'num_groups': 9}\n",
    "        #     cont += 1\n",
    "        \n",
    "        print(x)\n",
    "        # lag = x[\"lag\"]\n",
    "        # num_input = x[\"n_inputs\"]\n",
    "        max_rulesize = x[\"max_rulesize\"] #Max numbers of premises rules.\n",
    "        min_activation = x[\"min_activation\"] #Minimum activation\n",
    "        # form_method = x[\"form_method\"]\n",
    "        # split_method = x[\"split_method\"]\n",
    "        # solve_method = x[\"solve_method\"]\n",
    "        # fuzzy_method = x[\"fuzzy_method\"]\n",
    "        num_groups = x[\"num_groups\"]\n",
    "        # defuzz_method = x[\"defuzz_method\"]\n",
    "\n",
    "        ensemble_rules = None\n",
    "\n",
    "        # total_number = data_.shape[1]*lag\n",
    "\n",
    "        filepath = 'results V2'\n",
    "        \n",
    "        target_position = 4\n",
    "\n",
    "        preprocess_data = Preprocess(deepcopy(training_data), lag, h_prev=h_validation,num_series=num_series, target_position = target_position)\n",
    "\n",
    "        training_val_set, test_set = preprocess_data.split_data()\n",
    "        training_set, val_set = preprocess_data.split_data(data=training_val_set)\n",
    "        correlation_array = preprocess_data.spearman_corr_weights(in_sample=training_set)\n",
    "        autocorrelation_matrix = preprocess_data.linear_acf_weights(in_sample=training_set)\n",
    "\n",
    "        yt, yp, yp_lagged = preprocess_data.delay_input(in_sample = training_set, lag = lag)\n",
    "        all_yt, all_yp, all_lagged = preprocess_data.delay_input(in_sample = dataset, lag = lag)\n",
    "\n",
    "        min_error = 400.0\n",
    "\n",
    "        bres = min_error\n",
    "\n",
    "        initial_values = all_lagged[yp_lagged.shape[0],:].reshape(1,-1)\n",
    "        in_sample = deepcopy(training_set)\n",
    "        out_sample = deepcopy(val_set)\n",
    "\n",
    "        #Concatenate rules\n",
    "        for i in range(n_predictors):\n",
    "            try:\n",
    "                _, _, yp_lagged_ = preprocess_data.generate_subsamples(correlation_array=deepcopy(correlation_array),\n",
    "                                                                        autocorrelation_matrix=autocorrelation_matrix,\n",
    "                                                                        num_inputs=num_input, \n",
    "                                                                        in_sample=in_sample, \n",
    "                                                                        yt = yt, \n",
    "                                                                        yp = yp, \n",
    "                                                                        yp_lagged = deepcopy(yp_lagged))\n",
    "                print('='*30)\n",
    "                \n",
    "                Fuzzyfy, mX_, mY_, mf_params_, mX_lagged_ = fuzzy_external(fuzzy_method, \n",
    "                                                                            num_series, \n",
    "                                                                            training_set, \n",
    "                                                                            num_groups, \n",
    "                                                                            yp, \n",
    "                                                                            yt,\n",
    "                                                                            deepcopy(yp_lagged_), \n",
    "                                                                            lag)\n",
    "                print(f'mX_: {sys.getsizeof(mX_)}')\n",
    "                print(f'mY_: {sys.getsizeof(mY_)}')\n",
    "                print(f'mf_params_: {sys.getsizeof(mf_params_)}')\n",
    "                print(f'mX_lagged_: {sys.getsizeof(mX_lagged_)}')\n",
    "                \n",
    "                model = autoMFIS(diff_series=diff_series,\n",
    "                                detrend_series=detrend_series, \n",
    "                                fuzzy_method=fuzzy_method,\n",
    "                                solve_method=solve_method,\n",
    "                                defuzz_method=defuzz_method, \n",
    "                                num_groups = num_groups, \n",
    "                                inputs = num_input, \n",
    "                                h_prev = out_sample.shape[0],\n",
    "                                num_series = num_series, \n",
    "                                max_rulesize = max_rulesize,\n",
    "                                min_activation = min_activation, \n",
    "                                lag = lag, \n",
    "                                target_position = 4, \n",
    "                                hide_values = False, \n",
    "                                form_method = form_method, \n",
    "                                split_method = split_method, \n",
    "                                show=True)\n",
    "                \n",
    "                model.set_fuzzification(Fuzzyfy, mf_params_, mX_, mY_, deepcopy(mX_lagged_))\n",
    "\n",
    "                t_mX_lagged, complete_rules, prem_terms, rules, agg_training, wd_ = model.train(data = dataset, \n",
    "                                                                                                correlation_array = correlation_array, \n",
    "                                                                                                autocorrelation_matrix = autocorrelation_matrix,\n",
    "                                                                                                in_sample=in_sample, \n",
    "                                                                                                out_sample=out_sample, \n",
    "                                                                                                lag_notused=[],\n",
    "                                                                                                debug=False)\n",
    "                \n",
    "                print(f't_mX_lagged: {sys.getsizeof(t_mX_lagged)}')\n",
    "                print(f'agg_training: {sys.getsizeof(agg_training)}')\n",
    "\n",
    "                predicted_values = np.zeros(test_set.shape)\n",
    "                \n",
    "                yt_totest, errors = model.predict(initial_values, \n",
    "                                                    data=dataset, \n",
    "                                                    in_sample = yt, \n",
    "                                                    out_sample=val_set,\n",
    "                                                    agg_training=agg_training,\n",
    "                                                    h_prev=h_teste,\n",
    "                                                    n_attempt=f'p_subsample_{i}',\n",
    "                                                    wd_=wd_,\n",
    "                                                    ensemble_antecedents=rules,\n",
    "                                                    ensemble_rules=complete_rules,\n",
    "                                                    filepath=filepath,\n",
    "                                                    lim=min_error, \n",
    "                                                    fig_axis=[4,2],\n",
    "                                                    ndata=data.columns,\n",
    "                                                    show=False,\n",
    "                                                    plot_image = True)\n",
    "\n",
    "                real_yt = deepcopy(yt_totest)\n",
    "\n",
    "                # print(errors)\n",
    "                res = errors[1,4]\n",
    "                # print(res)\n",
    "                if res < bres:\n",
    "                    bres = res\n",
    "                    if ensemble_rules is None:\n",
    "                        ensemble_rules = complete_rules\n",
    "                        ensemble_prem_terms = prem_terms\n",
    "                        ensemble_antecedents = rules\n",
    "                        # print(ensemble_rules.shape)\n",
    "                    else:\n",
    "                        ensemble_rules = np.concatenate((ensemble_rules, complete_rules))\n",
    "                        \n",
    "                        ensemble_prem_terms = np.concatenate((ensemble_prem_terms,prem_terms))\n",
    "                        ensemble_antecedents = np.concatenate((ensemble_antecedents,rules))\n",
    "                        # print(ensemble_rules.shape)\n",
    "                        #print(ensemble_prem_terms.shape)\n",
    "                    #print(ensemble_rules[:,0])\n",
    "                elif ensemble_rules is None and i == n_predictors - 1:\n",
    "                    ensemble_rules = complete_rules\n",
    "                    ensemble_prem_terms = prem_terms\n",
    "                    ensemble_antecedents = rules\n",
    "                    # print('No rules match criteria. Using rules to fill the gap')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                if 'shapes' in str(e) and i != 59:\n",
    "                    del  yp_lagged_, Fuzzyfy, mX_, mY_, mf_params_, mX_lagged_, model \n",
    "                if 'values to unpack' in str(e) and i != 59:\n",
    "                    del  yp_lagged_, Fuzzyfy, mX_, mY_, mf_params_, mX_lagged_\n",
    "                if 'memory' in str(e) and i != 59:\n",
    "                    del  yp_lagged_, Fuzzyfy, mX_, mY_, mf_params_, mX_lagged_, t_mX_lagged, complete_rules, prem_terms, rules, agg_training, wd_\n",
    "                pass\n",
    "            \n",
    "        print(f'ensemble_rules: {sys.getsizeof(ensemble_rules)}')\n",
    "        print(f'ensemble_prem_terms: {sys.getsizeof(ensemble_prem_terms)}')\n",
    "        print(f'ensemble_antecedents: {sys.getsizeof(ensemble_antecedents)}')\n",
    "        print('='*30)\n",
    "        \n",
    "        cnt = 0\n",
    "        list_remove = []\n",
    "\n",
    "        dict_val = {}\n",
    "\n",
    "        for i in range(ensemble_prem_terms.shape[0]):\n",
    "            except_one = np.copy(ensemble_prem_terms)\n",
    "            v = except_one[i,:]\n",
    "            idx = np.argwhere(v > 0.5).ravel()\n",
    "            v = v[idx]\n",
    "            rest = np.delete(except_one, i, axis=0)\n",
    "            rest = rest[:,idx]\n",
    "            cpare = np.tile(v,(rest.shape[0],1))\n",
    "            m = np.minimum(rest,cpare) \n",
    "            M = np.maximum(rest,cpare) + 10e-15\n",
    "            res = m/M\n",
    "            mean = np.mean(res,axis=1)\n",
    "            #plt.figure()\n",
    "            #plt.hist(mean)\n",
    "            \n",
    "            vv = np.argwhere(mean > 0.6).ravel()\n",
    "\n",
    "            if vv.shape[0] > 0:    \n",
    "                vv[vv > i] += 1\n",
    "                vv2 = np.append(vv,np.array([i]))\n",
    "\n",
    "                eval_v = ensemble_prem_terms[vv2][:,idx]\n",
    "\n",
    "                t = np.mean(eval_v,axis=1)\n",
    "\n",
    "                keep_val = vv2[np.argmax(t)]\n",
    "                vmax = np.max(t)\n",
    "                if keep_val not in list_remove:\n",
    "                    dict_val[keep_val] = 1\n",
    "                    list_remove.append(keep_val)\n",
    "                else:\n",
    "                    dict_val[keep_val] = dict_val[keep_val] + 1\n",
    "\n",
    "                cnt += np.argwhere(mean > 0.6).shape[0]\n",
    "\n",
    "        filtered_rules = deepcopy(ensemble_rules[list_remove,:])\n",
    "        filtered_prems = deepcopy(ensemble_prem_terms[list_remove,:])\n",
    "        filtered_antecedents = deepcopy(ensemble_antecedents[list_remove,:])\n",
    "        \n",
    "        print(f'filtered_rules: {sys.getsizeof(filtered_rules)}')\n",
    "        print(f'filtered_prems: {sys.getsizeof(filtered_prems)}')\n",
    "        print(f'filtered_antecedents: {sys.getsizeof(filtered_antecedents)}')\n",
    "\n",
    "        model.set_fuzzification(Fuzzyfy, mf_params_, mX_, mY_, mX_lagged_)\n",
    "        filtered_wd_, filtered_agg_training = model.reweight_mf(mY_,filtered_rules,filtered_prems)\n",
    "        print(f'filtered_wd_: {sys.getsizeof(filtered_wd_)}')\n",
    "        print(f'filtered_agg_training: {sys.getsizeof(filtered_agg_training)}')\n",
    "\n",
    "        \n",
    "        try:\n",
    "            _, filtered_errors = model.predict(initial_values, \n",
    "                                               data=dataset,\n",
    "                                               out_sample=test_set, \n",
    "                                               agg_training=filtered_agg_training,\n",
    "                                               h_prev=h_teste,\n",
    "                                               n_attempt='filtered_model',\n",
    "                                               wd_=filtered_wd_,\n",
    "                                               ensemble_antecedents=filtered_antecedents,\n",
    "                                               ensemble_rules=filtered_rules, \n",
    "                                               filepath=filepath, lim=min_error,\n",
    "                                               fig_axis=[4,2],\n",
    "                                               ndata=data.columns,\n",
    "                                               show=False,\n",
    "                                               plot_image = True) \n",
    "\n",
    "            out[\"F\"] = [filtered_errors[1, target_position], filtered_rules.shape[0], filtered_rules.shape[1]]\n",
    "            print(out)\n",
    "            print(f'out: {sys.getsizeof(out)}')\n",
    "\n",
    "            del training_val_set, training_set, val_set, test_set, correlation_array, autocorrelation_matrix, yt, yp, yp_lagged, all_yt, all_yp, all_lagged \n",
    "            del min_error, initial_values, in_sample, out_sample, yp_lagged_, Fuzzyfy, mX_, mY_, mf_params_, mX_lagged_, model, t_mX_lagged, complete_rules\n",
    "            del prem_terms, rules, agg_training, wd_, predicted_values, yt_totest, errors, cnt, list_remove, dict_val,filtered_rules, filtered_prems \n",
    "            del filtered_antecedents, filtered_wd_, filtered_agg_training, filtered_errors\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            out[\"F\"] = [np.inf, np.inf, np.inf]\n",
    "            del training_val_set, training_set, val_set, test_set, correlation_array, autocorrelation_matrix, yt, yp, yp_lagged, all_yt, all_yp, all_lagged \n",
    "            del min_error, initial_values, in_sample, out_sample, yp_lagged_, Fuzzyfy, mX_, mY_, mf_params_, mX_lagged_, model, t_mX_lagged, complete_rules\n",
    "            del prem_terms, rules, agg_training, wd_, predicted_values, yt_totest, errors, cnt, list_remove, dict_val,filtered_rules, filtered_prems \n",
    "            del filtered_antecedents, filtered_wd_, filtered_agg_training\n",
    "            pass\n",
    "        \n",
    "algorithm = NSGA2(pop_size=10,\n",
    "                  sampling=MixedVariableSampling(),\n",
    "                  mating=MixedVariableMating(eliminate_duplicates=MixedVariableDuplicateElimination()),\n",
    "                  eliminate_duplicates=MixedVariableDuplicateElimination(),\n",
    "                  )\n",
    "\n",
    "problem = Air_Quality_Problem()\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               ('n_gen', 10),\n",
    "               seed=1,\n",
    "               verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3099603d-b943-469d-9bbf-ef0b4480402f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%mprun` not found.\n"
     ]
    }
   ],
   "source": [
    "%mprun -f code_cell.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc6d97-59a3-4baa-b980-5bd9fa544106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
