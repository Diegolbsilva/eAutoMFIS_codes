{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "from copy import deepcopy\n",
    "from preprocessing import Preprocess\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('results.traffic','rb') as f:\n",
    "    predicted_values = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from utils import *\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "\n",
    "#For e-autoMFIS, we import all of them.\n",
    "from eautoMFIS_V2 import autoMFIS\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from reweight import Reweight\n",
    "from fuzzyfication import Fuzzification\n",
    "from defuzzification import Defuzzification\n",
    "import matplotlib.pyplot as plt\n",
    "from predict import predict, predict_pattern\n",
    "\n",
    "\n",
    "\n",
    "def convert_object_to_float(data,datanames):\n",
    "    \n",
    "    for name in datanames:\n",
    "        dname = data[name].values.astype('str')\n",
    "        dname = [new_value.replace(',','.') for new_value in dname]\n",
    "        data[name] = dname\n",
    "        data[name] = data[name].astype(float)\n",
    "    return data\n",
    "\n",
    "##Assertion for ensemble rules\n",
    "#Somehow, when appending rules, ensemble_rules[:,1] has a erroneous form. This part seems to normalize it.\n",
    "\n",
    "#This module correct this error. Also, we are going to use some assertion to check if rules contains the same antecedents.\n",
    "def correct_bug(ensemble_rules,max_rulesize=0):\n",
    "    correct_rule = []\n",
    "    d_stacked_rules = []\n",
    "    new_ensemble_rules = np.zeros(shape=ensemble_rules.shape, dtype=object)\n",
    "\n",
    "\n",
    "    for  n_times in range(ensemble_rules.shape[1]):\n",
    "        t_rules = ensemble_rules[:,n_times]\n",
    "        correct_rule = []\n",
    "        d_stacked_rules = []\n",
    "        k = 0\n",
    "        for rule in t_rules:\n",
    "            #print(rule)\n",
    "            #print(len(rule))\n",
    "            #Check if there's a rule bigger than max_rulesize + 1 (#antecedents + #consequent)\n",
    "            if len(rule) > max_rulesize + 1:\n",
    "                #print(rule)\n",
    "                for i in rule:\n",
    "                    #k += 1\n",
    "                    if isinstance(i,tuple):\n",
    "                        #print(i)\n",
    "                        correct_rule.append(i)\n",
    "                    else:\n",
    "                        if len(correct_rule) == 0:\n",
    "                            #print(i)\n",
    "                            pass\n",
    "                            #d_stacked_rules.append(i)\n",
    "                        else:\n",
    "                            #print(correct_rule)\n",
    "                            new_ensemble_rules[k,n_times] = correct_rule\n",
    "                            k += 1\n",
    "                            #d_stacked_rules.append(correct_rule)\n",
    "                            correct_rule = []\n",
    "                            #d_stacked_rules.append(i)\n",
    "            else:\n",
    "                new_ensemble_rules[k,n_times] = rule\n",
    "                k += 1\n",
    "                #d_stacked_rules.append(rule)\n",
    "            \n",
    "        #new_ensemble_rules[:,i] = np.array(d_stacked_rules)\n",
    "\n",
    "    return new_ensemble_rules\n",
    "\n",
    "def remove_duplicates(new_ensemble_rules,ensemble_prem_terms, ensemble_antecedents):\n",
    "    t_rules = deepcopy(new_ensemble_rules[:,0])\n",
    "    no_duplicated_ensemble = np.zeros(new_ensemble_rules.shape,dtype=object)\n",
    "    no_duplicated_prem_terms = np.zeros(ensemble_prem_terms.shape)\n",
    "    no_duplicated_antecedents = np.zeros(ensemble_antecedents.shape,dtype=object)\n",
    "    new_t_rules = None\n",
    "\n",
    "    k = 0\n",
    "    j = 0\n",
    "    for rule in t_rules:\n",
    "        if new_t_rules is None:\n",
    "            new_t_rules = [rule]\n",
    "            no_duplicated_ensemble[k,:] = deepcopy(new_ensemble_rules[j,:])\n",
    "            no_duplicated_prem_terms[k,:] = deepcopy(ensemble_prem_terms[j,:])\n",
    "            no_duplicated_antecedents[k,:] = deepcopy(ensemble_antecedents[j,:])\n",
    "            k += 1\n",
    "\n",
    "        elif not check_duplicate_rules(rule,new_t_rules):\n",
    "            new_t_rules.append(rule)\n",
    "            no_duplicated_ensemble[k,:] = deepcopy(new_ensemble_rules[j,:])\n",
    "            no_duplicated_prem_terms[k,:] = deepcopy(ensemble_prem_terms[j,:])\n",
    "            no_duplicated_antecedents[k,:] = deepcopy(ensemble_antecedents[j,:])\n",
    "            k += 1\n",
    "        j += 1\n",
    "\n",
    "    new_rules = deepcopy(no_duplicated_ensemble[:k,:])\n",
    "    new_prem_terms = deepcopy(no_duplicated_prem_terms[:k,:])\n",
    "    new_antecedents = deepcopy(no_duplicated_antecedents[:k,:])\n",
    "\n",
    "    return new_rules, new_prem_terms, new_antecedents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rule Object structure\n",
    "class rule_object():\n",
    "    def __init__(self,complete_rules,prem_terms,rules,wd_,index):\n",
    "        self.complete_rules = complete_rules\n",
    "        self.prem_terms = prem_terms\n",
    "        self.rules = rules\n",
    "        self.index = index\n",
    "        self.wd_ = wd_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(initial_values, lags_used = [], ndata=[''], data=[], in_sample=[], out_sample=[], agg_training=None,h_prev=0,n_attempt=0,wd_=[],ensemble_antecedents=[],ensemble_rules=[],not_used_lag = False, filepath='',lim=0, fig_axis=[3,2]):\n",
    "    '''\n",
    "    Module to time series forecasting. It uses multi-stepping in order to evaluate the model.\n",
    "    INPUTS:\n",
    "    \\n - Fuzzyfy: Object containing informations about Fuzzification.\n",
    "    \\n - lags_used: If not_used_lags is true, masks series that isn't in list.\n",
    "    \\n - num_groups: Number of fuzzy sets.\n",
    "    \\n - ndata: name of data (e.g. column header)\n",
    "    \\n - data: data of the problem\n",
    "    \\n - in_sample: in_sample set of data\n",
    "    \\n - out_sample: out_sample set of data\n",
    "    \\n - lag:\n",
    "    \\n - mf_params: Membership function parameters\n",
    "    \\n - agg_training: Aggregation terms in training set. Used to simplify deffuzification of training set.\n",
    "    \\n - yp_lagged\n",
    "    \\n - h_prev:\n",
    "    #TODO - Continue this list\n",
    "\n",
    "    VARIABLES:\n",
    "    \\n - y_predict_: Training set prediction\n",
    "    \\n - yp_totest: Input pattern to evaluate prediction\n",
    "    \\n - yt_totest: Output data, for each horizon and serie.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    print(f'Shape of ensemble rules is {ensemble_rules.shape}')\n",
    "\n",
    "\n",
    "    defuzz = Defuzzification(model.mf_params,num_series)\n",
    "    if agg_training is not None:\n",
    "        y_predict_ = defuzz.run(defuzz_method,agg_training)\n",
    "\n",
    "    yp_totest = initial_values\n",
    "    yt_totest = np.zeros((h_prev,num_series))\n",
    "\n",
    "    #Prediction - Multi-step\n",
    "    for h_p in range(h_prev):\n",
    "\n",
    "        #Check activated terms.\n",
    "        mX_values_in = np.zeros((1,model.mf_params.shape[0],yp_totest.shape[1]))\n",
    "\n",
    "        antecedents_activated = []\n",
    "        it = 0\n",
    "        for i in range(num_series):\n",
    "            mf_params = model.mf_params[:,i]\n",
    "            for j in range(lag):\n",
    "\n",
    "                mX, _ = Fuzzyfy.fuzzify(np.array([yp_totest[0,i*lag+j]]),mf_params,num_groups=num_groups)\n",
    "                mX_values_in[:,:,i*lag+j] = mX\n",
    "\n",
    "\n",
    "                idx_nonzero = np.where(mX[0,:] > 0)\n",
    "                idx_nonzero = idx_nonzero[0]\n",
    "\n",
    "                if not_used_lag:\n",
    "                    for k in range(idx_nonzero.shape[0]):\n",
    "                        if j in lags_used[i]:\n",
    "                            antecedents_activated.append((it,idx_nonzero[k]))\n",
    "                        else:\n",
    "                            pass\n",
    "                    it += 1\n",
    "                \n",
    "                else:\n",
    "                    for k in range(idx_nonzero.shape[0]):\n",
    "                        antecedents_activated.append((i*lag+j,idx_nonzero[k]))\n",
    "\n",
    "        '''\n",
    "        if not_used_lag:\n",
    "            mX_values_in, _ = remove_lags(mX_values_in,lag_notused,num_series,lag)\n",
    "\n",
    "\n",
    "        prem_terms_test = np.zeros((ensemble_antecedents.shape[0],1))\n",
    "        '''\n",
    "        rules_idx = []\n",
    "        check_idx = 0\n",
    "        #Checking for every rule in dataset if it's activated\n",
    "        #TODO - Check if we can modify this into enumerate, avoiding check_idx += 1 every time.\n",
    "        for n_rule in ensemble_antecedents:\n",
    "            #print('Rule {} is {}'.format(check_idx,test(n_rule,antecedents_activated)))\n",
    "            if test(n_rule,antecedents_activated):\n",
    "                rules_idx.append(check_idx)\n",
    "            check_idx += 1\n",
    "            \n",
    "        prem_activated = np.zeros((ensemble_antecedents.shape[0],))\n",
    "        for i in rules_idx:\n",
    "            prem_activated[i,] = prem_term(ensemble_antecedents[i,0],mX_values_in)\n",
    "        \n",
    "        agg_test = np.zeros((wd_.shape))\n",
    "        for i in range(num_series):\n",
    "            for j in rules_idx:\n",
    "                rule = ensemble_rules[j,i]\n",
    "                consequent = rule[-1]\n",
    "                agg_test[j,consequent[1],i] = prem_activated[j,]\n",
    "                \n",
    "\n",
    "        weight_agg = np.multiply(agg_test,wd_)\n",
    "        weight_ = np.zeros((weight_agg.shape[1],weight_agg.shape[2]))\n",
    "        for i in range(weight_.shape[1]):\n",
    "            weight_[:,i] = weight_agg[:,:,i].max(axis=0)\n",
    "\n",
    "        w_todefuzz = np.reshape(weight_,(1,weight_.shape[0],weight_.shape[1]))\n",
    "        \n",
    "        #Defuzzification in fact\n",
    "        y_pred = defuzz.run(defuzz_method,w_todefuzz,show=False)\n",
    "        \n",
    "        #Store predicted value into yt_totest.\n",
    "        yt_totest[h_p,:] = y_pred\n",
    "        \n",
    "        #Last step, we use the predicted output to compose input data.\n",
    "        y_temp = np.zeros(yp_totest.shape)\n",
    "        assert y_temp.shape == yp_totest.shape\n",
    "        y_temp[0,1:] = yp_totest[0,0:yp_totest.shape[1]-1]\n",
    "        for ii in range(num_series):\n",
    "            #print(yp_totest[0,ii*lag])\n",
    "            #print(y_pred[0][ii])\n",
    "            #yp_totest[0,ii*lag] = y_pred[0][ii]\n",
    "            y_temp[0,ii*lag] = y_pred[0][ii]\n",
    "            #print(yp_totest[0,yp_totest.shape[1]-1])\n",
    "        yp_totest = y_temp\n",
    "\n",
    "    k = 1\n",
    "    for i in range(num_series):\n",
    "        plt.subplot(fig_axis[0],fig_axis[1],k)\n",
    "        plt.title('Serie {}'.format(ndata.columns[i]),fontsize=30)\n",
    "        plt.plot(yt_totest[:,i],color='blue')\n",
    "        plt.plot(out_sample[:,i],color='red')\n",
    "        plt.legend(['Predicted','Target'])\n",
    "        plt.xlabel('Time(h)',fontsize=15)\n",
    "        plt.ylabel('Value',fontsize=15)\n",
    "        print(rrse(yt_totest[:,i],out_sample[:,i]))\n",
    "        k += 1\n",
    "\n",
    "    return yp_totest, yt_totest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "dataset = pd.read_csv('traffic.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic informations \n",
    "\n",
    "num_predictors = 10\n",
    "num_input = 12\n",
    "lag = 24\n",
    "lag_notused = np.array([[4,5],[4,5],[4],[4,5]])\n",
    "not_used_lag = False\n",
    "\n",
    "h_test = int(0.2*dataset.shape[0]) #Changed test set for 20% of dataset (3508 values)\n",
    "h_val = 168\n",
    "h_train = 24*7*12\n",
    "#Actually, lag stands for all inputs for each serie. Example, lag = 2 uses s(t) and s(t-1) to predict s(t+1)\n",
    "diff_series = False\n",
    "detrend_series = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin_values = 12; #Representação da binarização do tempo.\n",
    "#num_series = data_.shape[1]  #Numero de series do problema, extraído dos dados\n",
    "num_series = 70\n",
    "max_rulesize =3 #Max numbers of premises rules.\n",
    "min_activation = 0.6 #Minimum activation\n",
    "\n",
    "#####Definicao de funcoes######\n",
    "#detrend_method = ''\n",
    "#bin_method = ''\n",
    "\n",
    "fuzzy_method = 'mfdef_cluster'\n",
    "num_groups = 9\n",
    "\n",
    "defuzz_method = 'height'\n",
    "\n",
    "ensemble_rules = None\n",
    "\n",
    "total_number = num_series*lag\n",
    "\n",
    "filepath = 'results V2'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to split between training, validation and test set.\n",
    "#Training set: 2 months of data (168*60) + lag\n",
    "#Validation set: 168 steps (1 week)\n",
    "#Test set: 168 steps (1 week)\n",
    "a = dataset.shape[0]\n",
    "training_data = dataset[a - h_train - lag - 1 - h_val - h_test:a-h_test]\n",
    "test_data = dataset[a - h_test:a]\n",
    "\n",
    "training_values = training_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_train_2 = a - h_test - h_val\n",
    "all_data_2 = dataset[lag:] \n",
    "training_data_2 = dataset[lag:lag+h_train_2]\n",
    "test_data_2 = dataset[a - h_test:a]\n",
    "\n",
    "data_ = training_data_2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3508, 862)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data = data1[:,[0, 61, 147, 241]]\n",
    "\n",
    "#data_ = training_values[:,:4]\n",
    "#data_ = training_values[:,[0, 61, 147, 241]]\n",
    "#data_ = training_values[:,0:1]\n",
    "#data_ = training_values[:,[0,61]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_external(data_,h_val,num_series, training_set, test_set, lag, all_data = None):\n",
    "    preprocess_data = Preprocess(data_,h_prev=h_val,num_series=num_series, lag=lag, target_position=1)\n",
    "    #For training set\n",
    "    # preprocess_data = Preprocess(data_,h_prev=h_val,num_series=num_series, lag=lag, target_position=1)\n",
    "    training_set, val_set = preprocess_data.split_data()\n",
    "    yt, yp, yp_lagged = preprocess_data.delay_input(in_sample = training_set, lag = lag)\n",
    "\n",
    "    if all_data is None:\n",
    "        all_data = np.concatenate((training_set, test_set))\n",
    "    #For all set. This will be useful for initial values of prediction\n",
    "    all_yt, all_yp, all_lagged = preprocess_data.delay_input(in_sample = all_data, lag = lag)\n",
    "\n",
    "    assert val_set.shape[0] == h_val\n",
    "    assert yp_lagged.shape[0] == h_train\n",
    "    assert yt.shape[0] == h_train\n",
    "\n",
    "    return preprocess_data, training_set, val_set, yt, yp, yp_lagged, all_yt, all_yp, all_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fuzzy_external(fuzzy_method, num_series, training_set, num_groups, yp, yt, yp_lagged, lag):\n",
    "    ###############Fuzzificacao\n",
    "\n",
    "    Fuzzyfy = Fuzzification(fuzzy_method)\n",
    "\n",
    "    #Lembrete: \n",
    "    #axis 0 - Registros da série\n",
    "    #axis 1 - Valor de pertinência ao conjunto Fuzzy\n",
    "    #axis 2 - Numero de séries\n",
    "\n",
    "    first_time = True\n",
    "    print(f'Serie fuzzification')\n",
    "    for n in range(num_series):\n",
    "        _, mf_params = Fuzzyfy.fuzzify(training_set[:,n],np.array([]),num_groups=num_groups)\n",
    "        mX, _ = Fuzzyfy.fuzzify(yp[:,n],mf_params,num_groups=num_groups)\n",
    "        mY, _ = Fuzzyfy.fuzzify(yt[:,n],mf_params,num_groups=num_groups)\n",
    "        if first_time:\n",
    "            mX_ = np.ndarray([mX.shape[0],mX.shape[1], num_series])\n",
    "            mY_ = np.ndarray([mY.shape[0],mY.shape[1], num_series])\n",
    "            mf_params_ = np.ndarray([mf_params.shape[0],num_series])\n",
    "            first_time = False\n",
    "        mX_[:,:,n] = mX\n",
    "        mY_[:,:,n] = mY\n",
    "        mf_params_[:,n] = mf_params.ravel()\n",
    "        #print(mf_params)\n",
    "        #print(mX.shape)\n",
    "\n",
    "    print('Creating for lag values')\n",
    "    mX_lagged_ = np.ndarray([mX_.shape[0],mX_.shape[1],yp_lagged.shape[1]])\n",
    "    for i in range(num_series):\n",
    "        # print(f'Serie {i}')\n",
    "        mf_params = mf_params_[:,i]\n",
    "        for j in range(lag):\n",
    "            mX, _ = Fuzzyfy.fuzzify(yp_lagged[:,i*lag+j],mf_params,num_groups=num_groups)\n",
    "            mX_lagged_[:,:,i*lag+j] = mX\n",
    "            #print(i*lag+j)\n",
    "\n",
    "\n",
    "    #mX_lagged_[:,:,not_select_subsample] = 0\n",
    "\n",
    "    #print(mX_lagged_[:,:,not_select_subsample])\n",
    "    ############## Formulacao\n",
    "    if not_used_lag:\n",
    "        new_mX, lags_used = remove_lags(mX_lagged_,lag_notused,num_series,lag)\n",
    "    else:\n",
    "        new_mX = mX_lagged_\n",
    "\n",
    "    return Fuzzyfy, mX_, mY_, mf_params_, mX_lagged_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#preprocess_data, training_set, val_set, yt, yp, yp_lagged, all_yt, all_yp, all_lagged = preprocess_external(data_,h_val,num_series, training_set, lag)\n",
    "\n",
    "#Fuzzyfy, mX_, mY_, mf_params_, mX_laged_ = fuzzy_external(fuzzy_method, num_series, training_set, num_groups, yp_lagged, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open ('results.traffic','rb') as f:\\n    predicted_values = pickle.load(f)\\n\\n#predicted_values = np.zeros((h_test, dataset.shape[1]))\\n\\nfor n_s in range(35,75):\\n    print(f'Begin serie {n_s}')\\n    print('='*89)\\n    train_values = training_values[:,n_s:n_s+1]\\n    test_values = test_data.values[:,n_s:n_s+1]\\n\\n    preprocess_data, training_set, val_set, yt, yp, yp_lagged, all_yt, all_yp, all_lagged = preprocess_external(train_values,h_val,num_series, train_values, test_values, lag)\\n\\n    Fuzzyfy, mX_, mY_, mf_params_, mX_lagged_ = fuzzy_external(fuzzy_method, num_series, training_set, num_groups, yp_lagged, lag)\\n\\n    new_mX = mX_lagged_\\n    #Initialization of model\\n\\n    manual_pattern = 7\\n\\n    #Creation a list of rule object. \\n    list_rules = [rule_object(None,None,None,None,i) for i in range(7)]\\n\\n    for n_pattern in range(manual_pattern):\\n\\n        min_error = 300.0\\n\\n        #print('='*89)\\n        #print(f'Starting Pattern {n_pattern}')\\n        #print('='*89)\\n        #Select a sample pattern for our problem. In that case, we apply a manual pattern on dataset\\n        t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \\n        t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\\n        \\n        t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\\n\\n        \\n        yp1 = deepcopy(yp[t_lagged,:])\\n        \\n        yt1 = deepcopy(yt[t_lagged,:])\\n        \\n        yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\\n\\n        in_sample = training_set[t,:]\\n        #plt.figure()\\n        #plt.plot(in_sample)\\n        #plt.show()\\n        out_sample = val_set[t_val,:]\\n        \\n        #Iintial values for prediction\\n        initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\\n\\n        #Always checking if initial values are correct by asserting it's target\\n        #assert (all_yt[yp_lagged.shape[0] + t_val[0],:] == out_sample[0,:]).all(), 'Target mismatch. Verify initial values lag.'\\n\\n        #print(f'Shape of in-sample is {in_sample.shape[0]}')\\n        #assert in_sample.shape[0] == h_train//7\\n        #print(f'Shape of lagged data is {yp_lagged1.shape[0]}')\\n        #assert yp_lagged1.shape[0] == h_train//manual_pattern\\n        #print(f'Shape of validation set is {out_sample.shape[0]}')\\n        #assert out_sample.shape[0] == h_val//manual_pattern\\n        #data1 = deepcopy(data_[t[len(t)-len(t_lagged):],:])\\n        #in_sample = data1[:data1.shape[0]-h_prev,:]\\n        #out_sample = data1[data1.shape[0]-h_prev:,:]\\n        #ensemble_rules = list_rules[n_pattern].complete_rules \\n        #ensemble_prem_terms = list_rules[n_pattern].prem_terms\\n        #ensemble_antecedents = list_rules[n_pattern].rules\\n\\n        #Concatenate rules\\n        for i in range(num_predictors):\\n            not_select_subsample = np.random.choice(total_number,total_number-num_input,replace=False)\\n            n_mX = deepcopy(new_mX)\\n            n_mX[:,:,not_select_subsample] = 0\\n            model = autoMFIS(diff_series=diff_series,detrend_series=detrend_series,fuzzy_method=fuzzy_method,solve_method='mqr',defuzz_method=defuzz_method, num_groups = num_groups, h_prev = h_val, num_series = num_series, max_rulesize = max_rulesize, min_activation = min_activation, lag = lag, hide_values = False, form_method = 'nmean', split_method = 'FCD')\\n\\n            model.set_fuzzification(Fuzzyfy, mf_params_, mX_, mY_, n_mX)\\n\\n            try:\\n                \\n                complete_rules, prem_terms, rules, agg_training, wd_ = model.train(train_values, yt=yt1,yp=yp1,yp_lagged=yp_lagged1,in_sample=in_sample,out_sample=out_sample,not_select_subsample=not_select_subsample, lag_notused=[])\\n\\n\\n\\n                #complete_rules, prem_terms, rules, agg_training, wd_ = autoMFIS(data_,lag=lag, lag_notused=lag_notused, not_used_lag=not_used_lag,not_select_subsample=not_select_subsample, h_prev = out_sample.shape[0], diff_series=diff_series, detrend_series=detrend_series, num_series=num_series, max_rulesize=max_rulesize, min_activation=min_activation, fuzzy_method=fuzzy_method, num_groups=num_groups,solve_method='mqr',defuzz_method=defuzz_method,yt=yt1,yp=yp1,yp_lagged=yp_lagged1,in_sample=in_sample,out_sample=out_sample)\\n                #print(f'Predict on validation set - #{i}')\\n                #Prediction of a single subset\\n                yt_totest, errors = model.predict(initial_values, data=train_values,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules, filepath=filepath, lim=3.0, fig_axis=[2,1],ndata=dataset)\\n\\n                #errors = predict(Fuzzyfy, lags_used = [], num_groups=num_groups, ndata=dataset, data=data_,in_sample=in_sample,out_sample=out_sample, lag = lag, mf_params_=mf_params_,num_series=num_series,agg_training=agg_training,yp_lagged=yp_lagged1,h_prev=out_sample.shape[0],not_used_lag=not_used_lag,n_attempt=f'p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules,filepath=filepath,lim=3.0,defuzz_method=defuzz_method,fig_axis=[2,2])\\n                #print(errors)\\n                #print(complete_rules)\\n                \\n                if errors[1,0] < 0.6:\\n                    if ensemble_rules is None:\\n                        ensemble_rules = complete_rules\\n                        ensemble_prem_terms = prem_terms\\n                        ensemble_antecedents = rules\\n                        #print(ensemble_rules.shape)\\n                    else:\\n                        ensemble_rules = np.concatenate((ensemble_rules, complete_rules))\\n                        \\n                        ensemble_prem_terms = np.concatenate((ensemble_prem_terms,prem_terms))\\n                        ensemble_antecedents = np.concatenate((ensemble_antecedents,rules))\\n                        #print(ensemble_rules.shape)\\n                        #print(ensemble_prem_terms.shape)\\n                    #print(ensemble_rules[:,0])\\n                elif ensemble_rules is None and i == num_predictors - 1:\\n                    ensemble_rules = complete_rules\\n                    ensemble_prem_terms = prem_terms\\n                    ensemble_antecedents = rules\\n                    print('No rules match criteria. Using rules to fill the gap')\\n                #print('RMSE Errors = {}'.format(errors[0,:]))\\n                print('RRSE Errors = {}'.format(errors[1,:]))\\n                #print('Mean RRSE Error = {}'.format(np.mean(errors[1,:])))\\n                \\n                #print('RRSE Errors = {}'.format(errors[1,:]))\\n                if errors[1,0] < min_error:\\n                    ensemble_rules = deepcopy(complete_rules)\\n                    ensemble_prem_terms = deepcopy(prem_terms)\\n                    ensemble_antecedents = deepcopy(rules)\\n                    wd__ = deepcopy(wd_)\\n                    min_error = errors[1,0]\\n                    #print(f'Min error found = {min_error}')\\n\\n            except Exception as e:\\n                print(e)\\n                pass\\n        list_rules[n_pattern].complete_rules = deepcopy(ensemble_rules)\\n        list_rules[n_pattern].prem_terms = deepcopy(ensemble_prem_terms)\\n        list_rules[n_pattern].rules = deepcopy(ensemble_antecedents)\\n        list_rules[n_pattern].wd_ = deepcopy(wd__)\\n\\n\\n\\n    init = in_sample.shape[0]\\n    for h_p in range(0,h_test,24):\\n\\n        rem = h_p % 168\\n\\n        k = rem // 24\\n\\n        #print(f'Debug only, rem = {rem} and k = {k}')\\n        #print('='*89)\\n        ensemble_antecedents = list_rules[k].rules\\n        ensemble_rules = list_rules[k].complete_rules\\n        wd_ = list_rules[k].wd_\\n\\n        initial_values = all_lagged[yp_lagged.shape[0]+h_p,:].reshape(1,-1)\\n\\n\\n        yt_totest, _ = model.predict(initial_values, data=train_values, in_sample = yt, out_sample=out_sample, agg_training=agg_training,h_prev=24,n_attempt=f'p_subsample_{i}',wd_=wd_,ensemble_antecedents=ensemble_antecedents,ensemble_rules=ensemble_rules, filepath=filepath, lim=min_error, fig_axis=[4,2],ndata=dataset,show=False)\\n\\n        #print(k)\\n        if (h_p+24 > predicted_values.shape[0]):\\n            bb = predicted_values.shape[0] - h_p\\n            predicted_values[h_p:h_p+bb,n_s:n_s+1] = yt_totest[0:bb]\\n        else:\\n            predicted_values[h_p:h_p+24,n_s:n_s+1] = yt_totest\\n\\n\\n    with open('results.traffic','wb') as f:\\n        pickle.dump(predicted_values, f, protocol=pickle.HIGHEST_PROTOCOL)\\n\\n    del model, list_rules\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "with open ('results.traffic','rb') as f:\n",
    "    predicted_values = pickle.load(f)\n",
    "\n",
    "#predicted_values = np.zeros((h_test, dataset.shape[1]))\n",
    "\n",
    "for n_s in range(35,75):\n",
    "    print(f'Begin serie {n_s}')\n",
    "    print('='*89)\n",
    "    train_values = training_values[:,n_s:n_s+1]\n",
    "    test_values = test_data.values[:,n_s:n_s+1]\n",
    "\n",
    "    preprocess_data, training_set, val_set, yt, yp, yp_lagged, all_yt, all_yp, all_lagged = preprocess_external(train_values,h_val,num_series, train_values, test_values, lag)\n",
    "\n",
    "    Fuzzyfy, mX_, mY_, mf_params_, mX_lagged_ = fuzzy_external(fuzzy_method, num_series, training_set, num_groups, yp_lagged, lag)\n",
    "\n",
    "    new_mX = mX_lagged_\n",
    "    #Initialization of model\n",
    "\n",
    "    manual_pattern = 7\n",
    "\n",
    "    #Creation a list of rule object. \n",
    "    list_rules = [rule_object(None,None,None,None,i) for i in range(7)]\n",
    "\n",
    "    for n_pattern in range(manual_pattern):\n",
    "\n",
    "        min_error = 300.0\n",
    "\n",
    "        #print('='*89)\n",
    "        #print(f'Starting Pattern {n_pattern}')\n",
    "        #print('='*89)\n",
    "        #Select a sample pattern for our problem. In that case, we apply a manual pattern on dataset\n",
    "        t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "        t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "        \n",
    "        t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "        \n",
    "        yp1 = deepcopy(yp[t_lagged,:])\n",
    "        \n",
    "        yt1 = deepcopy(yt[t_lagged,:])\n",
    "        \n",
    "        yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "        in_sample = training_set[t,:]\n",
    "        #plt.figure()\n",
    "        #plt.plot(in_sample)\n",
    "        #plt.show()\n",
    "        out_sample = val_set[t_val,:]\n",
    "        \n",
    "        #Iintial values for prediction\n",
    "        initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\n",
    "\n",
    "        #Always checking if initial values are correct by asserting it's target\n",
    "        #assert (all_yt[yp_lagged.shape[0] + t_val[0],:] == out_sample[0,:]).all(), 'Target mismatch. Verify initial values lag.'\n",
    "\n",
    "        #print(f'Shape of in-sample is {in_sample.shape[0]}')\n",
    "        #assert in_sample.shape[0] == h_train//7\n",
    "        #print(f'Shape of lagged data is {yp_lagged1.shape[0]}')\n",
    "        #assert yp_lagged1.shape[0] == h_train//manual_pattern\n",
    "        #print(f'Shape of validation set is {out_sample.shape[0]}')\n",
    "        #assert out_sample.shape[0] == h_val//manual_pattern\n",
    "        #data1 = deepcopy(data_[t[len(t)-len(t_lagged):],:])\n",
    "        #in_sample = data1[:data1.shape[0]-h_prev,:]\n",
    "        #out_sample = data1[data1.shape[0]-h_prev:,:]\n",
    "        #ensemble_rules = list_rules[n_pattern].complete_rules \n",
    "        #ensemble_prem_terms = list_rules[n_pattern].prem_terms\n",
    "        #ensemble_antecedents = list_rules[n_pattern].rules\n",
    "\n",
    "        #Concatenate rules\n",
    "        for i in range(num_predictors):\n",
    "            not_select_subsample = np.random.choice(total_number,total_number-num_input,replace=False)\n",
    "            n_mX = deepcopy(new_mX)\n",
    "            n_mX[:,:,not_select_subsample] = 0\n",
    "            model = autoMFIS(diff_series=diff_series,detrend_series=detrend_series,fuzzy_method=fuzzy_method,solve_method='mqr',defuzz_method=defuzz_method, num_groups = num_groups, h_prev = h_val, num_series = num_series, max_rulesize = max_rulesize, min_activation = min_activation, lag = lag, hide_values = False, form_method = 'nmean', split_method = 'FCD')\n",
    "\n",
    "            model.set_fuzzification(Fuzzyfy, mf_params_, mX_, mY_, n_mX)\n",
    "\n",
    "            try:\n",
    "                \n",
    "                complete_rules, prem_terms, rules, agg_training, wd_ = model.train(train_values, yt=yt1,yp=yp1,yp_lagged=yp_lagged1,in_sample=in_sample,out_sample=out_sample,not_select_subsample=not_select_subsample, lag_notused=[])\n",
    "\n",
    "\n",
    "\n",
    "                #complete_rules, prem_terms, rules, agg_training, wd_ = autoMFIS(data_,lag=lag, lag_notused=lag_notused, not_used_lag=not_used_lag,not_select_subsample=not_select_subsample, h_prev = out_sample.shape[0], diff_series=diff_series, detrend_series=detrend_series, num_series=num_series, max_rulesize=max_rulesize, min_activation=min_activation, fuzzy_method=fuzzy_method, num_groups=num_groups,solve_method='mqr',defuzz_method=defuzz_method,yt=yt1,yp=yp1,yp_lagged=yp_lagged1,in_sample=in_sample,out_sample=out_sample)\n",
    "                #print(f'Predict on validation set - #{i}')\n",
    "                #Prediction of a single subset\n",
    "                yt_totest, errors = model.predict(initial_values, data=train_values,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules, filepath=filepath, lim=3.0, fig_axis=[2,1],ndata=dataset)\n",
    "\n",
    "                #errors = predict(Fuzzyfy, lags_used = [], num_groups=num_groups, ndata=dataset, data=data_,in_sample=in_sample,out_sample=out_sample, lag = lag, mf_params_=mf_params_,num_series=num_series,agg_training=agg_training,yp_lagged=yp_lagged1,h_prev=out_sample.shape[0],not_used_lag=not_used_lag,n_attempt=f'p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules,filepath=filepath,lim=3.0,defuzz_method=defuzz_method,fig_axis=[2,2])\n",
    "                #print(errors)\n",
    "                #print(complete_rules)\n",
    "                \n",
    "                if errors[1,0] < 0.6:\n",
    "                    if ensemble_rules is None:\n",
    "                        ensemble_rules = complete_rules\n",
    "                        ensemble_prem_terms = prem_terms\n",
    "                        ensemble_antecedents = rules\n",
    "                        #print(ensemble_rules.shape)\n",
    "                    else:\n",
    "                        ensemble_rules = np.concatenate((ensemble_rules, complete_rules))\n",
    "                        \n",
    "                        ensemble_prem_terms = np.concatenate((ensemble_prem_terms,prem_terms))\n",
    "                        ensemble_antecedents = np.concatenate((ensemble_antecedents,rules))\n",
    "                        #print(ensemble_rules.shape)\n",
    "                        #print(ensemble_prem_terms.shape)\n",
    "                    #print(ensemble_rules[:,0])\n",
    "                elif ensemble_rules is None and i == num_predictors - 1:\n",
    "                    ensemble_rules = complete_rules\n",
    "                    ensemble_prem_terms = prem_terms\n",
    "                    ensemble_antecedents = rules\n",
    "                    print('No rules match criteria. Using rules to fill the gap')\n",
    "                #print('RMSE Errors = {}'.format(errors[0,:]))\n",
    "                print('RRSE Errors = {}'.format(errors[1,:]))\n",
    "                #print('Mean RRSE Error = {}'.format(np.mean(errors[1,:])))\n",
    "                \n",
    "                #print('RRSE Errors = {}'.format(errors[1,:]))\n",
    "                if errors[1,0] < min_error:\n",
    "                    ensemble_rules = deepcopy(complete_rules)\n",
    "                    ensemble_prem_terms = deepcopy(prem_terms)\n",
    "                    ensemble_antecedents = deepcopy(rules)\n",
    "                    wd__ = deepcopy(wd_)\n",
    "                    min_error = errors[1,0]\n",
    "                    #print(f'Min error found = {min_error}')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        list_rules[n_pattern].complete_rules = deepcopy(ensemble_rules)\n",
    "        list_rules[n_pattern].prem_terms = deepcopy(ensemble_prem_terms)\n",
    "        list_rules[n_pattern].rules = deepcopy(ensemble_antecedents)\n",
    "        list_rules[n_pattern].wd_ = deepcopy(wd__)\n",
    "\n",
    "\n",
    "\n",
    "    init = in_sample.shape[0]\n",
    "    for h_p in range(0,h_test,24):\n",
    "\n",
    "        rem = h_p % 168\n",
    "\n",
    "        k = rem // 24\n",
    "\n",
    "        #print(f'Debug only, rem = {rem} and k = {k}')\n",
    "        #print('='*89)\n",
    "        ensemble_antecedents = list_rules[k].rules\n",
    "        ensemble_rules = list_rules[k].complete_rules\n",
    "        wd_ = list_rules[k].wd_\n",
    "\n",
    "        initial_values = all_lagged[yp_lagged.shape[0]+h_p,:].reshape(1,-1)\n",
    "\n",
    "\n",
    "        yt_totest, _ = model.predict(initial_values, data=train_values, in_sample = yt, out_sample=out_sample, agg_training=agg_training,h_prev=24,n_attempt=f'p_subsample_{i}',wd_=wd_,ensemble_antecedents=ensemble_antecedents,ensemble_rules=ensemble_rules, filepath=filepath, lim=min_error, fig_axis=[4,2],ndata=dataset,show=False)\n",
    "\n",
    "        #print(k)\n",
    "        if (h_p+24 > predicted_values.shape[0]):\n",
    "            bb = predicted_values.shape[0] - h_p\n",
    "            predicted_values[h_p:h_p+bb,n_s:n_s+1] = yt_totest[0:bb]\n",
    "        else:\n",
    "            predicted_values[h_p:h_p+24,n_s:n_s+1] = yt_totest\n",
    "\n",
    "\n",
    "    with open('results.traffic','wb') as f:\n",
    "        pickle.dump(predicted_values, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    del model, list_rules\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Traffic rate')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_values[:168*2,0])\n",
    "plt.title('Patterns of Traffic Rate dataset')\n",
    "plt.xlabel('Time(h)')\n",
    "plt.ylabel('Traffic rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization\n",
      "Start\n",
      "=========================================================================================\n",
      "Starting Pattern 0\n",
      "=========================================================================================\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #0\n",
      "[[0.02665013 0.02744224 0.0751663  0.01908921 0.02456713 0.04354131\n",
      "  0.07526544 0.04928087 0.02786579 0.06612908 0.02182674 0.02509898\n",
      "  0.02008694 0.02558381 0.06764665 0.0394706  0.03211595 0.03390203\n",
      "  0.02198941 0.02207014 0.02169789 0.03391305 0.02161022 0.08586427\n",
      "  0.07934857 0.05242165 0.03370072 0.0163774  0.0251065  0.03194499\n",
      "  0.0619074  0.04876947 0.05418847 0.03676775 0.0191584  0.02088557\n",
      "  0.01279006 0.05354509 0.01421325 0.02169789 0.01853008 0.03032629\n",
      "  0.02843551 0.01583456 0.01197166 0.05062724 0.02110298 0.03796373\n",
      "  0.03650055 0.01977364 0.01643986 0.01671355 0.05315573 0.02135752\n",
      "  0.02515579 0.08626635 0.04304161 0.02799136 0.08233864 0.02195365\n",
      "  0.03903646 0.03096261 0.03762879 0.02077556 0.04824951 0.01205819\n",
      "  0.02411244 0.01826558 0.01113294 0.08073413]\n",
      " [0.75081867 1.29015751 0.85983962 0.81220421 1.81813688 1.49782101\n",
      "  1.15161303 1.44640243 0.93123279 1.84860976 0.94204618 1.13171229\n",
      "  0.54893418 0.95280928 0.6665987  1.11030345 2.24458641 0.60237406\n",
      "  0.7100919  0.75285807 0.75174623 0.86335891 0.70658325 0.89539007\n",
      "  1.90743323 1.23276038 1.0711528  0.53547285 0.85029401 1.08744791\n",
      "  0.95177409 1.73961995 1.30669015 0.85198793 0.81554678 0.63939056\n",
      "  0.6887441  1.12816379 0.75450152 0.75174623 0.80738777 1.14261897\n",
      "  1.50290372 0.67319707 0.75324283 2.68625731 0.7399202  1.22825048\n",
      "  1.19405794 0.48014486 0.56889445 0.59487608 0.62358725 0.58659457\n",
      "  0.95116497 0.75086626 2.0030134  0.98339345 2.72824156 0.65563354\n",
      "  1.00481496 1.01241647 1.39426988 0.62358408 1.27157537 0.63133442\n",
      "  1.33394758 0.59406699 0.40589467 2.31153448]]\n",
      "0.7508186685489511\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #1\n",
      "[[0.02075261 0.0202203  0.06614915 0.01861642 0.02577483 0.06059288\n",
      "  0.04508507 0.04441038 0.01935167 0.07413581 0.02311837 0.01657013\n",
      "  0.02292291 0.03950939 0.0625827  0.04101715 0.03791301 0.03012426\n",
      "  0.02609308 0.02622745 0.02627798 0.02159755 0.01780464 0.07510464\n",
      "  0.11123108 0.04762159 0.02710243 0.01379816 0.02215035 0.03726778\n",
      "  0.03974483 0.02497823 0.05570815 0.0321231  0.01410104 0.0194641\n",
      "  0.01288598 0.05610493 0.01675289 0.02627798 0.02151031 0.03024971\n",
      "  0.0242219  0.08368529 0.01043653 0.05030284 0.01916145 0.0370405\n",
      "  0.0380072  0.02187914 0.02321364 0.01659419 0.04897068 0.01570597\n",
      "  0.02656597 0.08254621 0.03379481 0.02878541 0.04197145 0.03025883\n",
      "  0.03394979 0.0312246  0.04306013 0.02761809 0.05609778 0.01075199\n",
      "  0.02676085 0.052758   0.01638945 0.07282182]\n",
      " [0.80681375 0.9559094  0.82566451 0.81452059 1.88375234 0.91055989\n",
      "  0.86546301 1.026571   0.48924982 2.60852094 1.04339146 0.68279393\n",
      "  1.06259854 0.8492421  1.04741131 1.44447124 2.30626214 0.66962523\n",
      "  1.04383037 1.00738172 1.49827626 0.61396278 0.82398243 0.91750077\n",
      "  1.08375767 0.82138634 0.98835468 0.9559409  0.85303083 2.0674307\n",
      "  0.6789384  0.68404983 1.2477939  1.11472467 0.70048773 0.65410434\n",
      "  0.76186719 1.46496137 0.86591028 1.49827626 1.23229162 0.68503092\n",
      "  0.87450075 0.91753768 0.69032867 3.3655506  0.75254074 1.29101775\n",
      "  1.22845313 0.58782905 1.19859865 0.6825157  0.83107385 0.74916875\n",
      "  1.18746852 0.91042637 0.87245695 0.9815391  0.82823423 0.73618746\n",
      "  0.93952048 1.18011262 1.57379684 0.83909711 0.82368141 0.51412305\n",
      "  1.16634203 0.85925315 1.00885256 1.99800777]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #2\n",
      "[[0.02747616 0.01420948 0.05442705 0.01911758 0.02576694 0.09111618\n",
      "  0.08542372 0.05970634 0.04276095 0.07205221 0.02093783 0.02440299\n",
      "  0.01606131 0.03437229 0.07611017 0.03464199 0.02204466 0.03408357\n",
      "  0.02401265 0.09943171 0.01842524 0.02473694 0.03261384 0.05130417\n",
      "  0.11632392 0.04667278 0.03613008 0.0090254  0.01367515 0.07201509\n",
      "  0.07330458 0.04111626 0.06734757 0.03199381 0.018925   0.01239694\n",
      "  0.00780999 0.05282417 0.01018968 0.01842524 0.02012077 0.08629932\n",
      "  0.02286813 0.01480012 0.00940291 0.04674163 0.03819018 0.03985949\n",
      "  0.0332365  0.02252848 0.01362178 0.01215863 0.05225221 0.01487737\n",
      "  0.02481681 0.06718367 0.0408817  0.02699973 0.05667401 0.02100153\n",
      "  0.03402484 0.01954321 0.03781836 0.01855097 0.04762791 0.01063828\n",
      "  0.01764901 0.01483021 0.01484883 0.06877263]\n",
      " [0.70650834 0.49535851 0.74680528 0.73661595 1.08916017 0.95789701\n",
      "  1.04112035 0.77396565 0.80932795 2.6773172  0.73360087 0.75777148\n",
      "  0.57367242 0.71758564 1.30312046 1.0780163  1.08757483 0.67188961\n",
      "  0.77017048 0.93165756 0.64544452 0.75419525 0.83341787 0.65642095\n",
      "  0.8858978  0.7833406  0.88600924 0.41641456 0.63644202 0.92499756\n",
      "  0.94557403 0.71527968 0.99646104 0.79941187 0.77204915 0.51541091\n",
      "  0.55381312 1.69051154 0.63905497 0.64544452 0.72557405 0.97641533\n",
      "  1.02171403 0.50171864 0.72584147 2.15464363 0.85081468 0.9070172\n",
      "  0.84142057 0.57148996 0.71226427 0.52705125 0.68556171 0.60327315\n",
      "  0.70208568 0.76241309 0.79747203 0.74789596 2.52853    0.5966892\n",
      "  1.09818975 0.57885213 1.41274923 0.57894262 0.68384495 0.58315217\n",
      "  0.68310742 0.64607487 0.63455612 1.86420217]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #3\n",
      "[[0.02120284 0.01819082 0.0485825  0.0168207  0.02080538 0.10849885\n",
      "  0.0398799  0.05827183 0.03648226 0.07163844 0.01741647 0.01338891\n",
      "  0.0197371  0.031519   0.06410284 0.03207243 0.03251871 0.03813877\n",
      "  0.02131562 0.08328746 0.01701829 0.01869902 0.03647944 0.05581711\n",
      "  0.0952674  0.03387305 0.03511813 0.01295185 0.01650239 0.03287747\n",
      "  0.03396444 0.03212103 0.05088388 0.02688709 0.02876408 0.01703103\n",
      "  0.01433256 0.04961821 0.01141685 0.01701829 0.01832937 0.08113693\n",
      "  0.02478607 0.01402331 0.00950686 0.05072249 0.03532691 0.03590556\n",
      "  0.03060593 0.01820633 0.0134125  0.01539958 0.05135269 0.01463726\n",
      "  0.02165491 0.08009025 0.03851487 0.02555633 0.02946932 0.0343207\n",
      "  0.03269212 0.0256684  0.04216854 0.05841134 0.04235954 0.0135697\n",
      "  0.01663849 0.06571657 0.01537195 0.07153893]\n",
      " [0.70463835 0.78536655 0.65757661 0.75936323 0.95839499 1.01739506\n",
      "  0.67873614 0.70893346 0.76634026 2.37559686 0.69594983 0.6413301\n",
      "  0.63149342 0.73143248 1.16816358 0.8836902  2.00543899 0.63819873\n",
      "  0.66769287 0.86476834 0.61941106 0.53414198 0.88681716 0.77931463\n",
      "  0.91471938 0.69303791 0.96845716 0.52362596 0.73664399 1.47091377\n",
      "  0.60533352 0.70649364 0.76459463 0.87622262 0.8726649  0.63993793\n",
      "  0.78648392 1.35615306 0.67185093 0.61941106 0.88998355 0.99135462\n",
      "  1.20814921 0.49754396 0.66400571 2.0586094  0.87867134 1.29912808\n",
      "  0.83468203 0.55333249 0.57019525 0.74029999 0.55558368 0.53477412\n",
      "  1.01020608 0.83344286 0.85738134 0.9796471  0.56335575 0.76446292\n",
      "  0.97452408 0.91956644 1.72664834 0.98748297 0.70807371 0.62288743\n",
      "  0.61398676 0.90051122 0.72654508 1.97390995]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #4\n",
      "[[0.0237137  0.02023426 0.07369185 0.02926077 0.02570263 0.06010432\n",
      "  0.084549   0.06204262 0.03396931 0.07266525 0.02299106 0.02447337\n",
      "  0.03035    0.03624595 0.07899452 0.04254192 0.03199968 0.04448554\n",
      "  0.03986006 0.02958394 0.0288311  0.03580228 0.02691984 0.05722404\n",
      "  0.08019104 0.05801246 0.02728336 0.02415054 0.03027609 0.03859107\n",
      "  0.05794126 0.03762713 0.05540447 0.03073487 0.02275044 0.02568054\n",
      "  0.01936948 0.05539082 0.01846252 0.0288311  0.02538049 0.04424387\n",
      "  0.03842573 0.02936232 0.01781309 0.04717886 0.02952615 0.03907702\n",
      "  0.03842392 0.0396914  0.02326975 0.01989424 0.06880355 0.02855199\n",
      "  0.03161189 0.09609975 0.04869518 0.02756692 0.05552457 0.03504288\n",
      "  0.0424989  0.0349076  0.04746852 0.09346276 0.06108491 0.01846281\n",
      "  0.02515199 0.10144777 0.0242406  0.07072419]\n",
      " [0.73121868 0.76410539 0.75421456 1.14938561 1.61748581 0.74958072\n",
      "  0.84219839 1.17615417 0.77108205 2.0702763  1.04755498 0.79046487\n",
      "  0.82051072 1.01140946 0.83781281 1.15994137 1.6598817  0.66875154\n",
      "  1.23314857 0.91104037 1.09989411 1.03146792 0.89058088 0.741118\n",
      "  1.0480382  0.7908454  0.70950347 0.78095676 1.04386384 1.34735741\n",
      "  0.74551512 1.12617603 0.90679238 0.65404987 0.8533911  0.77707774\n",
      "  0.8216427  1.11687002 0.95748917 1.09989411 1.01415866 0.7389132\n",
      "  0.96090569 0.81254671 1.09493718 1.94439545 0.91373287 1.24223506\n",
      "  1.11635032 0.86407816 0.85319805 0.73415324 0.63177677 0.94351313\n",
      "  1.12078461 0.75239775 1.2896105  0.80379075 0.89526429 0.89876706\n",
      "  1.21136527 1.10993056 1.62652697 1.01077088 0.75501601 0.93015732\n",
      "  0.84534319 0.98456862 0.89691728 1.59772779]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #5\n",
      "[[0.02314544 0.03493759 0.06815636 0.02661965 0.02964892 0.0984222\n",
      "  0.04636869 0.06204756 0.03490587 0.07500306 0.02472661 0.02443472\n",
      "  0.0282598  0.02877582 0.06240535 0.04008241 0.03827269 0.04589423\n",
      "  0.02692189 0.03320547 0.02507936 0.03939323 0.03792437 0.0759922\n",
      "  0.09827397 0.05871939 0.04681065 0.01636743 0.02343578 0.03516967\n",
      "  0.0437219  0.06327909 0.06242283 0.05035031 0.01857327 0.02160939\n",
      "  0.01429331 0.05745111 0.01855382 0.02507936 0.02724072 0.06190716\n",
      "  0.02935865 0.01728039 0.01271179 0.04852105 0.03309944 0.04414214\n",
      "  0.04037945 0.02724704 0.02400516 0.01786856 0.08354688 0.01928135\n",
      "  0.02628736 0.10496532 0.04277114 0.03216291 0.04429918 0.0359793\n",
      "  0.04008195 0.03110594 0.04494249 0.02777376 0.05509887 0.01485516\n",
      "  0.02750349 0.05312705 0.01446971 0.07764659]\n",
      " [0.78192456 1.25010649 0.98399078 1.05685778 1.88228128 1.03446135\n",
      "  0.90117355 0.9717566  0.80198783 2.23327258 1.08591732 1.15937638\n",
      "  0.8377368  0.76523726 0.99771939 1.01503286 1.79801085 0.7853788\n",
      "  0.82315953 1.25460295 1.04505954 1.04463569 0.88595796 0.95909127\n",
      "  1.14514848 1.46400539 1.29818731 0.62068524 0.8479765  1.52827868\n",
      "  0.70473726 2.14510972 1.07758625 1.02865084 0.78582518 0.71915711\n",
      "  0.79016124 1.53753682 0.84783922 1.04505954 1.03411108 0.96551448\n",
      "  1.34716638 0.59412175 0.7794803  1.96169412 0.90534423 1.65035017\n",
      "  1.25007042 0.68014562 1.12697481 0.73040121 0.85198047 0.64559265\n",
      "  1.02874939 1.10639009 0.97664779 1.00956114 0.8856184  0.78007224\n",
      "  1.01367542 1.09305462 1.54219847 0.87512333 1.6380897  0.68266213\n",
      "  1.05028433 0.94798727 0.6926764  1.93426717]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #6\n",
      "[[0.02962585 0.03068832 0.05954125 0.01387009 0.02496053 0.06215533\n",
      "  0.05901429 0.04316281 0.04132086 0.07523288 0.01947215 0.02055217\n",
      "  0.02684987 0.03367313 0.0788899  0.03089941 0.02612814 0.07052898\n",
      "  0.03319695 0.06471561 0.01388913 0.03589668 0.02685679 0.04867652\n",
      "  0.07432076 0.05408802 0.03855838 0.02281259 0.02992177 0.0370547\n",
      "  0.05178943 0.05214334 0.05515785 0.06106125 0.01726795 0.01814313\n",
      "  0.00996382 0.05637402 0.01365912 0.01388913 0.02494843 0.03646963\n",
      "  0.02048495 0.03178933 0.00940972 0.06385089 0.03169213 0.03495313\n",
      "  0.02744302 0.02344356 0.02004068 0.01301618 0.09372199 0.01213589\n",
      "  0.02901154 0.07243953 0.04200434 0.02317617 0.07216945 0.0218022\n",
      "  0.03764083 0.02709949 0.03695074 0.02128148 0.05391028 0.01751214\n",
      "  0.02524714 0.01768934 0.01564424 0.08164593]\n",
      " [0.79700286 0.98412977 0.84066643 0.51321569 1.00237748 0.83856244\n",
      "  0.90780183 0.73230301 1.03611008 2.80777226 0.73566516 0.71452294\n",
      "  0.75182218 0.95003946 1.19902661 1.03549199 1.10342838 0.92113677\n",
      "  1.43058733 0.93894036 0.57637582 0.85218427 0.7583266  0.6951918\n",
      "  0.96440933 0.88518298 0.85247357 0.98049457 1.05008353 2.07397598\n",
      "  0.82445663 0.99186393 0.80666194 1.00306268 0.75566245 0.76357743\n",
      "  0.68068914 1.60708096 0.71818938 0.57637582 0.9106043  0.80422104\n",
      "  0.97155922 1.13898253 0.8045623  1.96155885 0.78095172 0.97602518\n",
      "  1.03317453 0.77025008 0.89904428 0.7075781  0.95589982 0.44100407\n",
      "  1.08578829 0.86562096 0.98803564 0.66484311 2.8640016  0.66477093\n",
      "  1.33093273 0.67132731 1.2212944  0.67997078 0.91003046 0.96767379\n",
      "  0.97798017 0.7577826  0.97243436 1.63450966]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #7\n",
      "[[0.03106356 0.03570242 0.1040713  0.02651467 0.03021429 0.0786437\n",
      "  0.07488117 0.06736209 0.0412764  0.07134817 0.02809853 0.03069662\n",
      "  0.03020013 0.03551612 0.08659363 0.04606857 0.03478427 0.04730918\n",
      "  0.02519562 0.05212345 0.02849892 0.05299259 0.02564315 0.09269211\n",
      "  0.09191742 0.06237854 0.04934203 0.02499152 0.02405679 0.04535651\n",
      "  0.08121355 0.06613423 0.07007119 0.04697808 0.02838538 0.03152731\n",
      "  0.01891039 0.06965635 0.02056347 0.02849892 0.02734278 0.05172087\n",
      "  0.03234168 0.03361234 0.01497551 0.04909914 0.03264206 0.04934987\n",
      "  0.04608477 0.03902628 0.02773277 0.02487798 0.07969544 0.03211593\n",
      "  0.02989976 0.1328825  0.04406838 0.03276057 0.07890598 0.0334057\n",
      "  0.04293359 0.04011931 0.04607677 0.03317452 0.05694691 0.0162126\n",
      "  0.02862914 0.02431086 0.02761855 0.08108987]\n",
      " [0.87849499 1.47250278 1.40479476 0.90591496 1.21271689 1.37669265\n",
      "  1.5233498  1.33838611 1.23717999 2.33194391 0.98494002 1.00508198\n",
      "  1.15445529 1.05252154 1.42517834 1.41825124 1.7758155  1.85152598\n",
      "  0.80784552 1.03989067 0.96144297 1.74600728 0.96709221 1.31924456\n",
      "  1.53095668 1.13382337 1.22498718 0.95677664 0.86564547 1.63313472\n",
      "  1.29247921 1.24747364 1.58194186 1.35499707 1.20448706 1.1740267\n",
      "  1.35827856 1.94510589 1.15077721 0.96144299 1.18501662 1.39719815\n",
      "  1.6350692  1.04535434 1.00644597 2.1004689  1.26062009 1.15391604\n",
      "  1.12481527 1.18303631 1.1438628  1.03282565 2.4739558  1.12707068\n",
      "  1.24687909 1.28230582 1.2429194  1.08933964 1.57375791 0.95265719\n",
      "  1.33955901 0.90172558 1.3852391  1.33937098 1.23610898 0.92922062\n",
      "  1.02246074 1.13671646 1.24517782 2.2498586 ]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #8\n",
      "[[0.03056169 0.0283279  0.0911915  0.02169491 0.0236779  0.06026069\n",
      "  0.06557046 0.0510646  0.03588658 0.07002743 0.02172927 0.02398135\n",
      "  0.02366835 0.02965754 0.0691926  0.03823061 0.03349739 0.03452016\n",
      "  0.02565724 0.05535539 0.02055129 0.03085519 0.02274434 0.06088138\n",
      "  0.06958148 0.0552204  0.03870869 0.01519939 0.0227271  0.0382316\n",
      "  0.0486036  0.04967349 0.05137854 0.04382794 0.02612031 0.02415841\n",
      "  0.0111925  0.05953633 0.01674628 0.02055129 0.02227476 0.0448772\n",
      "  0.02659946 0.02027175 0.01405219 0.04858133 0.02489538 0.04066193\n",
      "  0.03749745 0.02583686 0.01801264 0.01561491 0.07336812 0.02977514\n",
      "  0.02527922 0.10039561 0.0461372  0.02824621 0.06286795 0.02757771\n",
      "  0.03713155 0.0273235  0.04216    0.0231051  0.05884242 0.01318801\n",
      "  0.02573632 0.01888793 0.01736976 0.07895206]\n",
      " [0.77439982 1.00814458 1.13741675 0.83850018 1.07071124 0.93595288\n",
      "  1.04310138 0.9964554  0.92101732 2.11247521 0.82404554 0.91022153\n",
      "  0.82548197 1.13666295 0.95875004 1.0528372  1.37505847 0.73596679\n",
      "  1.02497734 0.91368796 0.88713422 0.8323917  0.87616883 0.86156616\n",
      "  1.11891347 0.97629753 1.08920401 0.62333226 0.96157919 1.50905444\n",
      "  1.04849847 1.13705065 1.0822965  1.00496359 1.24039043 0.88386507\n",
      "  0.74387686 1.50159204 0.94269853 0.88713421 0.91514969 0.96134641\n",
      "  1.3199886  0.69572823 1.11646815 2.30207634 0.9029503  1.22789122\n",
      "  1.08903028 0.71466713 0.8726866  0.62460078 0.83843936 0.86750501\n",
      "  1.10984108 1.22378899 1.10155367 0.89445995 1.33023363 0.90138109\n",
      "  1.20653997 0.77820712 1.68433161 0.88232455 0.9896105  0.79017198\n",
      "  0.9330736  0.86791893 0.89346432 2.2096792 ]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #9\n",
      "[[0.02675331 0.01813434 0.08570231 0.02784659 0.03152315 0.10200095\n",
      "  0.09413985 0.06179999 0.05542334 0.07646648 0.02530359 0.0197249\n",
      "  0.03655828 0.04771871 0.06580994 0.0407244  0.03353454 0.04459046\n",
      "  0.02732238 0.03962937 0.0308692  0.04674907 0.04146654 0.08179423\n",
      "  0.09926141 0.0584449  0.05171504 0.01980782 0.01840832 0.03809731\n",
      "  0.09665785 0.043202   0.05910956 0.0307872  0.03191711 0.02400395\n",
      "  0.01455676 0.06195628 0.01960297 0.0308692  0.03069469 0.07191644\n",
      "  0.03239388 0.02269143 0.0154869  0.04849927 0.04972541 0.04029042\n",
      "  0.03807042 0.03545485 0.02629269 0.02099813 0.07812739 0.02831039\n",
      "  0.02823891 0.1116862  0.03937364 0.0333863  0.05750679 0.0379013\n",
      "  0.04289589 0.03306162 0.0503997  0.03260007 0.05853428 0.01758676\n",
      "  0.03126843 0.02669244 0.0185426  0.08573277]\n",
      " [0.91572876 0.77619927 1.12842908 1.08854298 4.23648587 1.10804526\n",
      "  1.11377405 0.98894025 0.91992091 2.71894209 1.2845156  0.73976404\n",
      "  1.13406908 0.93179409 1.04120802 1.09289587 1.97272962 1.29488768\n",
      "  0.8569414  1.88494155 1.37132555 1.27726878 0.92962964 1.33214124\n",
      "  1.11786441 1.92421486 2.45169615 0.72005333 0.94416453 1.47224107\n",
      "  1.08536215 1.61943916 0.99669843 1.08632611 0.99602281 0.91424627\n",
      "  1.04651848 1.57171952 1.09209007 1.37132555 2.17709049 1.11653327\n",
      "  1.57514466 0.70916196 1.02336429 2.1741468  1.0743691  2.01479485\n",
      "  1.31333535 0.87276034 1.20795649 0.89545678 1.61581988 0.80630408\n",
      "  1.18147606 1.20980812 0.85010381 1.49300205 1.66827341 0.82233735\n",
      "  1.06346604 1.67218081 2.00786245 1.04074327 1.83089118 0.75790194\n",
      "  1.14739583 1.23547516 0.70986228 2.55513155]]\n",
      "=========================================================================================\n",
      "Starting Pattern 1\n",
      "=========================================================================================\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #0\n",
      "[[0.02870787 0.02383099 0.0428075  0.02609858 0.03696173 0.04937475\n",
      "  0.05240005 0.0414816  0.0252548  0.09534753 0.03576093 0.01766423\n",
      "  0.02509327 0.02592972 0.03959822 0.02602334 0.02818598 0.05147347\n",
      "  0.02013546 0.10118634 0.03164975 0.06820592 0.02058543 0.05783469\n",
      "  0.06534168 0.07523351 0.02282727 0.02093281 0.01720549 0.03801586\n",
      "  0.04130193 0.02998543 0.03983464 0.02058681 0.01232439 0.0202487\n",
      "  0.01532632 0.02689875 0.0172762  0.03164975 0.02765187 0.04297248\n",
      "  0.02215751 0.04867263 0.01276361 0.03241841 0.03559915 0.02617592\n",
      "  0.03002421 0.02399873 0.01957857 0.01402669 0.07121323 0.01118776\n",
      "  0.02308351 0.06342543 0.03340315 0.01355358 0.03253087 0.01437202\n",
      "  0.0199114  0.03253289 0.03576468 0.04456908 0.06257108 0.01073706\n",
      "  0.02466473 0.06307969 0.01074725 0.02500981]\n",
      " [0.74784242 0.93337983 0.56194585 1.1387228  2.77667908 0.7097284\n",
      "  0.68258994 0.63234574 0.52582881 3.09302605 1.6154492  0.53058039\n",
      "  0.81639932 0.64178598 0.47039574 0.78699721 1.46309904 1.01928785\n",
      "  0.67854536 3.74452988 1.24845682 0.86647564 0.57092661 0.73890589\n",
      "  0.70112161 2.089787   0.49268261 0.76843112 0.73248607 0.69323181\n",
      "  0.55729879 0.92865689 0.58919657 0.47744252 0.56012146 0.75484081\n",
      "  0.84843792 0.6301169  1.00745344 1.24845682 1.14456547 0.60952567\n",
      "  0.88232217 0.66139077 0.89191678 1.16402106 0.96451941 0.58781391\n",
      "  1.1445123  0.52414154 0.92748669 0.58094429 0.99292493 0.35795072\n",
      "  0.76472784 0.63115194 0.69547099 0.37982557 0.63569523 0.42988484\n",
      "  0.6561173  1.23618611 1.30340068 0.77724344 2.1845971  0.61841133\n",
      "  1.08337922 0.97127203 0.39638009 0.74153978]]\n",
      "0.74784241948925\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #1\n",
      "[[0.0290279  0.03134925 0.06406524 0.03114243 0.02619876 0.05179254\n",
      "  0.04700406 0.04629059 0.04048817 0.10362497 0.03346979 0.02525052\n",
      "  0.0339496  0.03005749 0.06858152 0.03278578 0.02623149 0.0581685\n",
      "  0.03962259 0.08456688 0.03438621 0.08766528 0.02965163 0.07036958\n",
      "  0.06660334 0.06261629 0.03406044 0.02864727 0.02261169 0.03629968\n",
      "  0.05582614 0.04032407 0.05475679 0.03006036 0.02213871 0.0273674\n",
      "  0.01684871 0.04764051 0.02159939 0.03438621 0.02092795 0.04129279\n",
      "  0.0283501  0.07804368 0.0145604  0.03703047 0.03801395 0.03480031\n",
      "  0.02723123 0.04045066 0.03195904 0.02974983 0.05181434 0.03194266\n",
      "  0.03029922 0.1099366  0.040333   0.0266974  0.03807813 0.03664296\n",
      "  0.03408931 0.02521102 0.03517682 0.0398591  0.04804176 0.02249332\n",
      "  0.03653403 0.06495254 0.0278554  0.04613885]\n",
      " [0.99953887 1.1322818  0.86625447 1.33256089 1.341922   0.68077313\n",
      "  0.89364453 0.77033553 0.88924248 3.48411818 1.28272295 1.15395019\n",
      "  1.28371116 0.75020354 1.53152405 1.07811065 1.54298154 1.11374751\n",
      "  1.40028286 1.59265382 1.21291625 2.78444748 1.10147595 1.11334607\n",
      "  0.63963911 1.44260875 0.89651882 1.24193186 1.1860505  1.93530406\n",
      "  0.94643278 1.06407633 1.18073323 0.70879409 1.07983948 1.2400771\n",
      "  1.22378101 1.4480023  1.2568214  1.21291626 1.06241106 0.66055107\n",
      "  1.95503875 3.21454523 1.20771929 1.6889788  1.16525907 1.24376944\n",
      "  1.03359438 1.8418482  1.47440668 1.15154072 0.85876276 1.34582348\n",
      "  1.41233994 1.20268689 0.8047979  1.1060024  0.85023337 1.15780292\n",
      "  1.17868564 0.7921262  1.23056339 1.53276619 1.02978095 1.4752808\n",
      "  1.86338419 3.06846052 1.66922565 1.59859927]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #2\n",
      "[[0.04617132 0.04882826 0.07914171 0.03671909 0.04660308 0.07694571\n",
      "  0.09552059 0.04117624 0.03354474 0.0927297  0.03386893 0.04794319\n",
      "  0.04020825 0.03357931 0.06212175 0.043067   0.03695519 0.04762246\n",
      "  0.02821658 0.11591855 0.0424408  0.10293761 0.02550744 0.07441403\n",
      "  0.09226236 0.07604382 0.05971597 0.02138451 0.03330291 0.03678837\n",
      "  0.068943   0.07480775 0.06140505 0.0438715  0.03430547 0.02327904\n",
      "  0.01716721 0.04299849 0.02376937 0.0424408  0.0303532  0.06040894\n",
      "  0.02451993 0.08439683 0.01512538 0.02907252 0.03827376 0.06365603\n",
      "  0.04291312 0.03247252 0.02522005 0.0213349  0.07291534 0.02598144\n",
      "  0.02551754 0.09648207 0.05542684 0.04407398 0.04004735 0.0276366\n",
      "  0.03065388 0.05435245 0.04960502 0.05829525 0.0834752  0.01503789\n",
      "  0.04453653 0.05751107 0.02248569 0.0560633 ]\n",
      " [1.07859079 1.78735798 0.95778187 1.18996983 1.83159278 1.30597317\n",
      "  1.13230083 0.72058297 0.67833655 3.32989378 1.37811607 1.31936071\n",
      "  1.23473678 0.8192535  0.71651085 1.00090965 1.30943624 1.55687043\n",
      "  0.76683325 1.83111406 1.30069963 1.20812977 0.76416702 0.95377618\n",
      "  0.90270284 2.05217885 1.41513538 0.83782358 0.98064071 0.72820309\n",
      "  1.00016932 1.35152362 0.98484972 1.19422645 0.87177422 0.70186378\n",
      "  0.94715615 0.84241156 1.0807745  1.30069962 1.62458298 0.88217671\n",
      "  0.92635709 0.79204841 0.89870386 1.15082871 1.13349555 1.36868156\n",
      "  1.16994384 0.6740789  1.03604534 0.8396127  2.12110645 0.701354\n",
      "  0.82591569 0.89614497 1.12860471 1.29636583 0.85612311 0.67827769\n",
      "  0.77415859 1.19302964 1.51339933 0.95845176 1.57799719 0.69606477\n",
      "  1.35042236 1.16914622 0.7520464  1.46464905]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #3\n",
      "[[0.01388356 0.02778142 0.04343749 0.02310683 0.02592443 0.04814566\n",
      "  0.06806854 0.02821216 0.01369912 0.08619824 0.02915859 0.02579149\n",
      "  0.01636381 0.03137753 0.04776919 0.02776066 0.02974948 0.03902886\n",
      "  0.01817592 0.08753313 0.0229583  0.07461903 0.01609634 0.03697108\n",
      "  0.06555733 0.07314781 0.03514756 0.00871842 0.02057108 0.03042366\n",
      "  0.0465832  0.03746294 0.03664137 0.02579555 0.00973449 0.01488558\n",
      "  0.01076359 0.02217749 0.01234885 0.0229583  0.01754962 0.03814443\n",
      "  0.02486801 0.06505802 0.01009972 0.02725969 0.03270069 0.02928384\n",
      "  0.028365   0.02537092 0.01847626 0.00955327 0.05037782 0.01116068\n",
      "  0.01625011 0.0524863  0.0328402  0.02890133 0.02690554 0.014122\n",
      "  0.02106754 0.02660421 0.03046835 0.02887768 0.0643969  0.01458742\n",
      "  0.02375895 0.05319163 0.01363841 0.02977185]\n",
      " [0.47600592 1.43699201 0.95216587 1.13413639 1.08258217 0.74107416\n",
      "  1.15034525 0.57091887 0.4481109  3.18572962 1.61470932 1.02000859\n",
      "  0.57460319 1.17786711 0.93345738 0.84589517 1.94321668 1.37794645\n",
      "  0.69693443 4.23059725 1.09206839 2.50089166 0.52240058 0.55810237\n",
      "  1.29207074 2.28562156 1.02472352 0.42961061 0.94711372 1.5215259\n",
      "  0.76790251 0.83029797 0.74344301 1.09872084 0.47996087 0.5662142\n",
      "  0.6915241  0.7015174  0.89890632 1.09206839 0.79042935 0.86396371\n",
      "  1.40849894 2.47736887 0.7760316  1.66345716 1.18649236 1.27686398\n",
      "  1.09472004 0.85293142 1.09060095 0.42845893 0.60088101 0.4310202\n",
      "  0.6998018  0.67610579 0.83669931 1.32174958 1.21778252 0.44049742\n",
      "  0.7755559  1.16273041 1.2092028  1.09952666 2.13332547 1.01139213\n",
      "  1.05039818 2.79405578 0.75954645 0.82182862]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #4\n",
      "[[0.04031164 0.01934687 0.04447872 0.01534831 0.01513936 0.033554\n",
      "  0.05547906 0.03081035 0.02732998 0.0816389  0.02036579 0.0279729\n",
      "  0.02099587 0.02640397 0.04775079 0.02087618 0.02247612 0.03573165\n",
      "  0.01728624 0.05027124 0.01614048 0.08293792 0.01660503 0.0299245\n",
      "  0.04433263 0.06309482 0.03241952 0.01775811 0.01052359 0.02612007\n",
      "  0.04651571 0.03515602 0.03440541 0.02230146 0.01717441 0.01287684\n",
      "  0.01391524 0.02702761 0.00785389 0.01614048 0.01289403 0.04029391\n",
      "  0.02638785 0.070632   0.00827424 0.02958219 0.02350063 0.02972367\n",
      "  0.02063528 0.01927624 0.01137274 0.01316674 0.05601844 0.01227829\n",
      "  0.01674637 0.06387944 0.03319451 0.02274341 0.02979205 0.01823355\n",
      "  0.01375535 0.02811324 0.03470561 0.03462732 0.06431328 0.01193848\n",
      "  0.03495044 0.05207074 0.01679136 0.03275775]\n",
      " [0.82304374 0.64243765 0.66283519 0.62577673 0.53883126 0.46323986\n",
      "  0.6799578  0.51700685 0.60465175 1.93841162 0.91294343 0.81006388\n",
      "  0.76972073 0.80239347 0.77161016 0.64961615 1.4177394  0.99100838\n",
      "  0.64825109 0.84496779 0.63042007 3.26686243 0.45470422 0.4011798\n",
      "  0.58130875 1.60651759 0.80426546 0.6156679  0.53258855 1.09750387\n",
      "  0.60267873 0.62389859 0.55801877 0.59530948 0.57418982 0.4465388\n",
      "  1.05332975 0.822639   0.46984111 0.63042008 0.55395886 0.51443329\n",
      "  1.48840763 3.09068685 0.6673057  0.88867462 0.59940646 0.68238866\n",
      "  0.66947883 0.58399414 0.57391701 0.7982562  1.71788199 0.44326457\n",
      "  0.77941309 0.70400507 0.78307565 0.71179624 1.70205789 0.55386568\n",
      "  0.42689575 0.76273261 1.05548243 1.57704393 0.8167325  0.77745521\n",
      "  1.05144609 2.18889024 0.95490984 0.91062887]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #5\n",
      "[[0.04618965 0.03679134 0.0689874  0.03598038 0.03577303 0.1034628\n",
      "  0.1088016  0.07160206 0.0453805  0.09909644 0.03775595 0.03950601\n",
      "  0.04859857 0.05968734 0.09977419 0.05880828 0.02964595 0.04606924\n",
      "  0.05139089 0.13613597 0.034579   0.09543179 0.04478519 0.06356553\n",
      "  0.12574345 0.0861421  0.0554361  0.03307324 0.03361306 0.04909489\n",
      "  0.08679508 0.05445952 0.08593715 0.04807502 0.02959285 0.0352535\n",
      "  0.01975046 0.05202472 0.0219806  0.034579   0.02591664 0.07651369\n",
      "  0.03936694 0.09210577 0.02064375 0.02964631 0.06043618 0.04959658\n",
      "  0.03776114 0.05203985 0.03337364 0.03358328 0.12085448 0.03736048\n",
      "  0.03694848 0.09698683 0.05672549 0.04860097 0.05924451 0.05222714\n",
      "  0.05112602 0.03727484 0.04633789 0.07297941 0.09029571 0.02960666\n",
      "  0.0439069  0.08694991 0.03034272 0.05644071]\n",
      " [1.02932243 1.27187169 0.72438204 1.21644597 1.47025832 1.55409834\n",
      "  1.22138688 1.51443381 1.29340725 3.11440046 1.2510177  1.31689186\n",
      "  1.06887029 2.00371605 1.05999576 1.55975803 1.3102508  0.66972796\n",
      "  1.49788872 1.3228206  1.2252293  2.29966046 1.69213738 0.8006209\n",
      "  1.80974753 1.54558956 1.13670814 1.05062554 0.99626877 1.69995868\n",
      "  1.24398128 1.16506268 1.4550233  0.91343062 1.15213228 0.97502521\n",
      "  0.9093395  1.0373391  0.91038361 1.2252293  0.89633528 1.50898682\n",
      "  1.3496118  2.29653033 1.22199572 1.37930394 1.92403707 1.25623031\n",
      "  1.00103805 1.08724972 1.10337322 1.08274481 1.02853204 1.10915623\n",
      "  1.33598738 0.75668176 1.71419986 1.30904446 1.07607877 1.12305093\n",
      "  1.21770946 0.97731564 1.35900225 1.00362195 1.25215621 1.46624018\n",
      "  1.28869995 1.17646819 1.28233966 1.28655862]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #6\n",
      "[[0.02507515 0.04551409 0.06984097 0.02965268 0.03516862 0.04984685\n",
      "  0.03985277 0.03788314 0.03445968 0.09536869 0.03857598 0.03403763\n",
      "  0.03405509 0.03521375 0.05176777 0.03570832 0.03622501 0.07538937\n",
      "  0.02233006 0.09288411 0.03436764 0.08407901 0.02255105 0.06103999\n",
      "  0.0670494  0.08335399 0.05188441 0.01676736 0.02817255 0.03079926\n",
      "  0.03437299 0.06182785 0.04140502 0.04189526 0.01453918 0.025584\n",
      "  0.01712149 0.04210966 0.02204134 0.03436764 0.03155624 0.04038726\n",
      "  0.02882739 0.06961454 0.01524633 0.03257026 0.03688032 0.0488392\n",
      "  0.0362736  0.03312162 0.02525888 0.01945037 0.10143038 0.02153343\n",
      "  0.02578831 0.07954466 0.03429408 0.03676921 0.04391778 0.02112308\n",
      "  0.02881441 0.03249931 0.04126329 0.05153619 0.07804146 0.01568682\n",
      "  0.03345707 0.06656362 0.01767968 0.05146189]\n",
      " [0.74996984 1.55213375 0.86456973 1.15762775 2.05032436 0.79566027\n",
      "  0.64236055 0.80900485 0.97175525 3.20499217 1.78276438 1.65263942\n",
      "  1.0411395  1.18273419 0.75295836 0.99683559 1.65739484 1.18917703\n",
      "  0.8135992  3.24308178 1.40913982 2.58058698 0.8881551  0.87489787\n",
      "  1.09895505 2.13817832 1.48891012 0.71961429 1.08178652 1.34482608\n",
      "  0.57754262 2.21036838 0.77002279 0.92513352 0.70166152 0.88494662\n",
      "  1.03141931 0.87060342 1.16431196 1.40913982 1.33727559 0.87335104\n",
      "  1.50628924 2.43560692 1.09309451 2.0453507  1.3869248  1.47983209\n",
      "  1.22442328 0.89281528 1.16330977 0.84068743 1.15168712 0.74091521\n",
      "  0.99311292 0.77244555 1.00093942 1.41317777 0.70366696 0.65418266\n",
      "  0.93840827 1.12305855 1.4655639  0.88677738 2.2171837  0.92871346\n",
      "  1.29933957 0.86315197 0.83434579 1.33760727]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #7\n",
      "[[0.02224319 0.02956889 0.07521608 0.0349967  0.04161164 0.04170668\n",
      "  0.05151834 0.03601145 0.0230876  0.09680182 0.03964782 0.0366444\n",
      "  0.03756352 0.03296811 0.05022951 0.03605918 0.03239077 0.06056425\n",
      "  0.02129091 0.10140469 0.03395218 0.08604521 0.02533437 0.06073592\n",
      "  0.06943258 0.08807067 0.03881992 0.01799499 0.0300145  0.03104261\n",
      "  0.04277915 0.06276686 0.04139786 0.0496163  0.01498366 0.0258168\n",
      "  0.01959232 0.04481149 0.02334351 0.03395218 0.03646905 0.04587966\n",
      "  0.02545847 0.06650205 0.01650383 0.03192165 0.03699985 0.05123235\n",
      "  0.03931723 0.03535899 0.02662432 0.02059713 0.0808546  0.02408939\n",
      "  0.02658587 0.09023612 0.03417215 0.04101145 0.03742196 0.02417525\n",
      "  0.03248226 0.03544504 0.04664648 0.04412965 0.0780485  0.01567592\n",
      "  0.03437728 0.07899168 0.01664371 0.0552722 ]\n",
      " [0.69307245 1.39929302 0.91036531 1.39192812 4.0429866  0.5443946\n",
      "  0.98407895 0.51326788 0.52113692 3.23229232 1.77914279 2.02024579\n",
      "  1.38885568 0.886768   0.61544425 0.89558546 1.82589332 2.06624357\n",
      "  0.73315862 4.88515351 1.3675159  2.53465571 0.84816786 0.85668988\n",
      "  1.14426548 2.37808908 1.16247587 0.78399982 1.13693451 0.96808623\n",
      "  0.66981952 2.37745801 0.79990524 1.61447505 0.63451264 0.8207786\n",
      "  1.25001954 0.98070456 1.09489453 1.3675159  1.72706153 0.77467998\n",
      "  0.91277787 1.85925722 1.17553861 1.74342668 1.1404034  2.06887689\n",
      "  1.26003626 0.97871967 1.06692974 0.84354863 1.95299368 0.70812822\n",
      "  0.99614712 1.11564605 1.01352953 1.61721668 0.75465869 0.61506262\n",
      "  0.90555331 1.67387972 2.0006254  1.6050477  2.52974737 0.74939434\n",
      "  1.28138494 0.88449641 0.85012748 1.92226917]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #8\n",
      "[[0.03490027 0.02860622 0.03687595 0.02864832 0.02328102 0.06536485\n",
      "  0.0816183  0.04049306 0.02575955 0.08877926 0.02761631 0.02944445\n",
      "  0.02882502 0.0241457  0.06491454 0.03250513 0.02176658 0.03832838\n",
      "  0.02653085 0.08368289 0.02752395 0.0734602  0.02753221 0.04345699\n",
      "  0.07278191 0.06025989 0.04321156 0.01952645 0.02345013 0.03037347\n",
      "  0.06766242 0.04992069 0.03141513 0.03071756 0.02806126 0.0210547\n",
      "  0.01282471 0.03669751 0.01638737 0.02752395 0.02224104 0.05198721\n",
      "  0.02592987 0.07055594 0.01240051 0.03219048 0.03932681 0.0370358\n",
      "  0.04060696 0.03340247 0.02068913 0.01650521 0.04710951 0.0217326\n",
      "  0.02221245 0.06641112 0.03038433 0.03070159 0.03060243 0.02764348\n",
      "  0.02565891 0.02457893 0.03353535 0.0314234  0.05988305 0.01507587\n",
      "  0.03049591 0.0495239  0.02131131 0.03973515]\n",
      " [0.91311553 0.97363269 0.50137156 0.95261408 0.76760947 1.23926483\n",
      "  1.15168432 1.1929392  0.9248914  3.41303088 0.98850184 1.04403182\n",
      "  0.9397166  0.59488133 1.10884026 1.02970666 1.0067237  0.72991014\n",
      "  1.04111578 0.95316336 0.82192444 2.1509528  0.98006101 0.66080896\n",
      "  0.67260301 0.96288791 1.05191165 0.90709586 1.06844984 1.24784991\n",
      "  1.01828056 0.72999004 0.56902905 0.80011318 0.80787516 0.85699305\n",
      "  0.87071323 1.06489139 0.89993167 0.82192442 0.88891858 1.68723995\n",
      "  1.19572247 2.58073776 0.8938905  1.63046431 1.5337917  0.85408295\n",
      "  0.93554821 1.00188884 0.87590291 0.90191362 0.63011737 0.72492525\n",
      "  1.06934097 0.76711927 0.66033198 0.95872079 0.80805225 0.69286505\n",
      "  0.83099838 0.82821902 1.47483978 1.08481903 0.76644569 0.80229906\n",
      "  0.95819278 1.03518801 1.01043003 1.08252818]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #9\n",
      "[[0.03495299 0.02141155 0.03896215 0.01381923 0.01892191 0.05389276\n",
      "  0.05422404 0.02323023 0.01628292 0.08586686 0.02328023 0.02118649\n",
      "  0.01220827 0.02884922 0.03526972 0.02033553 0.01729611 0.02536465\n",
      "  0.01995799 0.08608381 0.01798642 0.07125525 0.01285768 0.03252906\n",
      "  0.06048957 0.05989951 0.02775347 0.00881799 0.01200938 0.02533053\n",
      "  0.0385754  0.02376203 0.03397969 0.01759486 0.00836254 0.00947764\n",
      "  0.00983803 0.0124291  0.00518042 0.01798642 0.01682308 0.02585168\n",
      "  0.02107489 0.03725487 0.00681349 0.0219454  0.02702008 0.03059787\n",
      "  0.02405036 0.01958595 0.01031665 0.00915473 0.02982729 0.00947752\n",
      "  0.01516563 0.04416599 0.03833743 0.02163013 0.02638325 0.0120025\n",
      "  0.01391149 0.03035934 0.03073731 0.02471894 0.04607488 0.0093527\n",
      "  0.01666392 0.05458466 0.01218517 0.02829683]\n",
      " [0.84756513 0.74067041 0.57928542 0.50096109 0.67316432 0.66714983\n",
      "  0.97971444 0.4246302  0.46220845 3.44169433 0.99519315 0.67221594\n",
      "  0.4039816  0.67166249 0.49550999 0.67887765 0.83564484 0.57165537\n",
      "  0.76548549 0.73364802 0.59505837 2.12068502 0.42428199 0.44095413\n",
      "  0.9509022  0.85377069 0.60626961 0.41426384 0.52140169 1.01041163\n",
      "  0.81957204 0.43519483 0.58696381 0.41363948 0.40131191 0.37966433\n",
      "  0.60576681 0.32112618 0.30021487 0.59505837 0.84816064 0.60404699\n",
      "  1.14250471 0.53922103 0.52167564 1.04589691 0.89969233 0.6650188\n",
      "  0.60588576 0.58978059 0.50030899 0.43997073 0.4762097  0.33860569\n",
      "  0.69667851 0.49846303 0.85647591 0.66494828 0.55852932 0.35676313\n",
      "  0.45989314 0.70415193 1.25139961 0.79976373 0.62181566 0.5274974\n",
      "  0.57114165 0.80188375 0.62043261 0.77846275]]\n",
      "=========================================================================================\n",
      "Starting Pattern 2\n",
      "=========================================================================================\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #0\n",
      "[[0.04752649 0.10238717 0.07422103 0.0366211  0.03346945 0.08002116\n",
      "  0.08730245 0.05381965 0.03167621 0.11082682 0.04866279 0.04603896\n",
      "  0.04263838 0.0303886  0.08451157 0.04337989 0.0289828  0.10163617\n",
      "  0.03264057 0.16394489 0.03972785 0.0886044  0.02920722 0.08113839\n",
      "  0.06484258 0.11683127 0.05697379 0.02906315 0.03536793 0.04718063\n",
      "  0.06877427 0.06722913 0.04586153 0.05228016 0.03090112 0.0295634\n",
      "  0.01925322 0.10095115 0.02533347 0.03972785 0.04299506 0.0684916\n",
      "  0.03513558 0.05206653 0.01771123 0.03189367 0.03737609 0.0584864\n",
      "  0.04437693 0.04801639 0.03505225 0.03183217 0.13687945 0.02906813\n",
      "  0.03183292 0.10551893 0.05165738 0.0401639  0.0623     0.03936108\n",
      "  0.04679833 0.04512387 0.04121443 0.0685515  0.1064164  0.02355352\n",
      "  0.04184916 0.08747403 0.02440062 0.06999698]\n",
      " [0.96317507 3.63224158 1.03384763 1.14950545 1.18491809 0.75192398\n",
      "  1.21864839 0.65350051 0.68595088 4.25052197 1.43047007 1.2920108\n",
      "  1.13044208 0.59581865 1.50064428 1.00560445 1.00422162 1.24837167\n",
      "  0.83071962 1.21559639 1.10405915 1.45974777 0.64050793 1.42184026\n",
      "  0.6963725  1.57139267 1.19989849 1.06218148 1.15293247 1.0153599\n",
      "  1.05887165 1.08830376 0.63570702 1.36387326 0.78044164 1.08762612\n",
      "  1.08060243 2.42240398 1.24514291 1.10405915 1.31526818 0.75670623\n",
      "  1.10985695 0.56351271 1.16921586 1.27448323 0.78662696 1.20030308\n",
      "  0.88260801 1.13389969 1.13288659 1.07991029 1.28081887 0.77502038\n",
      "  1.24240535 1.42399657 0.85299577 1.00835291 0.97626343 0.75399374\n",
      "  1.09100461 0.89694776 1.09612574 0.99889883 1.35435946 1.02593726\n",
      "  1.09293702 1.04884814 1.02943123 1.59813067]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #1\n",
      "[[0.02769741 0.09868635 0.08074674 0.02365073 0.02815579 0.07667933\n",
      "  0.07077528 0.04947915 0.03742047 0.09178314 0.03871813 0.02815843\n",
      "  0.03032813 0.03979895 0.05660281 0.03192184 0.0348585  0.03947482\n",
      "  0.04335423 0.09591224 0.0219657  0.06452016 0.02554479 0.08300144\n",
      "  0.08997214 0.07981249 0.03585065 0.0208201  0.02903913 0.05212747\n",
      "  0.05413084 0.04751178 0.04726477 0.0366621  0.017232   0.02960252\n",
      "  0.01786797 0.09494285 0.02189377 0.0219657  0.03703053 0.04602481\n",
      "  0.03178289 0.07301732 0.01738249 0.02672031 0.03869828 0.041035\n",
      "  0.03105429 0.0390721  0.02394409 0.02270684 0.05352538 0.0249708\n",
      "  0.0300278  0.08976549 0.04621852 0.02493119 0.06429789 0.02689944\n",
      "  0.04076904 0.0250162  0.03275743 0.03366894 0.05623671 0.02522208\n",
      "  0.01947163 0.06676815 0.01927732 0.04169787]\n",
      " [0.69037365 3.4627807  0.96715974 0.80445772 1.07473837 3.1165326\n",
      "  2.65373085 1.56579211 1.25752107 2.73137497 1.37206649 0.9752052\n",
      "  0.91974339 1.7185655  0.67155207 1.05368829 1.59494376 0.77292628\n",
      "  1.72935956 3.1656905  0.74251025 1.8047198  1.01174915 0.94643815\n",
      "  3.22901937 1.3690579  0.81484013 0.72328473 1.12033284 2.03911208\n",
      "  1.72413491 0.85853674 1.30691364 0.85765352 1.08559214 1.13570684\n",
      "  1.16170373 2.43155429 1.02901479 0.74251026 1.97974126 1.96757364\n",
      "  1.81532827 2.2797977  1.17646094 1.21958999 1.57550626 1.04111838\n",
      "  0.80662212 0.98455056 0.97986325 0.96224674 0.99023123 0.83652733\n",
      "  1.34107929 0.93324288 1.78586541 0.84140192 2.35955212 0.98012497\n",
      "  1.37644597 0.79404167 1.28499429 1.11266591 0.86360078 1.61630701\n",
      "  0.67981331 2.65570466 0.95930597 1.04986133]]\n",
      "0.6903736509240007\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #2\n",
      "[[0.06395471 0.0791069  0.06257275 0.0196337  0.01936932 0.06290319\n",
      "  0.06748681 0.02567404 0.02373026 0.10126117 0.02286389 0.02871936\n",
      "  0.02995933 0.02012566 0.06526777 0.01863311 0.02207091 0.04023458\n",
      "  0.03102898 0.11359595 0.01622676 0.07124595 0.01778745 0.05747758\n",
      "  0.06677275 0.08883151 0.02992706 0.01872794 0.01632575 0.05245891\n",
      "  0.05370651 0.04085576 0.03329761 0.02260737 0.0250524  0.01356424\n",
      "  0.015656   0.09852611 0.01248329 0.01622676 0.02029351 0.04870739\n",
      "  0.02454055 0.06961461 0.01089863 0.03557412 0.02055059 0.03711785\n",
      "  0.02354819 0.02260355 0.01887819 0.01331845 0.07376129 0.01829522\n",
      "  0.02175789 0.10504715 0.03422339 0.03452634 0.05123277 0.01957469\n",
      "  0.02638709 0.02761762 0.03324964 0.03333882 0.06442672 0.01846393\n",
      "  0.02749241 0.04956277 0.019204   0.04337283]\n",
      " [0.95783937 2.48727859 0.82458108 0.78946682 0.6072199  0.70721595\n",
      "  0.88698054 0.46653777 0.48389609 3.18103248 0.88668757 1.05028428\n",
      "  0.91408947 0.55147641 0.82464365 0.55957967 1.1363178  1.20699599\n",
      "  1.13292988 0.92366226 0.63598965 2.24839731 0.52863354 0.80683216\n",
      "  0.75032499 2.34228954 0.6481263  0.72378289 0.84258194 2.1409177\n",
      "  0.65873281 0.65183754 0.65743792 0.63150856 0.73081211 0.51379403\n",
      "  0.85261587 2.73408694 0.65273051 0.63598966 0.8762309  0.67864627\n",
      "  0.84744325 2.17793601 0.76362552 1.07059388 0.58705945 0.82579385\n",
      "  0.68480442 0.62186647 0.82535793 0.61025935 1.24695563 0.61815987\n",
      "  0.96713902 1.05223529 0.90183967 0.88077598 1.08378553 0.56617831\n",
      "  0.88160176 0.98573408 1.03314688 1.18757262 0.76463296 1.11050384\n",
      "  0.90201829 0.70937902 1.0109544  1.07468498]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #3\n",
      "[[0.03334613 0.11770098 0.11104475 0.03774827 0.0422087  0.03737136\n",
      "  0.06256102 0.03576397 0.02715752 0.10306363 0.0449812  0.04866509\n",
      "  0.03919865 0.02765623 0.07391108 0.03573132 0.03713681 0.06374221\n",
      "  0.03004045 0.11780331 0.03885009 0.08243503 0.02133989 0.08786814\n",
      "  0.04973697 0.11499721 0.06625456 0.02375098 0.03139407 0.05017992\n",
      "  0.04197574 0.07140878 0.04040856 0.05913457 0.01596445 0.02821803\n",
      "  0.02167475 0.09768281 0.02623715 0.03885009 0.04777138 0.03190394\n",
      "  0.03090468 0.06703187 0.01721642 0.02402265 0.03350475 0.07093174\n",
      "  0.03925124 0.04016929 0.02964792 0.02694256 0.08872224 0.03102113\n",
      "  0.02909482 0.13519614 0.03268174 0.0434013  0.04743848 0.02556154\n",
      "  0.03743632 0.04507671 0.04369661 0.05817877 0.10649357 0.02199895\n",
      "  0.03962958 0.05699935 0.02874867 0.06989508]\n",
      " [1.1940612  5.84683509 1.14203624 1.42678129 4.1674373  0.5241048\n",
      "  1.22831537 0.55006448 0.54483472 3.32769418 2.10433384 2.70053687\n",
      "  1.37498574 0.81150027 0.69171065 0.97166071 2.12753746 1.8539021\n",
      "  0.99039809 4.95548389 1.46243903 2.32248831 0.56721173 1.2857496\n",
      "  0.77625436 3.10751128 2.58915225 0.83864474 1.22006031 1.59616357\n",
      "  0.59992915 2.64196857 0.78237612 1.94086516 0.69547448 0.89687646\n",
      "  1.27323851 2.3314974  1.4754999  1.46243903 2.37077862 0.60666995\n",
      "  1.2299921  0.93723428 1.10564085 1.49036115 1.02199169 2.72264435\n",
      "  1.1995568  1.18859159 1.19097208 1.0903583  2.25620522 0.85458139\n",
      "  1.03346103 1.1075635  0.88326503 1.63252109 0.67049721 0.67789952\n",
      "  1.07457232 1.59326927 1.74394449 0.86229644 3.06882622 1.03411994\n",
      "  1.37155923 0.80425683 0.90969253 2.0789413 ]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #4\n",
      "[[0.01864795 0.09460574 0.08340112 0.02214334 0.02863152 0.06089886\n",
      "  0.06554704 0.04649318 0.03185986 0.09829307 0.03297765 0.04071407\n",
      "  0.02492843 0.03053069 0.05818419 0.03055939 0.02504455 0.0363352\n",
      "  0.02877626 0.08964758 0.02188263 0.06996591 0.02213763 0.04805179\n",
      "  0.06045774 0.0844787  0.03188042 0.01548687 0.02086318 0.05634017\n",
      "  0.05250005 0.04593844 0.04122693 0.02270355 0.01904039 0.01912807\n",
      "  0.01462028 0.08565881 0.01690802 0.02188263 0.02421683 0.04359708\n",
      "  0.02038867 0.08403813 0.01183358 0.0226485  0.02800832 0.05387824\n",
      "  0.03088304 0.02961164 0.01880293 0.01204276 0.05292858 0.02597074\n",
      "  0.02206532 0.08323963 0.05227508 0.02639521 0.04253238 0.02290088\n",
      "  0.03031063 0.02724572 0.0205296  0.08302734 0.07213085 0.02036163\n",
      "  0.01861354 0.08629159 0.01709091 0.03521013]\n",
      " [0.57405476 4.78094342 0.86179033 0.76899276 2.12717074 0.64689548\n",
      "  0.68127121 0.5837738  0.67515358 2.60506716 1.16427827 1.62463715\n",
      "  0.71712709 0.76298305 0.61469351 0.70512861 1.22565692 0.58088239\n",
      "  0.79559519 2.9141624  0.68902004 0.83362514 0.49633103 0.69732646\n",
      "  0.70574254 2.39234397 1.01714672 0.49644624 0.79402771 0.7326871\n",
      "  0.61985604 1.78842467 0.5816947  0.55900637 0.60326683 0.54382263\n",
      "  0.6026609  1.61061765 0.88056025 0.68902004 0.99844082 0.66012738\n",
      "  0.56522656 0.81162263 0.74918981 0.93979989 0.58729404 2.38582409\n",
      "  0.87886019 0.59196084 0.60181538 0.46571718 0.62410078 0.65608173\n",
      "  0.7023839  0.67806061 0.93702017 0.79644868 0.67266578 0.54205226\n",
      "  0.8164455  1.05373819 0.75492088 0.90068788 1.98921476 0.92475738\n",
      "  0.55065964 0.88035117 0.56617944 0.7989951 ]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #5\n",
      "[[0.03745527 0.09102642 0.06695685 0.01950929 0.02688775 0.06235152\n",
      "  0.07326408 0.04490112 0.02366631 0.09590952 0.03400335 0.03727726\n",
      "  0.02798906 0.02981626 0.06580598 0.02050032 0.02371502 0.05591267\n",
      "  0.04609635 0.13730241 0.02777788 0.06494421 0.02024142 0.04714441\n",
      "  0.07919384 0.08582132 0.03906842 0.01923942 0.02067093 0.05398503\n",
      "  0.04354714 0.04894939 0.03917943 0.02976816 0.01489763 0.01512609\n",
      "  0.00907539 0.10185565 0.01298782 0.02777788 0.02620796 0.04039485\n",
      "  0.02503461 0.07175217 0.00972481 0.03091659 0.02601784 0.05181746\n",
      "  0.03543675 0.02463061 0.0168188  0.01596658 0.08951707 0.01855211\n",
      "  0.02020949 0.05764459 0.0489522  0.03305526 0.05468246 0.02006986\n",
      "  0.02667851 0.03337591 0.02407857 0.0314836  0.0841811  0.02133889\n",
      "  0.03181024 0.06600912 0.02106213 0.04530549]\n",
      " [1.0259986  3.74393536 0.86514725 0.81881099 1.20184586 0.88099037\n",
      "  1.24641574 0.78778509 0.63987403 2.87014574 1.15811156 1.57266188\n",
      "  1.1480337  0.85066969 0.99581817 0.68606437 1.38410114 1.12644721\n",
      "  1.94164528 1.24965224 1.0421498  1.67489676 0.6622961  0.68879454\n",
      "  1.22885662 1.47585223 1.1334385  0.69165204 0.83645674 2.61906611\n",
      "  0.69177879 1.00704835 0.78309306 0.99586238 0.72669289 0.61266385\n",
      "  0.53269852 2.99570429 0.79587872 1.0421498  1.22750305 0.77562022\n",
      "  1.45900429 2.72060649 0.70795195 1.126308   0.82006295 1.70509923\n",
      "  1.02173776 0.65488327 0.93712908 0.65513848 1.1366036  0.90913313\n",
      "  0.9839932  0.61173173 1.28456094 1.1395424  1.29530698 0.66825083\n",
      "  1.05799734 1.06419762 0.86115606 1.01076165 1.30793567 1.37742545\n",
      "  1.18665583 2.64572221 1.25392012 1.35705373]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #6\n",
      "[[0.03092818 0.08828733 0.07426831 0.01653164 0.0269574  0.0716144\n",
      "  0.07870784 0.04452074 0.02495456 0.0907337  0.0315389  0.03294277\n",
      "  0.02077656 0.02876823 0.07001805 0.01802264 0.0268088  0.03417312\n",
      "  0.02579445 0.09462038 0.02312532 0.06108405 0.01733283 0.05313471\n",
      "  0.07123242 0.07374279 0.02981239 0.01834172 0.01712936 0.04936722\n",
      "  0.0582216  0.03289006 0.04504277 0.02161015 0.02364364 0.01798173\n",
      "  0.01419295 0.09265586 0.01185875 0.02312532 0.02046078 0.03678499\n",
      "  0.02451417 0.06352448 0.00653934 0.02423433 0.02902689 0.0422652\n",
      "  0.03385805 0.02005138 0.01404462 0.00849174 0.04293392 0.01617469\n",
      "  0.02017488 0.10016394 0.04236162 0.02736319 0.06239822 0.02136425\n",
      "  0.02479781 0.02377154 0.01806133 0.02678414 0.05484201 0.01854207\n",
      "  0.02789841 0.05988635 0.01324702 0.03852614]\n",
      " [0.99888988 4.11793436 0.91942176 0.74893004 1.51469056 2.8531316\n",
      "  0.88707537 1.4924718  0.75873765 2.94083078 1.20120332 1.44908871\n",
      "  0.63878845 1.01820783 0.79147316 0.62827686 1.55848406 0.77126574\n",
      "  0.80097941 0.90527318 0.92949283 2.20565453 0.54896577 0.92239518\n",
      "  1.45279099 1.72123207 0.87334807 0.62973741 0.64634173 1.99927453\n",
      "  0.7348193  0.86836886 1.24514119 0.76019711 0.80335129 0.59364391\n",
      "  0.70421793 2.37319393 0.61976378 0.92949283 0.82924648 1.10528237\n",
      "  0.74163332 1.92115274 0.45743307 1.84434749 0.8773007  1.01767294\n",
      "  0.92098243 0.51784077 0.54576555 0.37420071 0.86510971 0.49127185\n",
      "  0.67262143 0.94137465 1.36607865 0.9050936  1.71961407 0.60581845\n",
      "  0.73983631 0.71747822 0.62581898 0.78759188 0.84146375 0.91909491\n",
      "  1.02690615 2.05340433 0.74041114 1.10381405]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #7\n",
      "[[0.02060272 0.09246161 0.07083934 0.0168401  0.02473857 0.08283406\n",
      "  0.07105184 0.05118412 0.02984635 0.08834703 0.03344018 0.04214036\n",
      "  0.02058447 0.03674892 0.05994195 0.0213927  0.02009248 0.05509247\n",
      "  0.03604797 0.11172403 0.0248144  0.05913379 0.0207431  0.06291523\n",
      "  0.09088785 0.07969582 0.04580635 0.01337169 0.02297554 0.0476543\n",
      "  0.05955689 0.04792129 0.05326796 0.02848893 0.0334644  0.01138122\n",
      "  0.0091794  0.09150146 0.01176939 0.0248144  0.02673389 0.04521131\n",
      "  0.01965129 0.0652095  0.00873577 0.02491842 0.03308021 0.05888576\n",
      "  0.02045962 0.02496346 0.01619106 0.01286555 0.09567064 0.01976754\n",
      "  0.01958621 0.08933739 0.04666339 0.01745949 0.04912642 0.0282116\n",
      "  0.02657647 0.01905099 0.01957954 0.04468155 0.07028463 0.02039231\n",
      "  0.02072461 0.068879   0.01661174 0.0395748 ]\n",
      " [0.57537818 4.26232429 0.75415002 0.72065559 1.21817994 1.34080599\n",
      "  1.2430398  1.18984374 0.90713062 2.47465248 1.22016231 1.85319553\n",
      "  0.7797176  1.44171041 0.65535364 0.6517878  1.23020182 1.10547623\n",
      "  0.96966627 1.17353228 0.78647975 1.37605964 0.82120655 0.76424481\n",
      "  1.82858973 1.34171631 1.36077791 0.4626185  0.79679187 1.81462436\n",
      "  0.77132671 1.09818937 1.21637293 0.75958278 0.82895286 0.41337441\n",
      "  0.45652528 2.27768177 0.67240335 0.78647975 1.24099589 1.2035881\n",
      "  0.69440057 1.73833068 0.56007842 1.01663133 1.31570864 1.83742499\n",
      "  0.62481968 0.64706569 0.80636181 0.42416066 1.08948764 0.66019921\n",
      "  0.83983025 0.72858001 1.63813806 0.57030261 1.10187924 0.64171946\n",
      "  0.77912931 0.60404414 0.68114631 0.87319821 1.10918926 0.98703002\n",
      "  0.74705714 1.15537409 0.8263308  1.01941897]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #8\n",
      "[[0.03276438 0.08518691 0.05281037 0.01059027 0.0234663  0.03856686\n",
      "  0.03098716 0.02919312 0.01739481 0.09330247 0.021129   0.02751821\n",
      "  0.01798986 0.02406409 0.02886902 0.01112193 0.02475738 0.05087889\n",
      "  0.025338   0.0868164  0.01375009 0.0582878  0.00934451 0.03827485\n",
      "  0.05422461 0.07187716 0.02313978 0.00648441 0.01344001 0.04593427\n",
      "  0.03127627 0.02594393 0.02648136 0.01408553 0.00584415 0.0117749\n",
      "  0.00962245 0.08994517 0.01313075 0.01375009 0.02373359 0.0280025\n",
      "  0.01328022 0.06855144 0.0093425  0.02513724 0.02030072 0.04209872\n",
      "  0.01817418 0.01665473 0.0077057  0.01048635 0.0598613  0.01477757\n",
      "  0.01569359 0.04214997 0.03722601 0.02210711 0.02542056 0.01365813\n",
      "  0.02136297 0.01910688 0.02291809 0.03055721 0.0477822  0.01766662\n",
      "  0.01519698 0.04626291 0.0118557  0.03684991]\n",
      " [0.93830737 3.39736952 0.68425002 0.45890912 1.07886937 0.5653715\n",
      "  0.36576848 0.45986963 0.47195906 3.61655662 0.90233143 1.03276361\n",
      "  0.56806742 0.79374046 0.39703914 0.34656855 1.32475238 0.80720558\n",
      "  0.83551084 0.9230885  0.55512702 1.7840023  0.28382762 0.53777618\n",
      "  0.77941261 1.4445472  0.57694947 0.27421868 0.64288932 1.69626962\n",
      "  0.44024813 0.48608134 0.50837701 0.341851   0.28748119 0.388036\n",
      "  0.53616935 2.40094983 0.78290739 0.55512702 1.20876105 0.58838516\n",
      "  0.52722904 2.3629673  0.6561     1.33328832 0.69302181 1.23378718\n",
      "  0.6439815  0.44754252 0.36273163 0.42886104 0.76893964 0.48819861\n",
      "  0.63037823 0.45836436 0.82267488 0.69363526 0.38078503 0.36167865\n",
      "  0.71105542 0.76340567 0.79032197 1.1723764  0.66512803 0.9545367\n",
      "  0.54608172 0.73620638 0.49046353 0.98029368]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #9\n",
      "[[0.02240255 0.09974521 0.05661637 0.02039759 0.03208631 0.06628213\n",
      "  0.05550235 0.03060945 0.02319365 0.09702531 0.03176633 0.03795659\n",
      "  0.02923118 0.02941515 0.05480437 0.01956053 0.03165854 0.03105524\n",
      "  0.0315114  0.09978864 0.02153274 0.06405518 0.01533024 0.06253894\n",
      "  0.05461613 0.06626887 0.0435858  0.01028205 0.0218745  0.05014988\n",
      "  0.0370502  0.05420287 0.04497786 0.03069213 0.01000956 0.0156729\n",
      "  0.0136806  0.0912187  0.0188349  0.02153274 0.03223206 0.02584661\n",
      "  0.02193223 0.07012757 0.01102292 0.02409992 0.0298196  0.05922047\n",
      "  0.03783175 0.02362329 0.02081316 0.01459531 0.07531011 0.01522485\n",
      "  0.02079341 0.0728295  0.04132532 0.0335937  0.05252863 0.0134563\n",
      "  0.02877175 0.03219927 0.03178902 0.02940028 0.07268936 0.01886384\n",
      "  0.02384099 0.06035146 0.01327468 0.04623124]\n",
      " [0.80220906 3.92025079 0.78795114 0.78432687 1.50602837 0.88034948\n",
      "  1.15010013 0.53949105 0.72006775 3.87245096 1.12904887 1.89389585\n",
      "  0.88750843 0.70951131 1.05559591 0.57004608 1.88471563 0.63937371\n",
      "  1.22590002 3.86883364 0.80163625 1.62055764 0.61630238 0.82653498\n",
      "  0.75330928 1.04211599 1.10075369 0.51645801 0.97228346 2.21914581\n",
      "  0.82536763 1.12098562 0.92855335 0.73545117 0.40850104 0.60340495\n",
      "  0.84769734 2.32997618 1.01768623 0.80163625 1.14499443 0.59307151\n",
      "  1.06788796 2.64141291 0.86258609 1.35275023 1.05213256 2.05340816\n",
      "  0.95799139 0.68810244 0.97733368 0.71124806 0.75535435 0.53809473\n",
      "  1.0011449  0.85455615 0.93332954 1.22472745 1.17655206 0.4373074\n",
      "  0.92433602 1.02906092 1.14249466 0.88793062 1.08271088 1.06856315\n",
      "  0.85585419 0.83708802 0.71532933 1.32019703]]\n",
      "=========================================================================================\n",
      "Starting Pattern 3\n",
      "=========================================================================================\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #0\n",
      "[[0.02402073 0.01691194 0.04113281 0.01362105 0.01266829 0.06179555\n",
      "  0.03847512 0.04263889 0.02812661 0.04219267 0.03910816 0.01329855\n",
      "  0.01614201 0.03271623 0.07885862 0.04401305 0.01883241 0.03033267\n",
      "  0.01072386 0.06864428 0.00989976 0.04946109 0.02029204 0.04713339\n",
      "  0.06177136 0.06059586 0.02383566 0.02438353 0.00991251 0.04152251\n",
      "  0.02975593 0.0215385  0.03765012 0.01317911 0.01453426 0.01276123\n",
      "  0.00858878 0.09456603 0.00730037 0.00989976 0.01297499 0.04628468\n",
      "  0.01812914 0.08026909 0.00675396 0.02745359 0.0208992  0.02357434\n",
      "  0.01886132 0.02721065 0.01963077 0.00993018 0.03705101 0.00995423\n",
      "  0.02914402 0.05398698 0.05959469 0.01628287 0.03227001 0.0100359\n",
      "  0.01584627 0.02123397 0.0200132  0.02472437 0.02823714 0.02358714\n",
      "  0.01317406 0.07930383 0.01441731 0.089841  ]\n",
      " [0.64847354 0.68373208 0.61044594 0.54212763 0.59620394 1.27230381\n",
      "  0.51539814 0.9926039  0.81385522 1.35511032 1.50410981 0.52158203\n",
      "  0.52322125 1.1256404  1.31646317 1.37771184 0.94859601 0.77077475\n",
      "  0.42558474 0.82025049 0.39713308 1.4462051  0.66772842 0.71285413\n",
      "  1.30134701 1.24474292 0.7443951  0.99369114 0.41332578 0.98385777\n",
      "  0.50853882 0.46986469 0.83127083 0.38867579 0.52354206 0.56821464\n",
      "  0.60024969 2.56159961 0.39651373 0.39713308 0.54567535 1.33504527\n",
      "  0.76799275 2.69722483 0.52557664 1.47981551 0.80239503 0.5730187\n",
      "  0.53399726 0.7997704  1.10124468 0.45595739 0.54677693 0.37654467\n",
      "  1.22854351 0.66318941 1.6890211  0.56042221 0.66288275 0.31713045\n",
      "  0.5443573  0.56746288 0.66555654 0.94216708 0.51280267 1.35001444\n",
      "  0.53547859 1.51400409 0.96020046 2.58688391]]\n",
      "0.6484735357991956\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #1\n",
      "[[0.02952503 0.01860045 0.05002295 0.01630998 0.03162374 0.04361406\n",
      "  0.04525575 0.03116913 0.02792244 0.05357005 0.05033122 0.02073502\n",
      "  0.01367963 0.0283746  0.09378237 0.06321602 0.03100263 0.04521566\n",
      "  0.01667614 0.05322289 0.02728135 0.06491717 0.02623238 0.06501036\n",
      "  0.04990288 0.07672127 0.03093626 0.03077669 0.0201348  0.04012054\n",
      "  0.034571   0.03819541 0.05510126 0.01720313 0.01390194 0.01836131\n",
      "  0.01312424 0.10698184 0.01138309 0.02728135 0.02699554 0.04182257\n",
      "  0.02316912 0.04618195 0.01232324 0.02057003 0.02366385 0.04362476\n",
      "  0.03798049 0.03329448 0.02631769 0.02068826 0.06240749 0.01975492\n",
      "  0.03181692 0.07549063 0.06109777 0.03311686 0.03353661 0.02213078\n",
      "  0.03052008 0.03191087 0.03328914 0.05297651 0.06474884 0.02564126\n",
      "  0.01784874 0.05472456 0.01589715 0.08913748]\n",
      " [0.90600928 0.66189307 0.73061218 0.74137518 3.54735216 0.80951214\n",
      "  0.82798379 0.54779352 0.79044795 1.77942656 3.10174525 0.65245988\n",
      "  0.47899087 0.87753331 1.56136112 1.82755237 1.88833495 1.38017436\n",
      "  0.53890863 2.39586742 1.38297451 1.86316945 0.92496298 0.92195757\n",
      "  0.7750592  2.49680714 0.87850876 1.18869461 0.96912939 0.77871037\n",
      "  0.60196569 1.15833966 1.10277129 0.52425749 0.57673154 0.75834066\n",
      "  0.78662029 2.9926951  0.82010478 1.38297451 1.60743021 1.1332819\n",
      "  0.85435992 0.53768853 0.95483953 0.9084257  0.72483156 1.99426401\n",
      "  1.65604645 0.90045192 1.24943474 0.99886026 1.3511789  0.71664451\n",
      "  1.56585844 0.75469273 1.55055033 1.29326697 0.55731449 0.63181768\n",
      "  0.96015037 1.49274585 1.50127844 0.84620386 1.92838888 1.42258624\n",
      "  0.89378339 0.74241775 0.76861504 2.64283617]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #2\n",
      "[[0.02833688 0.01971834 0.05720289 0.02016358 0.02019073 0.07181879\n",
      "  0.07344779 0.03799947 0.03277196 0.04000993 0.0471256  0.02286164\n",
      "  0.0204855  0.0365316  0.0653921  0.05078642 0.01883874 0.0391436\n",
      "  0.02260685 0.05555952 0.01870484 0.04608409 0.02681121 0.06259014\n",
      "  0.07855861 0.06087395 0.02811513 0.02333334 0.02706061 0.02999704\n",
      "  0.06106766 0.04334439 0.0575968  0.02252424 0.0125451  0.01160626\n",
      "  0.00734626 0.09455976 0.00739549 0.01870484 0.01438613 0.05635149\n",
      "  0.02440228 0.08941071 0.01119027 0.02308568 0.02310717 0.03059123\n",
      "  0.03543691 0.02512422 0.02018054 0.01059606 0.07454223 0.01463344\n",
      "  0.03611556 0.06189797 0.06600759 0.02842122 0.05558108 0.01913211\n",
      "  0.02355239 0.01988384 0.02602785 0.02199754 0.04459023 0.02595226\n",
      "  0.02019598 0.07609897 0.01530756 0.08889756]\n",
      " [0.80011284 0.76741041 0.69521329 0.76855813 0.96694467 2.9611992\n",
      "  2.8874057  1.12920062 1.25759793 1.36112917 2.1246012  0.91315096\n",
      "  0.71123998 1.7231608  0.88170854 1.5515571  1.0603881  0.89268906\n",
      "  0.89487022 0.90057583 0.82389274 1.51586771 1.18805122 0.86365114\n",
      "  2.88993854 1.51713373 1.01017286 1.0966777  0.90536349 1.41217094\n",
      "  2.24735254 1.04118208 1.72792158 0.65491116 0.92432467 0.43884975\n",
      "  0.49393444 2.09986995 0.39245168 0.82389274 0.74081025 2.75493707\n",
      "  1.294729   4.63180659 0.7716657  1.54495837 1.06642916 0.97031576\n",
      "  1.09105412 0.80060513 1.07405453 0.45067615 0.94917045 0.5286138\n",
      "  1.44662076 0.64823452 3.24629106 1.01171602 2.52585131 0.75784483\n",
      "  0.93604211 0.63053219 1.05190434 0.77672685 0.84914677 1.70473373\n",
      "  0.95260581 3.73669149 0.84531489 2.53937088]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #3\n",
      "[[0.03562672 0.01779329 0.04331985 0.01564666 0.01891228 0.09967228\n",
      "  0.07511475 0.05395171 0.03883147 0.05199123 0.03814914 0.0164885\n",
      "  0.02110939 0.03538651 0.09804156 0.04284717 0.02625169 0.03700369\n",
      "  0.01635151 0.0462249  0.02281427 0.05676917 0.03664518 0.02606038\n",
      "  0.09360844 0.05670767 0.02059443 0.02585826 0.01385201 0.04494472\n",
      "  0.08897164 0.0310525  0.04328369 0.01650703 0.0364571  0.02303541\n",
      "  0.01881576 0.09391115 0.01013344 0.02281427 0.02126229 0.07230045\n",
      "  0.03603201 0.10946739 0.00625648 0.0265415  0.0334032  0.02991902\n",
      "  0.02370185 0.03275385 0.01697149 0.01472496 0.05114994 0.02285235\n",
      "  0.0338813  0.04555652 0.04657648 0.03102032 0.0557559  0.03188926\n",
      "  0.02127338 0.03642988 0.02742364 0.02564277 0.04604838 0.02381255\n",
      "  0.02013928 0.05644542 0.02142667 0.08756045]\n",
      " [0.85197615 0.76386945 0.79488195 0.59301925 0.80211992 1.00575618\n",
      "  0.81536475 0.86859585 0.74168397 1.91982429 1.49563999 0.61377626\n",
      "  0.67369707 0.83730986 1.43083325 1.47717818 1.44618698 1.36450801\n",
      "  0.52742929 0.87528695 0.88307412 1.95147056 0.94910819 0.39201722\n",
      "  0.96445291 1.14407746 0.54130483 0.99766699 0.65208896 1.10728201\n",
      "  0.98968402 0.78184692 0.69005416 0.52227016 0.99596761 0.81180171\n",
      "  1.16573817 2.80397235 0.65177743 0.88307412 0.98890633 0.89867166\n",
      "  1.06137135 1.25558866 0.45723096 1.34571455 0.90869223 0.70535071\n",
      "  0.8190296  0.89456082 0.84955551 0.65412615 1.27380957 0.7520923\n",
      "  1.50545502 0.54609626 1.31136892 0.80670647 1.04551853 0.73885903\n",
      "  0.62048948 0.84466968 0.89997881 1.03575687 0.76839423 1.30550627\n",
      "  0.98312525 0.84463046 0.94958681 2.58147408]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #4\n",
      "[[0.01874382 0.02575445 0.06671858 0.01668821 0.0171806  0.05371414\n",
      "  0.03420688 0.02558687 0.02091733 0.04548725 0.03787655 0.02566584\n",
      "  0.01634864 0.027223   0.07176132 0.04546874 0.02772459 0.03132527\n",
      "  0.00964483 0.03354703 0.014602   0.04421661 0.01812362 0.04056002\n",
      "  0.05478522 0.0546713  0.03154185 0.02318606 0.01890513 0.0299532\n",
      "  0.02636916 0.04125594 0.03947563 0.02412639 0.00527562 0.01371249\n",
      "  0.01195425 0.09460172 0.01457044 0.014602   0.0172272  0.02889568\n",
      "  0.01946368 0.08040583 0.00921637 0.02630433 0.01379121 0.03780833\n",
      "  0.03014005 0.02531586 0.01683159 0.00970884 0.05116912 0.00984867\n",
      "  0.02706545 0.05404077 0.06410416 0.02775128 0.03259126 0.0100361\n",
      "  0.01761593 0.02487839 0.02908675 0.03206843 0.03974021 0.02243841\n",
      "  0.01470578 0.04663301 0.01014805 0.08270518]\n",
      " [0.61055496 0.9174253  0.76453861 0.57458143 0.64420593 1.20368478\n",
      "  0.44727886 0.5505165  0.52613114 1.47759918 1.18426831 1.13237054\n",
      "  0.50419051 0.92442687 1.05697087 1.29354571 1.33782822 0.49488926\n",
      "  0.33141069 1.19532813 0.57355591 0.90336974 0.61177112 0.52171705\n",
      "  0.76532535 0.83853662 0.73226484 0.94892364 0.72136236 0.6886493\n",
      "  0.38836713 0.7784055  0.87418989 0.52058155 0.25927245 0.47625892\n",
      "  0.72114977 2.0265322  0.73859816 0.57355591 0.68894988 0.6200507\n",
      "  0.92839907 2.50581872 0.62368293 1.03581581 0.4623097  1.1819857\n",
      "  1.04474423 0.64031792 0.64806357 0.40584037 0.54460297 0.34472919\n",
      "  0.97297267 0.54180518 1.5250184  0.93497865 0.77550457 0.30431187\n",
      "  0.54006794 0.7193041  1.00554939 0.74911316 0.6051607  1.2671143\n",
      "  0.56790589 0.88013218 0.45800667 1.99921522]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #5\n",
      "[[0.0282996  0.01387772 0.03221258 0.01277841 0.01673593 0.03571052\n",
      "  0.03504602 0.02455505 0.01378648 0.12344694 0.05352624 0.01236896\n",
      "  0.01436298 0.02032815 0.08353914 0.04308927 0.0169853  0.0256016\n",
      "  0.00954251 0.05730839 0.01322044 0.04619908 0.01480701 0.02627733\n",
      "  0.05404082 0.05827452 0.01159566 0.02610266 0.00868732 0.02707083\n",
      "  0.02397293 0.01813827 0.03209919 0.01178249 0.00934672 0.01093531\n",
      "  0.00774671 0.091284   0.00840672 0.01322044 0.01113452 0.02139464\n",
      "  0.01426696 0.0783182  0.00701604 0.02068966 0.01297596 0.01876177\n",
      "  0.02423473 0.02419075 0.01416841 0.01075996 0.03284107 0.00991103\n",
      "  0.02931881 0.03797699 0.06137096 0.0170386  0.02332751 0.01123297\n",
      "  0.01572034 0.01870757 0.02589549 0.04508368 0.03341365 0.02472699\n",
      "  0.01527766 0.03948007 0.01032403 0.08659252]\n",
      " [0.72970775 0.49485469 0.42972075 0.43574042 0.44418568 0.52425858\n",
      "  0.54197049 0.43299482 0.32583394 1.01814413 1.03083441 0.44144068\n",
      "  0.42536    0.55354844 1.0962108  1.27348924 0.72370545 0.4699255\n",
      "  0.34351775 0.76278881 0.46531893 1.25874969 0.46890706 0.37553417\n",
      "  0.53534004 0.98605191 0.27330011 1.06526084 0.36406199 1.19372945\n",
      "  0.44266198 0.36921064 0.67419321 0.28476228 0.38327478 0.40543834\n",
      "  0.43824186 2.27659974 0.44558227 0.46531893 0.41568831 0.37226902\n",
      "  0.55939896 2.51719905 0.51016322 1.14310311 0.40510068 0.51374859\n",
      "  0.59818617 0.63692903 0.67660503 0.40855112 0.45582781 0.3279713\n",
      "  1.257842   0.39500306 1.23173412 0.47340181 0.3823686  0.33619131\n",
      "  0.52608517 0.48756288 0.81195195 0.78033356 0.57250756 1.44856942\n",
      "  0.51266306 0.50579075 0.48604876 2.31162608]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #6\n",
      "[[0.01954134 0.03259023 0.05014476 0.01506067 0.02296744 0.04886593\n",
      "  0.07877942 0.04437688 0.02842845 0.0525217  0.04880379 0.02507238\n",
      "  0.02042926 0.03381714 0.09843152 0.05655739 0.02657336 0.04030362\n",
      "  0.01415303 0.04236985 0.02325874 0.06129679 0.02383745 0.0642763\n",
      "  0.06052768 0.0580281  0.04169618 0.0275611  0.02521411 0.03667214\n",
      "  0.06961212 0.0623569  0.04556093 0.01827097 0.02885391 0.0167514\n",
      "  0.01610042 0.11311387 0.02043944 0.02325874 0.02320702 0.04006486\n",
      "  0.03375616 0.08403497 0.01096632 0.02522507 0.02258905 0.03907669\n",
      "  0.03368434 0.0247045  0.02524154 0.02230258 0.06408988 0.02900745\n",
      "  0.03423252 0.05942319 0.07072337 0.02519591 0.05543437 0.02108499\n",
      "  0.02550167 0.02678752 0.03436961 0.03177214 0.04974274 0.03031362\n",
      "  0.02689052 0.07919556 0.01872041 0.10164107]\n",
      " [0.69312591 1.65630693 0.72629648 0.58212337 1.27287456 0.88441885\n",
      "  2.64432596 1.06808175 0.62886983 1.91979444 2.81293111 1.23241117\n",
      "  0.96252765 0.90141691 1.60212589 1.94606783 1.51502016 0.91143424\n",
      "  0.54075033 1.2538112  1.0090313  2.05653861 0.81507095 0.9025783\n",
      "  0.84093271 1.43092379 1.46212865 1.19790447 1.17151213 1.06137875\n",
      "  1.83334248 2.40520643 1.09818051 0.51577325 1.085084   0.75480186\n",
      "  1.30397116 3.76796093 1.35085455 1.00903131 1.3614713  0.8864964\n",
      "  1.95263733 2.7904072  0.9063232  1.42917749 0.6815412  1.64446186\n",
      "  1.45161376 0.80595305 1.33753058 1.04921151 1.09104018 0.90508544\n",
      "  1.7067274  0.79001854 1.72047101 1.03162397 1.85157733 0.71729337\n",
      "  0.92041647 0.82098009 1.62079026 1.31202744 1.16277631 1.89383647\n",
      "  1.29723852 4.04248635 0.96019726 3.91367789]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #7\n",
      "[[0.03041467 0.03846846 0.07168406 0.03298808 0.03011183 0.03811321\n",
      "  0.05962081 0.04061978 0.03280861 0.05267331 0.05154786 0.03027447\n",
      "  0.03280224 0.02469884 0.09994322 0.06580744 0.0336092  0.05689702\n",
      "  0.01641438 0.03736229 0.02771329 0.06912371 0.03158515 0.07903006\n",
      "  0.06094814 0.08292351 0.0561784  0.03118458 0.03103586 0.03290525\n",
      "  0.04992486 0.07386341 0.04839683 0.04786187 0.01612203 0.0265664\n",
      "  0.02014969 0.11761223 0.02503001 0.02771329 0.03475682 0.05241792\n",
      "  0.03260497 0.08462862 0.01411782 0.02217372 0.02741134 0.04372757\n",
      "  0.0427378  0.03225755 0.02917933 0.02489908 0.07874418 0.02518214\n",
      "  0.03887498 0.08569501 0.0676091  0.03840868 0.05270084 0.02459194\n",
      "  0.03520095 0.03399231 0.04171459 0.03919223 0.06066188 0.02622868\n",
      "  0.03005088 0.07973827 0.02035759 0.10819392]\n",
      " [0.84500374 1.65785252 0.90523905 1.34858687 1.65198328 0.54863008\n",
      "  0.91765616 0.95450558 0.88821965 1.62614733 2.37887058 1.31083313\n",
      "  1.13556947 0.57962761 1.51892507 1.78072319 1.9261334  1.69087514\n",
      "  0.49464262 1.08845191 1.06882342 1.94143218 1.09056235 0.99771268\n",
      "  1.01996753 2.1470858  2.20529143 1.129649   1.13248271 1.0744938\n",
      "  0.70499603 2.65757673 0.93899447 1.50272261 0.62832256 0.8958881\n",
      "  1.08261611 2.65025418 1.34229369 1.06882343 1.91344722 1.37532491\n",
      "  1.65803744 2.22660098 0.88323661 1.03171152 0.8855277  1.39895877\n",
      "  1.43317807 0.77594513 1.1168233  0.88195148 1.98767591 0.67155281\n",
      "  1.37653878 0.79925124 1.70167989 1.41309801 1.1523362  0.60873571\n",
      "  0.91923763 1.0610095  1.76005786 1.26520569 1.74318613 1.23970838\n",
      "  1.26226791 1.49194714 0.75014687 3.52479864]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #8\n",
      "[[0.02096576 0.01977015 0.04563391 0.02119056 0.01604399 0.06832958\n",
      "  0.06408103 0.03603945 0.03565312 0.11524512 0.03860403 0.02052867\n",
      "  0.01930479 0.0317652  0.09024998 0.04750671 0.01994334 0.02171937\n",
      "  0.01840845 0.06854649 0.01632036 0.0423847  0.02207644 0.04056764\n",
      "  0.10123378 0.0594499  0.02616868 0.02691067 0.01808908 0.03105796\n",
      "  0.0485614  0.02865283 0.034666   0.02035428 0.02082736 0.01725732\n",
      "  0.01091863 0.09534055 0.01076878 0.01632036 0.01476555 0.06283763\n",
      "  0.0202931  0.05079755 0.01116299 0.01763108 0.02858111 0.02270833\n",
      "  0.0289285  0.03287887 0.02255587 0.01368924 0.04405907 0.01926018\n",
      "  0.03534448 0.05356669 0.06549673 0.0265527  0.05789861 0.02272753\n",
      "  0.0233506  0.03246858 0.0304015  0.02523191 0.0325708  0.0225965\n",
      "  0.01410275 0.06208111 0.0176379  0.08683531]\n",
      " [0.6248329  0.75594827 0.6170152  0.73613363 0.64520048 0.70823584\n",
      "  1.0602355  0.55751151 0.59108194 1.00407213 1.36105201 0.68273311\n",
      "  0.60638329 0.60806625 1.18938152 1.25860182 1.05702238 0.44004988\n",
      "  0.56389444 0.77822567 0.55353484 0.9555598  0.48256046 0.53293617\n",
      "  0.78303028 1.03897737 0.69628277 0.97096136 0.64019953 1.10070969\n",
      "  0.56706287 0.58856746 0.53472269 0.44580387 0.62468086 0.59583573\n",
      "  0.62113516 2.29751458 0.51644821 0.55353484 0.68598129 0.6856709\n",
      "  0.70535504 0.74340805 0.6789856  0.71042771 0.59875009 0.5877067\n",
      "  0.71246854 0.76255523 0.93818824 0.58908405 0.63276065 0.5070122\n",
      "  1.32327732 0.60453966 1.17289225 0.82798404 1.05872473 0.49413015\n",
      "  0.55854434 0.74263173 0.9811561  0.59470447 0.52580558 0.96775505\n",
      "  0.4617788  1.19916339 0.84442595 2.34679732]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #9\n",
      "[[0.03818495 0.02029449 0.04021599 0.0177369  0.01818647 0.08381902\n",
      "  0.0735439  0.0478736  0.04470459 0.05073484 0.04444864 0.0236854\n",
      "  0.01698119 0.0421519  0.09694196 0.04696635 0.01839002 0.05388981\n",
      "  0.01866028 0.11890914 0.02702335 0.06318116 0.03114084 0.03880678\n",
      "  0.08403046 0.05775512 0.0243876  0.02676247 0.01857529 0.03004735\n",
      "  0.06726597 0.03633328 0.06085898 0.0192242  0.01753742 0.02313147\n",
      "  0.01067999 0.10197987 0.01077283 0.02702335 0.01701138 0.05879611\n",
      "  0.02659172 0.08972067 0.01178385 0.02362531 0.02677835 0.02910522\n",
      "  0.02352087 0.03184852 0.02778176 0.02022957 0.06346005 0.02126907\n",
      "  0.03350828 0.05137692 0.07729772 0.02440935 0.05642048 0.02187224\n",
      "  0.03360377 0.01798205 0.03289449 0.03244176 0.0558076  0.02941294\n",
      "  0.0177687  0.0795593  0.01518543 0.09188124]\n",
      " [0.828038   0.74891845 0.6448748  0.57345608 0.63088454 3.87176432\n",
      "  3.02115149 1.72975285 1.72206779 1.86545152 1.42618093 0.69406044\n",
      "  0.58746155 2.38488676 1.3911259  1.5645609  0.76122329 2.02003599\n",
      "  0.98540046 1.03493438 0.74054938 2.13598809 1.45401331 0.54608652\n",
      "  3.67576459 0.89610429 0.58722992 1.25719622 0.8001118  1.27562434\n",
      "  2.55589938 0.61218279 2.1055419  0.55330711 1.43337496 0.94407894\n",
      "  0.73231358 2.99816357 0.64628206 0.74054938 0.77434946 2.98572981\n",
      "  1.62493056 3.39468315 0.92457872 1.47720843 1.36057888 0.94145402\n",
      "  0.74349821 1.02255838 1.69611837 0.85566063 0.82397946 0.68735023\n",
      "  1.63542262 0.67042195 1.47687544 0.68375548 2.21582496 0.85178331\n",
      "  1.35790118 0.55712385 1.2726746  1.29851854 0.78242314 1.92041724\n",
      "  0.65809047 4.08551662 0.93983175 2.59390478]]\n",
      "=========================================================================================\n",
      "Starting Pattern 4\n",
      "=========================================================================================\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #0\n",
      "[[0.04639079 0.02126196 0.08509943 0.02688876 0.02584937 0.05708319\n",
      "  0.06526396 0.05182756 0.03126998 0.09186097 0.02940726 0.03174974\n",
      "  0.03198298 0.02343155 0.03730154 0.03522008 0.02249562 0.03591532\n",
      "  0.01911232 0.12869817 0.03028023 0.039875   0.02028106 0.04388467\n",
      "  0.05551899 0.03939826 0.03961479 0.02216586 0.02303838 0.02690576\n",
      "  0.05249724 0.05413599 0.03313947 0.03066828 0.0253847  0.02202674\n",
      "  0.01180919 0.03240141 0.01753663 0.03028023 0.01723596 0.04099837\n",
      "  0.0239326  0.08200874 0.01195503 0.02796243 0.01895093 0.04063219\n",
      "  0.04964187 0.0285888  0.01623569 0.01293198 0.04908885 0.06438039\n",
      "  0.02001293 0.06689078 0.05836263 0.0320438  0.04246194 0.02498414\n",
      "  0.02433451 0.03407931 0.03012281 0.05225305 0.07530643 0.06555327\n",
      "  0.03520399 0.10360614 0.01978188 0.04053351]\n",
      " [1.01735794 0.8247662  0.86156179 0.90114816 0.92029765 0.6823506\n",
      "  0.63533    0.65693229 0.68514776 2.07905588 1.00524407 0.92751831\n",
      "  1.02143377 0.58542051 0.43050397 0.75739135 1.06773161 0.91688953\n",
      "  0.51559013 1.13898134 1.0075469  1.06413513 0.47709785 0.61379691\n",
      "  0.61314143 0.89784356 1.03072228 0.68662249 0.7848336  0.77667701\n",
      "  0.5536842  0.97547741 0.49735985 0.89651956 0.6858492  0.58800857\n",
      "  0.57642563 0.63752268 0.82420959 1.0075469  0.75000813 0.69799452\n",
      "  0.64919769 0.77006313 0.71482502 1.05037403 0.49806641 0.89577938\n",
      "  1.07059833 0.63498273 0.62690686 0.52991992 1.05237234 0.9241976\n",
      "  0.62039718 0.53042722 1.38269762 0.92664951 0.69967828 0.52295942\n",
      "  0.60815837 0.85969674 1.22911908 0.79066885 1.12058719 2.70622573\n",
      "  1.0588534  1.05026772 0.61278116 1.14294838]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #1\n",
      "[[0.01558732 0.01160813 0.02736666 0.017958   0.01535966 0.055942\n",
      "  0.0457078  0.02817546 0.02304979 0.09766067 0.02996734 0.00952855\n",
      "  0.01954087 0.02163769 0.04423664 0.02963229 0.02213006 0.03559195\n",
      "  0.01327694 0.0202499  0.0214984  0.03680213 0.01674529 0.0274252\n",
      "  0.10637691 0.02511116 0.02819478 0.01437492 0.01600917 0.02019013\n",
      "  0.04909504 0.01906888 0.04072905 0.01610947 0.02607727 0.01150562\n",
      "  0.0067304  0.01715299 0.00743623 0.0214984  0.01276572 0.03952884\n",
      "  0.01642077 0.04918734 0.0090003  0.0221739  0.02254956 0.01345419\n",
      "  0.02444989 0.02676189 0.01040596 0.00930965 0.05203129 0.02347594\n",
      "  0.01958842 0.02918641 0.05600165 0.02209867 0.04402824 0.01552492\n",
      "  0.02027046 0.01848358 0.03241804 0.01572223 0.03331644 0.06696308\n",
      "  0.01546482 0.06734389 0.01332507 0.02420288]\n",
      " [0.53121674 0.46401085 0.36294675 0.62378684 1.13499053 0.76524591\n",
      "  0.78384192 0.4832146  0.53994039 3.32849522 1.47430064 0.51352146\n",
      "  0.70211024 0.69195974 0.53192565 0.72560421 1.07156398 0.62466753\n",
      "  0.52043389 0.80629222 1.02523681 0.99956896 0.48805136 0.36130233\n",
      "  0.9286698  0.52515612 0.73700629 0.58423451 0.64464272 0.70418813\n",
      "  0.74640266 0.63301263 0.79578366 0.45206465 0.75281222 0.40297908\n",
      "  0.3809897  0.41546862 0.4622406  1.02523681 0.60959635 1.01581716\n",
      "  0.68611714 0.63740076 0.65023754 1.27085295 0.87098465 0.49240655\n",
      "  1.03222333 0.75273064 0.44429728 0.39296809 0.66502142 0.59068212\n",
      "  0.82860514 0.33589902 1.17178187 0.91935317 0.66454432 0.50340957\n",
      "  0.53119736 0.63066849 1.41808746 0.49185783 0.65418646 3.34178606\n",
      "  0.60536783 1.02785379 0.58205658 0.74335999]]\n",
      "0.5312167437210491\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #2\n",
      "[[0.01212183 0.00826418 0.04029344 0.01481649 0.01263155 0.06535703\n",
      "  0.05824985 0.03871686 0.0275709  0.09666132 0.02860014 0.01761685\n",
      "  0.01613078 0.02180701 0.06005503 0.02680564 0.02340559 0.0404534\n",
      "  0.01625381 0.02483037 0.01915484 0.04027774 0.0219933  0.04274982\n",
      "  0.04165774 0.03309466 0.02034334 0.01693433 0.00961213 0.02327629\n",
      "  0.05808096 0.02928608 0.04911753 0.01197804 0.010453   0.01330412\n",
      "  0.0090728  0.01284196 0.00575641 0.01915484 0.01039474 0.04978193\n",
      "  0.0174495  0.07544003 0.00941107 0.03072894 0.03060682 0.02376305\n",
      "  0.02177773 0.02982528 0.00911338 0.01028615 0.05953629 0.01524157\n",
      "  0.01757815 0.05078647 0.04681352 0.02001239 0.03917788 0.01709813\n",
      "  0.0149857  0.01253294 0.03435326 0.01982552 0.05557001 0.06920255\n",
      "  0.01905555 0.05323239 0.01784207 0.02449147]\n",
      " [0.44298804 0.36128698 0.69072125 0.63743784 0.75018697 1.14380871\n",
      "  1.71496179 1.56592713 0.89292206 3.95924052 1.71672255 0.83751345\n",
      "  0.64244208 0.81753272 1.31108671 0.89978028 1.48226405 1.31776532\n",
      "  0.68505908 0.64768437 1.00054549 1.30870758 0.77169118 0.6797151\n",
      "  0.88584602 0.94844762 0.70003281 0.79322121 0.43758481 1.2812677\n",
      "  1.46324031 0.81609011 1.34593887 0.3503216  0.51492394 0.56596496\n",
      "  0.60706523 0.3678051  0.38136708 1.00054548 0.50395842 1.32968847\n",
      "  0.86339204 3.18545505 0.94273583 2.28065059 1.48967102 0.73076885\n",
      "  1.00266687 1.18741796 0.45175997 0.45049499 1.53112084 0.54575093\n",
      "  0.77889901 0.70616141 1.43669148 0.76434885 1.69691654 0.76471093\n",
      "  0.66817312 0.44766407 1.24890948 0.90254771 0.88733078 4.42959168\n",
      "  0.7606195  2.57968952 0.96148709 0.78740988]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #3\n",
      "[[0.03467451 0.01941261 0.03514757 0.02017283 0.0175958  0.05997109\n",
      "  0.05625799 0.03234449 0.02796984 0.09755652 0.02800095 0.02446976\n",
      "  0.02683952 0.02872198 0.05966305 0.02704933 0.02413211 0.05082602\n",
      "  0.01677    0.05077158 0.02470789 0.04144268 0.0260118  0.03673869\n",
      "  0.08800637 0.04778035 0.02567325 0.01894353 0.01157732 0.03799158\n",
      "  0.03522263 0.0212508  0.0468822  0.00939895 0.01604597 0.01970844\n",
      "  0.01064532 0.03451413 0.01528219 0.02470789 0.01884136 0.05110354\n",
      "  0.02700755 0.07083916 0.01265516 0.02684591 0.020033   0.0301981\n",
      "  0.01865868 0.03248403 0.02068142 0.01673133 0.07014644 0.01881227\n",
      "  0.02131812 0.05044953 0.04765334 0.0207573  0.0417602  0.01908207\n",
      "  0.02611764 0.02094052 0.03186165 0.03466273 0.03797007 0.06650558\n",
      "  0.02120826 0.07287525 0.01708381 0.03711017]\n",
      " [0.85177394 0.72269893 0.49318103 0.91753455 1.00861993 0.74345661\n",
      "  1.27586069 0.50930305 0.58695889 3.47864414 1.32870532 0.78956987\n",
      "  1.01970974 0.77895485 0.97683645 0.85923447 1.47329323 1.60563075\n",
      "  0.63376579 0.86550185 1.07176174 1.2322733  0.72581024 0.51536843\n",
      "  0.91880107 1.01929076 0.70159103 0.7086091  0.54490521 0.89246555\n",
      "  0.57634494 0.4731748  0.9721009  0.27343285 0.58647854 0.79239303\n",
      "  0.73395866 0.87961686 0.96720508 1.07176174 1.08534855 0.84590511\n",
      "  1.42790085 2.44423026 0.95178825 1.4661258  0.59557056 0.69960458\n",
      "  0.65856907 0.91309958 1.02726954 0.80144875 1.57373235 0.72675644\n",
      "  0.96450321 0.54849567 0.97818661 0.74413442 1.08138044 0.48379194\n",
      "  0.76953116 0.65917052 1.26703578 0.79151033 0.75387216 3.61474654\n",
      "  0.84452224 1.22911378 0.78930055 0.9861385 ]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #4\n",
      "[[0.03551787 0.01409893 0.03583266 0.02180333 0.01979331 0.06377162\n",
      "  0.04723624 0.03769765 0.0263523  0.09767481 0.03145289 0.02677349\n",
      "  0.01994787 0.01945225 0.05294637 0.02163192 0.0231662  0.03985482\n",
      "  0.01533593 0.026594   0.02896833 0.04322918 0.01663284 0.04134719\n",
      "  0.04140285 0.05099428 0.02605374 0.01803621 0.01802185 0.02396997\n",
      "  0.0355724  0.04071304 0.03764725 0.02054869 0.00981794 0.02048365\n",
      "  0.01214237 0.02076478 0.00722123 0.02896833 0.02358867 0.03918404\n",
      "  0.02184541 0.07385357 0.01254643 0.0216749  0.02443345 0.03656544\n",
      "  0.03306922 0.03153953 0.01831232 0.01404277 0.05386084 0.01870875\n",
      "  0.02225598 0.05659532 0.05663085 0.02951529 0.03688933 0.01684046\n",
      "  0.02477453 0.0242729  0.04218415 0.02064734 0.03196489 0.06793559\n",
      "  0.02300139 0.04983249 0.01231519 0.02751813]\n",
      " [0.90328542 0.58337059 0.5959691  1.00585953 0.7054317  1.00149252\n",
      "  0.92981109 0.59549926 0.71495668 3.08392011 1.73661567 0.8526158\n",
      "  0.83824849 0.58346388 0.87944595 0.68285688 1.19062094 1.18670869\n",
      "  0.46653911 1.10385299 1.1089986  1.1660509  0.44714352 0.61851544\n",
      "  0.71493328 1.71194324 0.68114792 0.64125119 0.87242766 0.78385515\n",
      "  0.57312725 0.7089853  0.61784675 0.66225019 0.48236741 0.71171366\n",
      "  0.74317209 0.57654576 0.47962624 1.1089986  1.38056713 0.97352492\n",
      "  0.97471667 2.00617818 0.84765743 1.08245029 0.8967018  0.79103138\n",
      "  0.9577713  0.81583274 0.79017468 0.57741922 1.17374242 0.53952474\n",
      "  0.90896519 0.62151914 1.07336979 1.00775821 0.70942684 0.47479591\n",
      "  0.70948254 1.12244581 1.71196088 0.6623872  0.91162682 3.34388009\n",
      "  0.91247437 2.27367711 0.5658845  0.8571184 ]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #5\n",
      "[[0.04450759 0.02465801 0.07131428 0.02030734 0.01414405 0.04711029\n",
      "  0.04366785 0.04236611 0.02773949 0.09865582 0.03555397 0.03014158\n",
      "  0.0199876  0.02107293 0.04500535 0.02580922 0.02100377 0.05122939\n",
      "  0.01872824 0.01944139 0.01724505 0.04330786 0.02038105 0.05522321\n",
      "  0.0395752  0.04152114 0.03428734 0.01961712 0.01763419 0.05525375\n",
      "  0.04424208 0.03477027 0.03496607 0.0334899  0.02110028 0.01972071\n",
      "  0.01058917 0.02694311 0.01287038 0.01724505 0.01325802 0.03489568\n",
      "  0.01680321 0.07450636 0.0092469  0.02863283 0.02017583 0.04132994\n",
      "  0.02776996 0.02505333 0.01637031 0.01040278 0.08235967 0.01935143\n",
      "  0.0164624  0.0762521  0.04412405 0.03124022 0.04998331 0.0197306\n",
      "  0.01968093 0.01629552 0.029908   0.02603681 0.04986768 0.06549274\n",
      "  0.01820217 0.10515841 0.0170389  0.03854128]\n",
      " [1.17851798 1.0048841  1.16515956 0.79691566 0.63763704 0.58820954\n",
      "  0.67257496 0.61969642 0.57538032 2.99643048 1.27181821 1.20294888\n",
      "  0.73177717 0.57517837 0.55412383 0.77608398 1.2217889  1.04575095\n",
      "  0.5659818  0.68101778 0.68254774 1.24501602 0.55940554 0.7762161\n",
      "  0.57415217 0.7067995  1.16161255 0.76309481 0.72778421 0.81383811\n",
      "  0.5894301  0.80917244 0.69225559 0.96762682 0.69374793 0.79041814\n",
      "  0.72020557 0.86020452 0.70968734 0.68254774 0.59389805 0.62699095\n",
      "  0.73240387 2.44461815 0.67777348 1.29171659 0.48685471 1.19152636\n",
      "  1.09251045 0.64591298 0.79489019 0.45938433 1.0805397  0.64845423\n",
      "  0.70993496 0.82190708 1.14556629 1.25498732 0.70461308 0.49076219\n",
      "  0.5965068  0.65694167 1.24617738 0.91211716 0.86442872 3.64987858\n",
      "  0.94724504 1.08093147 0.79193286 1.23330634]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #6\n",
      "[[0.03117915 0.01824704 0.06450408 0.01684007 0.0179345  0.10839143\n",
      "  0.04663173 0.05036454 0.03148129 0.09481966 0.0346392  0.02228182\n",
      "  0.01926085 0.02126392 0.03359349 0.01374043 0.01705147 0.06392085\n",
      "  0.02569541 0.10013632 0.0254183  0.04144487 0.02125049 0.06038113\n",
      "  0.0456642  0.05567018 0.03114854 0.01613124 0.01043897 0.02548531\n",
      "  0.02683192 0.03917337 0.05677233 0.01922996 0.02749508 0.01355329\n",
      "  0.0068805  0.01197265 0.0053738  0.0254183  0.01796584 0.03390003\n",
      "  0.01601716 0.04354974 0.00372876 0.03213678 0.02445968 0.03134449\n",
      "  0.03280087 0.02559226 0.01040514 0.0157163  0.09881977 0.11378533\n",
      "  0.01370578 0.08490327 0.05965347 0.01982034 0.02061578 0.0268225\n",
      "  0.01959249 0.0321733  0.03760736 0.03956913 0.05543167 0.06936963\n",
      "  0.02223344 0.06284819 0.01221117 0.03115594]\n",
      " [0.76177575 0.77863513 0.81471129 0.59391941 0.73254623 1.27487397\n",
      "  0.87094605 0.81440009 0.71772806 3.26627232 1.23522624 0.72866505\n",
      "  0.70004654 0.62049106 0.45755486 0.44088972 0.82669496 1.1504862\n",
      "  0.78116739 1.00240628 0.82064945 0.68628219 0.69063276 0.81165269\n",
      "  0.6702047  0.91162874 0.76214306 0.6854226  0.44109047 0.91589223\n",
      "  0.46213017 0.71793604 1.04880496 0.60481825 0.82548713 0.55464462\n",
      "  0.37337439 0.31223213 0.28779758 0.82064945 0.6594452  0.86356596\n",
      "  0.68350677 0.68745856 0.28192061 1.84388939 0.91678891 0.70640728\n",
      "  0.80800603 0.68097584 0.45763807 0.62242167 1.18069703 1.1822531\n",
      "  0.58778449 0.85884262 1.35038125 0.6143083  0.4358341  0.71640876\n",
      "  0.61191099 0.76362224 1.23412069 0.69244785 0.85109014 3.35978984\n",
      "  0.76551305 1.1008149  0.5397571  0.93360347]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #7\n",
      "[[0.02091783 0.03205195 0.08094231 0.02084658 0.02928118 0.06724915\n",
      "  0.0572032  0.04355886 0.02998909 0.09047543 0.0323388  0.02254599\n",
      "  0.03116087 0.0238363  0.04574352 0.03255025 0.02748726 0.0428994\n",
      "  0.01924257 0.02577788 0.02017732 0.03565957 0.02189934 0.04753917\n",
      "  0.05844074 0.04783739 0.04673738 0.02050638 0.0210375  0.0433239\n",
      "  0.04897701 0.04017037 0.03955275 0.03783866 0.0143202  0.0191901\n",
      "  0.01440725 0.02477505 0.01567028 0.02017732 0.02752654 0.04522631\n",
      "  0.02193494 0.07290613 0.01143004 0.02672208 0.02478225 0.0331603\n",
      "  0.02882352 0.02453948 0.0203704  0.01619741 0.07216588 0.01770085\n",
      "  0.01982181 0.07156954 0.06201406 0.03100969 0.04349256 0.01939072\n",
      "  0.02319772 0.02749388 0.03712318 0.08467436 0.03763398 0.06664183\n",
      "  0.02016803 0.10721758 0.01214932 0.04465627]\n",
      " [0.70323564 1.48228694 0.77748163 0.70077101 2.37673282 0.75298059\n",
      "  0.7209822  0.59655821 0.64039037 2.43927693 1.1240889  1.12924452\n",
      "  0.99227499 0.59700197 0.50968694 0.71940049 1.14201025 1.36511278\n",
      "  0.59173992 1.05514636 0.64187955 0.59683862 0.50426131 0.67351228\n",
      "  0.70346324 1.2110209  1.59067313 0.64557758 0.77163288 0.74442706\n",
      "  0.63927059 1.34040131 0.6226828  1.12081292 0.53869006 0.56767003\n",
      "  0.6252065  0.51247298 0.79677836 0.64187955 1.13539618 0.76318341\n",
      "  0.70131963 0.88174237 0.68656314 1.50500084 0.58296165 1.19529739\n",
      "  0.80789818 0.53668558 0.73690395 0.56115071 1.83243641 0.5111745\n",
      "  0.64067167 0.54381419 1.54557909 0.8578536  0.71997234 0.45659038\n",
      "  0.58127443 0.9606098  1.2933091  0.88740074 1.07465837 2.91971914\n",
      "  0.66305102 1.06500935 0.4276346  1.15437271]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #8\n",
      "[[0.01446328 0.01943619 0.03748526 0.01603428 0.01949777 0.08184223\n",
      "  0.05946126 0.02654991 0.03114237 0.10160332 0.03482014 0.02645217\n",
      "  0.02392345 0.01967115 0.05633139 0.02378485 0.03032807 0.04921466\n",
      "  0.01664302 0.03150839 0.02296085 0.049752   0.03096223 0.04657614\n",
      "  0.0475127  0.05551914 0.03139185 0.02206684 0.02342183 0.02201885\n",
      "  0.05233203 0.04230156 0.0404223  0.02432    0.01995729 0.01890635\n",
      "  0.01441671 0.03633241 0.01233998 0.02296085 0.01822237 0.04615426\n",
      "  0.03076354 0.07086385 0.01131375 0.03011196 0.02903009 0.02122369\n",
      "  0.02852665 0.03360017 0.01916594 0.01572773 0.0676921  0.01656148\n",
      "  0.01946436 0.07596689 0.044886   0.02605095 0.04182818 0.02024744\n",
      "  0.0183873  0.02021111 0.0379095  0.02817944 0.0549367  0.0668296\n",
      "  0.02562678 0.0578732  0.01747564 0.03380468]\n",
      " [0.7215385  1.17308435 0.74331807 0.81074867 0.83823961 1.03874809\n",
      "  1.3918977  0.58923722 0.68963291 4.0742863  2.11522647 1.12757782\n",
      "  1.05088953 0.62708424 1.04396516 0.72937636 2.96612467 1.83375375\n",
      "  0.765311   1.70632441 1.43913142 2.1480569  0.71864757 0.78416878\n",
      "  0.70697775 2.53804802 1.19480822 0.86366754 1.25019852 1.3557823\n",
      "  1.11924916 1.14486491 0.80611771 1.12897502 0.75193055 0.86641385\n",
      "  1.0188868  1.57932604 0.80908579 1.43913142 1.03923201 0.88441642\n",
      "  2.29120669 2.90031938 0.91532373 2.33298347 1.48605201 0.93171408\n",
      "  1.3279216  1.36670785 0.95577562 0.86164571 1.62720919 0.62392408\n",
      "  0.91285873 1.20222361 1.19616817 1.2290162  1.66490927 0.55243008\n",
      "  0.62619572 0.76716693 1.5311466  1.27865054 0.94947914 3.53655473\n",
      "  1.27943272 3.06260673 1.1131726  1.20801097]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #9\n",
      "[[0.02749519 0.07237595 0.07022754 0.02494943 0.03652997 0.05441253\n",
      "  0.04605662 0.03121306 0.02161285 0.13249128 0.04741542 0.0226674\n",
      "  0.02821209 0.01766338 0.04268445 0.02552178 0.03027297 0.04949183\n",
      "  0.01259662 0.05289197 0.02190439 0.04521733 0.01447962 0.06179762\n",
      "  0.04444632 0.05083578 0.04898733 0.01854044 0.03026615 0.02397806\n",
      "  0.040978   0.05385266 0.03813931 0.04844432 0.00976103 0.02280604\n",
      "  0.0134321  0.03431649 0.01854733 0.02190439 0.03373481 0.03611172\n",
      "  0.0184123  0.0738813  0.01236121 0.04026139 0.022815   0.03075477\n",
      "  0.02957174 0.0323507  0.02042677 0.01532761 0.06355015 0.02070594\n",
      "  0.02396994 0.07301356 0.05581016 0.02985835 0.03919378 0.01778795\n",
      "  0.02362171 0.02768014 0.03533825 0.0218147  0.05436745 0.06670224\n",
      "  0.02190623 0.07047218 0.01319805 0.03585852]\n",
      " [0.90282019 0.87878438 0.75350591 0.86688857 0.84070946 0.71320769\n",
      "  0.67795947 0.55208762 0.50482374 1.24006413 0.93525019 0.85525038\n",
      "  0.81932962 0.52168447 0.49424807 0.65428995 1.26049957 0.74633711\n",
      "  0.46556259 0.85779452 0.69519616 0.81105828 0.46314679 0.83730132\n",
      "  0.56687458 0.857839   1.00410953 0.78982766 1.00485056 0.94546286\n",
      "  0.84403843 0.87353234 0.70202935 0.79108476 0.46917704 0.73878109\n",
      "  0.67169753 0.66677974 0.91280236 0.69519616 0.77651759 0.90008434\n",
      "  0.64392548 2.25294643 0.76597647 1.3252839  0.74418105 0.87005187\n",
      "  0.96229511 0.90390659 0.75913896 0.58954966 0.72246137 0.63462618\n",
      "  0.82374965 0.59306938 1.60574988 0.88157796 0.68130968 0.48487267\n",
      "  0.68876961 0.73522668 1.19956089 0.58074755 0.7978579  3.53071714\n",
      "  0.72271441 1.12469167 0.52846962 0.60251662]]\n",
      "=========================================================================================\n",
      "Starting Pattern 5\n",
      "=========================================================================================\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #0\n",
      "[[0.0134371  0.01426568 0.05914866 0.01478362 0.02230718 0.05647099\n",
      "  0.05716724 0.03155565 0.02546434 0.0147039  0.03952447 0.00922993\n",
      "  0.01935803 0.0210342  0.05129567 0.01082991 0.02056334 0.05650655\n",
      "  0.01061027 0.01384221 0.00927293 0.05499819 0.01883154 0.04801462\n",
      "  0.04394971 0.04361383 0.03716697 0.06943707 0.013292   0.01939022\n",
      "  0.05147976 0.02558186 0.02553503 0.0166565  0.0103255  0.01412523\n",
      "  0.00926554 0.05194118 0.00853073 0.00927293 0.01257378 0.02638825\n",
      "  0.01455626 0.03878498 0.00693539 0.03060167 0.01517467 0.01477869\n",
      "  0.01229448 0.02395216 0.0079346  0.0108981  0.05450537 0.01735788\n",
      "  0.01194889 0.07996835 0.05008524 0.01262165 0.03041148 0.01016015\n",
      "  0.01292105 0.01946796 0.03046605 0.04040037 0.02151141 0.01291275\n",
      "  0.01129068 0.0398127  0.0193389  0.10803519]\n",
      " [0.52754534 0.61459929 0.9408392  0.6455881  0.93729495 1.07874966\n",
      "  0.99653596 0.75181252 0.71889431 0.56454566 1.4640458  0.56577089\n",
      "  0.75598774 0.7253654  1.06446834 0.39253905 1.42054123 1.20718449\n",
      "  0.45401553 0.60053131 0.43155661 1.01875936 0.78488739 0.76577115\n",
      "  1.04285173 1.24090417 1.31667493 4.22142702 0.62386667 0.67613095\n",
      "  0.90733504 0.8784373  0.67811955 0.60010409 0.56804347 0.59878303\n",
      "  0.6155643  1.57779675 0.63805677 0.43155661 0.66239214 0.84693828\n",
      "  0.61881372 0.84751019 0.59660363 2.06605698 0.64334656 0.56609464\n",
      "  0.51895386 0.84805657 0.56231979 0.53578108 1.01175368 0.62241459\n",
      "  0.52973751 1.07297775 2.28798204 0.52614181 0.80837167 0.41604404\n",
      "  0.57929439 0.7028531  1.26847032 0.91157745 0.62177631 0.80722886\n",
      "  0.59659043 0.88398079 1.21238585 3.32269213]]\n",
      "0.5275453364164164\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #1\n",
      "[[0.01905116 0.01583671 0.05062322 0.01060447 0.00943026 0.06881313\n",
      "  0.05612499 0.03686152 0.01071227 0.01685927 0.04002173 0.01107297\n",
      "  0.02068339 0.01310422 0.04781554 0.01510329 0.02138877 0.06269164\n",
      "  0.00972511 0.01552889 0.00688133 0.01957901 0.0088561  0.04743834\n",
      "  0.05427373 0.04468001 0.04034986 0.0677704  0.012797   0.00995126\n",
      "  0.03672079 0.02831933 0.02483676 0.02142469 0.01123028 0.01037825\n",
      "  0.00775437 0.04016286 0.00743629 0.00688133 0.0159374  0.03528729\n",
      "  0.0081251  0.01099365 0.00543474 0.03281845 0.01483983 0.01647476\n",
      "  0.01162919 0.02592627 0.0068692  0.00801071 0.09319459 0.01230517\n",
      "  0.01189342 0.05493017 0.05601882 0.01290175 0.01777594 0.01181741\n",
      "  0.01412922 0.01301257 0.03717576 0.01376546 0.07179366 0.00586039\n",
      "  0.01058759 0.00957637 0.01005766 0.10502272]\n",
      " [0.65950937 0.61638413 0.78358997 0.4177068  0.70327528 1.0174305\n",
      "  0.9175482  0.71932254 0.33564944 0.57371695 2.16921138 0.59250995\n",
      "  0.76687055 0.47521265 0.93458072 0.40585359 1.22709392 1.14247076\n",
      "  0.32422861 0.61277514 0.31661322 0.6415152  0.36947102 0.59346934\n",
      "  0.97295291 1.31594728 0.90403997 2.89073036 0.55099266 0.44221628\n",
      "  0.72823346 1.07671284 0.55594593 0.64555367 0.58272859 0.40239347\n",
      "  0.524836   0.94105324 0.47436726 0.31661322 0.75353984 0.87570757\n",
      "  0.47891377 0.37395844 0.37432402 2.10125904 0.53061366 0.59532629\n",
      "  0.49406564 0.82125146 0.37064426 0.3609847  1.17774571 0.43899219\n",
      "  0.46777678 0.61298225 1.33060958 0.55330578 0.68730228 0.40335082\n",
      "  0.42980623 0.52007403 1.14170202 0.54631218 0.98586169 0.39211085\n",
      "  0.43538239 0.50836162 0.62812831 3.02869926]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #2\n",
      "[[0.04519877 0.02443067 0.05261855 0.0321243  0.02945789 0.07385188\n",
      "  0.05817743 0.03709945 0.02457487 0.01727232 0.03069995 0.03472041\n",
      "  0.03354734 0.03995898 0.05847007 0.02981606 0.03081053 0.02611242\n",
      "  0.02088114 0.12703607 0.03782734 0.01507717 0.01373927 0.07325386\n",
      "  0.12840575 0.08827612 0.04717917 0.0645903  0.01776848 0.0140336\n",
      "  0.0432967  0.06848581 0.04999299 0.03388655 0.02926028 0.02121061\n",
      "  0.01057916 0.05169384 0.01661821 0.03782734 0.02546589 0.02868484\n",
      "  0.02062844 0.0176881  0.00988173 0.03513343 0.0197761  0.02740495\n",
      "  0.03594427 0.03141937 0.01048172 0.00949304 0.03144136 0.02311829\n",
      "  0.01500673 0.06048123 0.06179332 0.0393308  0.03870875 0.02678993\n",
      "  0.01939999 0.03533131 0.04127504 0.0131394  0.08023301 0.01118408\n",
      "  0.03548431 0.01170383 0.01558495 0.10588409]\n",
      " [1.04892359 0.93100031 0.63953276 1.08225361 1.11633877 1.07984987\n",
      "  1.01630713 0.81229304 0.70813464 0.61779022 0.97013711 1.09559807\n",
      "  1.17210688 0.84447589 1.02998892 0.76090058 1.39270857 0.89970777\n",
      "  0.61246691 1.1519306  1.21431496 0.50115283 0.5061205  0.91464929\n",
      "  1.14710806 1.33620265 1.13705564 2.62893802 0.76123165 0.57534909\n",
      "  0.76551803 1.19836815 0.87045333 1.01863248 0.92464204 0.77117327\n",
      "  0.77297912 1.34143209 1.00111227 1.21431496 1.15661785 0.73008815\n",
      "  0.85841717 0.5901012  0.71549892 1.88094733 0.77518481 0.87600899\n",
      "  1.08015342 0.85105351 0.55982164 0.41525925 0.86579689 0.70829668\n",
      "  0.64398222 0.6113844  1.23632901 1.06084688 0.80650751 0.73587742\n",
      "  0.55597518 1.05015211 1.37457259 0.490208   1.13073314 0.56008936\n",
      "  1.20850833 0.60196218 0.65487321 2.9984574 ]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #3\n",
      "[[0.02101938 0.02030697 0.05264312 0.01739488 0.01511467 0.11099619\n",
      "  0.05027876 0.0517693  0.05739916 0.01546417 0.03834033 0.01841824\n",
      "  0.03636531 0.05002374 0.08645307 0.0178491  0.01992771 0.03422906\n",
      "  0.01284666 0.03555512 0.02253173 0.02560491 0.04122591 0.05126229\n",
      "  0.0871235  0.04606161 0.0348843  0.06425977 0.01731639 0.06345101\n",
      "  0.09548341 0.0325346  0.03151381 0.02684261 0.04525406 0.01692943\n",
      "  0.01758577 0.04870564 0.01220676 0.02253173 0.02612424 0.10234535\n",
      "  0.01975816 0.06293353 0.00942165 0.03101888 0.05056995 0.02388281\n",
      "  0.01975833 0.03306374 0.02415631 0.02003319 0.04847416 0.02592171\n",
      "  0.01451611 0.06410222 0.04447103 0.02301066 0.03677683 0.03614701\n",
      "  0.02959184 0.02817744 0.03390409 0.02610763 0.03760341 0.01438913\n",
      "  0.01671746 0.05697615 0.01542605 0.10284931]\n",
      " [0.70943215 0.80936563 0.95086454 0.72132336 0.88112289 1.3727483\n",
      "  1.42523541 1.44324686 1.42155421 0.63269561 1.91768499 0.79731627\n",
      "  1.11770473 1.44861008 1.63888385 0.76746437 1.1775674  1.3391377\n",
      "  0.57859304 0.90727836 1.0932965  0.91818341 1.42274115 0.73166795\n",
      "  1.66770294 1.29777327 0.86853947 2.85360172 0.84303341 1.42262987\n",
      "  1.59310656 1.00152103 1.06729468 0.81898409 1.33150408 0.81296295\n",
      "  1.11762462 1.76188005 0.87835407 1.0932965  1.09044813 1.57280471\n",
      "  0.92502102 1.20751629 0.69433593 1.97983353 1.53107206 0.75555841\n",
      "  0.74390714 1.17957419 1.26780167 0.81620189 1.3118248  1.00873787\n",
      "  0.72972269 0.7648482  3.15552638 0.87335085 1.39383042 1.07570109\n",
      "  0.9563471  0.86125024 1.05556223 1.00020499 0.82053609 0.93321922\n",
      "  0.94433941 1.38674302 0.74660652 3.77111151]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #4\n",
      "[[0.02037816 0.01805759 0.05622592 0.0173714  0.02306241 0.00823336\n",
      "  0.07121368 0.01510501 0.01112868 0.0181652  0.04555332 0.02638682\n",
      "  0.02416403 0.00774482 0.07887681 0.01917918 0.02139486 0.06505079\n",
      "  0.01858986 0.01506252 0.02608972 0.03061009 0.01792545 0.04375702\n",
      "  0.04046854 0.06362303 0.04120463 0.06717042 0.01444929 0.01104346\n",
      "  0.06439208 0.04718685 0.04905456 0.03568848 0.01527889 0.01275262\n",
      "  0.00729942 0.04672974 0.00929513 0.02608972 0.0153953  0.05892174\n",
      "  0.0103898  0.01273182 0.00591713 0.04458162 0.02174467 0.03961324\n",
      "  0.00972945 0.02544704 0.01624545 0.00885974 0.09616588 0.01303784\n",
      "  0.00918967 0.09361539 0.04149337 0.01378052 0.01850518 0.01969387\n",
      "  0.01763412 0.02199574 0.02636221 0.0218392  0.0671931  0.00994281\n",
      "  0.0172451  0.00640072 0.00868253 0.09706107]\n",
      " [0.59665245 0.74932958 0.72066882 0.63763469 0.96842416 0.37741132\n",
      "  1.0071367  0.455334   0.39632682 0.53179578 1.34855254 1.11937803\n",
      "  0.68490559 0.36041832 1.13046201 0.66792308 1.18479996 1.02086154\n",
      "  0.64958125 0.5158535  0.78161472 0.71716175 0.62186268 0.49740814\n",
      "  0.87230326 0.94067118 1.11860408 2.6243092  0.50287632 0.45879232\n",
      "  0.94767568 0.90771636 0.80378962 0.89979606 0.73500697 0.43302207\n",
      "  0.41103927 1.39130348 0.42905822 0.78161472 0.63337783 1.02674193\n",
      "  0.47266836 0.49108004 0.37819613 1.36934344 0.6924223  1.23743148\n",
      "  0.34152314 0.72297754 0.67338811 0.33897141 1.05187698 0.50564631\n",
      "  0.43328848 0.89715603 1.64917973 0.45900652 0.59118058 0.57034677\n",
      "  0.52970672 0.65828061 0.8203356  0.65574551 0.96516888 0.53291117\n",
      "  0.60689999 0.28613866 0.39549613 2.45205383]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #5\n",
      "[[0.02350442 0.01381314 0.05685506 0.0195428  0.01730566 0.0757663\n",
      "  0.04693694 0.03589807 0.02138634 0.0254053  0.0487472  0.0196702\n",
      "  0.01980591 0.02107203 0.04996982 0.02165582 0.02173906 0.01963253\n",
      "  0.01506075 0.04346483 0.01766288 0.0198934  0.01618644 0.0535337\n",
      "  0.06038452 0.05140571 0.02380383 0.07675508 0.01414679 0.0136442\n",
      "  0.04742391 0.03136651 0.04096173 0.01934236 0.01240818 0.02045053\n",
      "  0.01225009 0.04287678 0.01338125 0.01766288 0.01584074 0.04278148\n",
      "  0.02222005 0.02298145 0.01011014 0.01899409 0.01867024 0.02900165\n",
      "  0.02414128 0.03848867 0.01451467 0.01860564 0.03425056 0.04310978\n",
      "  0.01872985 0.07611569 0.04785399 0.01897698 0.03072857 0.02491935\n",
      "  0.01786328 0.02793356 0.03024681 0.01854312 0.03265154 0.01183265\n",
      "  0.01672859 0.04493904 0.01763679 0.09627317]\n",
      " [0.81344676 0.7459806  0.67454702 0.9114645  1.02633156 0.94373598\n",
      "  0.84443229 0.71410398 0.61603088 0.78577889 2.48610122 0.88719304\n",
      "  0.76275687 0.65552944 0.64635546 0.66352619 1.06844643 0.65895523\n",
      "  0.46135564 1.0950931  0.75677085 0.66525601 0.54898145 0.82330577\n",
      "  0.92076642 1.58158821 0.86732024 2.71906511 0.67384415 0.57691436\n",
      "  0.78682049 0.89342527 0.74177542 0.6956686  0.63557947 0.68884068\n",
      "  0.70214589 1.14159953 0.85655119 0.75677085 0.83497168 0.84832894\n",
      "  1.17951487 0.67183868 0.7664364  1.09753608 0.58863482 0.92702502\n",
      "  0.84568083 0.88314856 0.66828995 0.80017775 1.06822019 0.9723925\n",
      "  0.74415334 0.68142586 1.10232813 0.7686532  0.67509516 0.7281493\n",
      "  0.57434514 0.94096637 1.32018692 0.66105464 0.92017969 0.64666836\n",
      "  0.62906922 0.8301494  0.78735278 3.3747394 ]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #6\n",
      "[[0.04898791 0.03498328 0.10464033 0.03270689 0.02853552 0.08136025\n",
      "  0.05622287 0.02930008 0.03375615 0.03146145 0.03939037 0.03169355\n",
      "  0.04080265 0.03703112 0.08080997 0.03887435 0.0342184  0.03113917\n",
      "  0.03672878 0.14140198 0.02750905 0.0251783  0.04025509 0.08271401\n",
      "  0.13010681 0.07336346 0.04339939 0.08108095 0.02622621 0.02257183\n",
      "  0.07562688 0.08281304 0.06139889 0.04593944 0.04356075 0.02249815\n",
      "  0.01617803 0.05519291 0.02095249 0.02750905 0.01485377 0.03438977\n",
      "  0.0220585  0.03754182 0.01172118 0.02382278 0.03647046 0.04182562\n",
      "  0.03635522 0.03728494 0.02150102 0.01849973 0.04135927 0.02852938\n",
      "  0.01774685 0.11802085 0.07627272 0.02830678 0.02500155 0.04174237\n",
      "  0.0284516  0.0305738  0.03271889 0.03863318 0.08800141 0.01888284\n",
      "  0.0268131  0.03663973 0.01848255 0.10734439]\n",
      " [1.09728184 1.34166538 1.77208761 1.26885708 1.2314353  0.97084473\n",
      "  0.9591731  1.14340713 0.88914949 1.02459739 2.7109249  1.49400615\n",
      "  1.42123516 1.00179504 1.65425761 1.06981852 1.98448122 1.60530382\n",
      "  1.22695049 1.17587594 1.46551466 1.08186178 0.94008089 1.33024232\n",
      "  1.17395833 1.85089067 1.17170088 3.57286658 1.29222151 1.31815684\n",
      "  1.02812606 1.62750551 0.91180096 1.40297728 1.0033468  1.03727915\n",
      "  1.24571359 2.05523003 1.28104765 1.46551466 1.00344539 0.94441307\n",
      "  1.28697163 0.97150391 0.99677889 1.64760719 0.98785608 1.37526328\n",
      "  1.17213626 1.42257704 0.99645699 1.10235977 1.46106356 0.8625744\n",
      "  0.97044817 1.50928278 1.51078041 1.23451018 0.99616857 1.07600211\n",
      "  0.81768728 1.29146846 1.94469169 0.95882588 1.18547952 1.09275782\n",
      "  1.29896892 0.86615574 1.05039189 3.15369625]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #7\n",
      "[[0.04527523 0.02719356 0.04936042 0.02381036 0.02677329 0.06053941\n",
      "  0.05963572 0.04152733 0.02523328 0.01884747 0.04477883 0.03972969\n",
      "  0.03287693 0.01787972 0.04012643 0.02749586 0.02924397 0.02501937\n",
      "  0.0138257  0.13807503 0.02707934 0.0167936  0.01724576 0.0486932\n",
      "  0.04572413 0.06596734 0.05057653 0.06949384 0.02486105 0.02144267\n",
      "  0.03549273 0.06444748 0.02961892 0.03927389 0.0128789  0.01697866\n",
      "  0.01044856 0.04311952 0.01785597 0.02707934 0.02370823 0.03766493\n",
      "  0.01895509 0.01985593 0.0110252  0.03313267 0.02004862 0.05628957\n",
      "  0.02863816 0.03166755 0.01565044 0.0149372  0.03799421 0.02363173\n",
      "  0.01659798 0.06432562 0.0632926  0.04316126 0.04047764 0.02051903\n",
      "  0.0184738  0.03631525 0.03744593 0.05288229 0.08413405 0.01066741\n",
      "  0.02522304 0.05652561 0.01971329 0.1076156 ]\n",
      " [1.03093464 0.95252685 0.68331878 0.93394177 1.03629042 0.91196867\n",
      "  1.00060636 0.71424325 0.65596172 0.71492386 2.27025881 1.11258531\n",
      "  1.00260888 0.57643343 0.53479572 0.75052174 1.16048193 0.83011175\n",
      "  0.49525112 1.12644605 0.96364027 0.5653605  0.54359075 0.69807413\n",
      "  0.82382767 1.19378734 1.11407131 2.92869525 0.94085757 0.72587164\n",
      "  0.69885334 1.19727634 0.66177753 1.05603246 0.62747783 0.60772949\n",
      "  0.72105377 1.02572922 1.03156718 0.96364027 0.96182597 0.81718076\n",
      "  0.90444062 0.61587069 0.78585213 1.36013502 0.56529642 1.09527196\n",
      "  0.93186866 0.83813371 0.68177006 0.67915546 1.12268084 0.78191567\n",
      "  0.68648114 0.72578007 1.13480758 1.11127477 0.75996314 0.62592087\n",
      "  0.55724202 0.98967152 1.2516139  0.85874136 1.105958   0.58318294\n",
      "  0.92468404 0.91636905 0.83173849 2.79858302]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #8\n",
      "[[0.04949256 0.02346296 0.07366914 0.02486055 0.03155496 0.00989669\n",
      "  0.01110463 0.01228687 0.01349937 0.01427247 0.04689223 0.03614609\n",
      "  0.0148304  0.00794852 0.05565511 0.01499491 0.02359447 0.02091274\n",
      "  0.0108494  0.07864789 0.0143183  0.02166176 0.01009409 0.08030387\n",
      "  0.01314838 0.0378498  0.04916752 0.06896599 0.02121311 0.0094446\n",
      "  0.01083041 0.07158101 0.01669855 0.02935761 0.00727363 0.01071997\n",
      "  0.01149076 0.04162172 0.00929402 0.0143183  0.01039128 0.01179092\n",
      "  0.01689472 0.01514151 0.00816679 0.0239774  0.01098259 0.05269853\n",
      "  0.03324648 0.02881414 0.0121813  0.01362041 0.0254747  0.01565513\n",
      "  0.01073883 0.07825397 0.02590545 0.03646938 0.01052007 0.02034233\n",
      "  0.01671976 0.0557092  0.02513327 0.01880952 0.06005413 0.00964441\n",
      "  0.00922797 0.01145321 0.01359352 0.09577306]\n",
      " [1.08602269 0.83779736 0.90246394 0.94022185 1.05002466 0.50419656\n",
      "  0.49025767 0.39703416 0.54576805 0.51766224 2.16295941 1.03262528\n",
      "  0.57164339 0.36373239 0.7902471  0.50554624 1.09926172 0.665705\n",
      "  0.41328558 1.08950223 0.55472111 0.57704084 0.43638171 1.06887712\n",
      "  0.48208402 0.96599103 1.07064957 2.52684487 0.80873836 0.37833866\n",
      "  0.40153533 1.12778327 0.53306555 0.75512275 0.5585211  0.44422995\n",
      "  0.69263076 1.14930531 0.49950713 0.55472111 0.59967561 0.57865386\n",
      "  0.82690761 0.48251842 0.60692601 1.06748769 0.53017349 0.9796159\n",
      "  0.84833554 0.73425209 0.55860313 0.59606355 0.56039557 0.60000207\n",
      "  0.53674372 0.80632367 1.20302298 0.94354783 0.38359226 0.61338137\n",
      "  0.49488577 1.11574281 1.17897616 0.59957045 1.02709481 0.50907177\n",
      "  0.41841763 0.56894855 0.78988507 2.36152658]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #9\n",
      "[[0.04761138 0.02717583 0.07282731 0.03280204 0.03006647 0.06520316\n",
      "  0.05448703 0.02608141 0.02895097 0.02093788 0.02751605 0.03795584\n",
      "  0.03714187 0.01722167 0.07998206 0.03190557 0.02955293 0.07707595\n",
      "  0.02159336 0.12336729 0.03719036 0.04699889 0.02038059 0.08423121\n",
      "  0.05523441 0.08433092 0.04826257 0.06768574 0.03367043 0.01587377\n",
      "  0.0457284  0.06786599 0.02236071 0.03773497 0.01171504 0.02527424\n",
      "  0.0149549  0.05196234 0.02059691 0.03719036 0.03492559 0.04564476\n",
      "  0.02166713 0.01742747 0.01368384 0.03470957 0.02429565 0.05481755\n",
      "  0.05109344 0.04400048 0.0259784  0.02444632 0.11797173 0.02649872\n",
      "  0.02494432 0.09808088 0.05013682 0.03930835 0.04336313 0.02619882\n",
      "  0.03397371 0.05278678 0.04213325 0.02027873 0.08486521 0.01216363\n",
      "  0.03638768 0.01477175 0.02312423 0.09933036]\n",
      " [1.21952439 1.12187404 0.89497335 1.22818314 1.181079   0.98753236\n",
      "  1.06990232 0.96017041 0.80518759 0.70705346 0.99130244 1.26538759\n",
      "  1.31814222 0.70160312 0.93732483 1.12253151 1.55471932 1.37291593\n",
      "  0.75484853 1.23494425 1.29907639 1.29330813 0.7302184  1.02795037\n",
      "  0.97307447 1.4364429  1.25371578 2.51020125 1.1095565  0.75459124\n",
      "  0.83459017 1.4081774  0.67033536 1.14897023 0.67526691 0.88956493\n",
      "  0.969289   1.51887964 1.12541327 1.29907639 1.30902963 0.94248048\n",
      "  1.14148674 0.7156991  0.90200681 2.4569242  0.86524637 1.28331876\n",
      "  1.28692979 1.26424485 1.20473793 1.08777455 1.3742659  0.74139344\n",
      "  0.91450619 0.9062525  1.78548274 1.23312194 0.99641222 0.80416728\n",
      "  0.98038691 1.28460452 1.35882079 0.69600206 1.33774913 0.68800114\n",
      "  1.35590564 0.64704342 1.06896629 2.90805385]]\n",
      "=========================================================================================\n",
      "Starting Pattern 6\n",
      "=========================================================================================\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #0\n",
      "[[1.77548376e-02 1.81519288e-02 1.26625983e-01 2.22450641e-02\n",
      "  1.11890807e-02 1.22734738e-01 1.70981734e-01 8.50716355e-02\n",
      "  6.25086412e-02 4.23107255e-02 2.03074814e-02 2.33000071e-02\n",
      "  2.75547168e-02 5.44207738e-02 1.52233552e-01 3.68630694e-02\n",
      "  3.56175814e-02 3.74158770e-02 5.79534750e-02 2.70734655e-02\n",
      "  3.43363176e-02 3.58815873e-02 4.50974546e-02 8.10849595e-02\n",
      "  1.58832753e-01 3.89756403e-02 2.49008941e-02 4.09179903e-02\n",
      "  3.38190164e-02 4.28890905e-02 1.59151804e-01 3.36057584e-02\n",
      "  9.57314415e-02 3.31143474e-02 7.50322207e-02 3.32770914e-02\n",
      "  2.38406979e-02 6.76464191e-02 2.15787419e-02 3.43363177e-02\n",
      "  2.71786554e-02 9.00983559e-02 2.85659320e-02 4.79128534e-02\n",
      "  1.77679752e-02 7.02773591e-02 4.87468041e-02 3.35165540e-02\n",
      "  4.38992225e-02 6.52090964e-02 3.60311057e-02 3.04506713e-02\n",
      "  3.94423083e-02 5.38456981e-02 3.48976508e-02 1.76745935e-01\n",
      "  3.44219703e-02 4.08678376e-02 4.19739957e-02 7.47528537e-02\n",
      "  5.65844010e-02 2.31852583e-02 4.17862733e-02 3.20354985e-02\n",
      "  4.72365741e-02 3.40554302e-02 4.18626026e-02 2.75336168e-02\n",
      "  4.75836258e-02 1.45336767e-01]\n",
      " [4.71578185e+00 5.82523735e+00 2.59165389e+00 2.30645119e+00\n",
      "  3.90694506e+00 6.62979861e+00 4.92729060e+00 3.78408834e+00\n",
      "  8.01537252e+00 4.57602219e+00 1.92893791e+00 2.47126226e+00\n",
      "  8.80240301e+00 1.11998760e+01 3.65290919e+00 2.64440057e+00\n",
      "  1.10165502e+01 5.09169451e+00 4.43211335e+00 4.20341182e+00\n",
      "  3.61755886e+00 8.10004069e+00 4.98611102e+00 3.43037615e+00\n",
      "  8.39404343e+00 7.34779801e+00 3.49480735e+00 3.31836568e+00\n",
      "  4.56462002e+00 3.44859033e+00 6.18892866e+00 6.47632238e+00\n",
      "  4.67622313e+00 3.83917133e+00 3.67424085e+00 3.07066908e+00\n",
      "  7.74051314e+00 7.33124613e+00 5.02637742e+00 3.61755891e+00\n",
      "  8.73102616e+00 7.83146774e+00 2.95626833e+00 4.48120578e+00\n",
      "  8.18269739e+00 9.79226401e+00 7.27675984e+00 3.07080147e+00\n",
      "  6.14957031e+00 5.04614592e+00 7.27032572e+00 8.34115152e+00\n",
      "  7.50925686e+00 2.98997765e+00 2.07391950e+00 2.58118761e+00\n",
      "  5.84825458e+00 3.38188412e+00 3.20228111e+00 3.88429621e+00\n",
      "  4.74237438e+00 1.35957061e+00 3.44987965e+00 4.17628646e+00\n",
      "  3.14509958e+00 5.71445245e+00 6.13596402e+00 4.60422243e+00\n",
      "  6.95235663e+00 9.97102480e+00]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #1\n",
      "[[0.02236471 0.02069979 0.08086779 0.03019447 0.02312542 0.08740186\n",
      "  0.04726762 0.07170529 0.04680676 0.02098937 0.02065562 0.02493141\n",
      "  0.02839327 0.04061029 0.07416522 0.03299027 0.035559   0.02186864\n",
      "  0.03429962 0.07248185 0.03278658 0.03366809 0.03329901 0.0737321\n",
      "  0.0618006  0.05963638 0.0333309  0.0207343  0.02271624 0.01860949\n",
      "  0.03717937 0.04752145 0.04701396 0.03128649 0.02626544 0.02592282\n",
      "  0.01141372 0.04818178 0.01642327 0.03278658 0.02644202 0.07375054\n",
      "  0.01232446 0.02337749 0.01140232 0.07331943 0.03664103 0.03043733\n",
      "  0.02948148 0.0382929  0.02130334 0.01253371 0.07841038 0.03258144\n",
      "  0.01843947 0.08422524 0.04876536 0.03114776 0.03578969 0.02553084\n",
      "  0.02999516 0.04233063 0.04099865 0.05190422 0.05664141 0.01260561\n",
      "  0.02926485 0.05909482 0.02365515 0.1501066 ]\n",
      " [0.76743629 0.92107479 0.96616825 1.0529561  1.16512647 1.13165618\n",
      "  1.00169018 0.97100179 0.92022569 0.67823833 0.92964382 1.20169152\n",
      "  1.03104681 0.9330302  0.98527588 0.89837757 1.7763118  0.71545326\n",
      "  0.94216254 1.19480468 1.25120782 0.98796204 0.95599113 0.95427009\n",
      "  1.05871545 1.19892558 1.16851363 0.75990324 0.96512333 0.7654615\n",
      "  0.82948643 1.25533553 0.9185332  1.01829433 0.96147485 0.89805341\n",
      "  0.7165048  1.1882891  0.94037655 1.25120782 1.23127625 1.15120239\n",
      "  0.66555313 0.74476023 0.79014515 5.10729813 0.98417672 0.9754559\n",
      "  0.96499239 0.95066096 1.00251391 0.57939002 1.31614625 0.84204049\n",
      "  0.7759806  0.86066659 0.9985939  1.14882063 0.91955969 0.71093568\n",
      "  0.93229027 1.25430515 1.69065196 0.87860603 1.27260825 0.64981665\n",
      "  1.21813002 0.92538902 1.06028062 4.61131964]]\n",
      "0.7674362877365674\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #2\n",
      "[[0.02519748 0.02506387 0.05897606 0.02111529 0.02155326 0.08614056\n",
      "  0.02711307 0.01862819 0.01603004 0.01773454 0.02081648 0.02520658\n",
      "  0.02888027 0.03447479 0.03822732 0.02129323 0.02747682 0.07337864\n",
      "  0.01642947 0.10997173 0.02190409 0.04211633 0.03194811 0.05638639\n",
      "  0.13382889 0.05993438 0.02916748 0.01669712 0.0164689  0.014698\n",
      "  0.0225291  0.04637892 0.05757016 0.02428522 0.02486787 0.01433395\n",
      "  0.00956204 0.043594   0.01278441 0.02190409 0.02557937 0.01913014\n",
      "  0.01438256 0.01734603 0.00834134 0.07430536 0.03385374 0.04290159\n",
      "  0.03658773 0.03065061 0.02448115 0.02081225 0.099326   0.02245834\n",
      "  0.011829   0.07156001 0.0622771  0.02535871 0.02659991 0.02409161\n",
      "  0.02905371 0.01851674 0.04093067 0.03646228 0.06733555 0.01414154\n",
      "  0.03019679 0.02488199 0.01517262 0.15137189]\n",
      " [0.78386049 1.09979644 0.72712119 0.85474436 1.092848   1.14233816\n",
      "  0.98547081 0.65588563 0.64568051 0.62392104 0.86419632 0.96476118\n",
      "  0.90121482 0.9386947  0.86081731 0.58659579 1.47357982 1.22346062\n",
      "  0.66503403 1.14081317 0.88592919 1.00079301 0.95430902 0.87773949\n",
      "  1.20629891 1.07175578 1.01076377 0.63835637 0.69411388 0.66211527\n",
      "  0.82675142 1.10405815 0.96485766 0.79934027 1.00850724 0.60549023\n",
      "  0.64872865 1.19147145 0.62861392 0.88592919 1.1130329  0.81186188\n",
      "  0.64218055 0.76546624 0.55461578 3.57459172 0.96501721 1.08712804\n",
      "  1.0289457  0.87375964 1.00382433 0.81554683 1.22026163 0.74330149\n",
      "  0.5558954  0.75764784 1.26464739 0.84696358 0.93805453 0.742869\n",
      "  0.80306643 0.69200179 1.56084833 0.98574005 1.08843535 0.73591318\n",
      "  1.12961545 0.8627817  0.67529886 4.2138334 ]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #3\n",
      "[[0.04834254 0.0319202  0.07197526 0.02681433 0.03237668 0.09771341\n",
      "  0.11313496 0.07826663 0.04033932 0.06318653 0.03061744 0.04149206\n",
      "  0.03084137 0.03397182 0.08533727 0.04981736 0.04033959 0.06749382\n",
      "  0.03276346 0.03342443 0.02043654 0.03429026 0.02701507 0.06023744\n",
      "  0.09900165 0.03945483 0.04766599 0.02428217 0.05261343 0.02979441\n",
      "  0.1004377  0.06673848 0.03626782 0.05285547 0.02817037 0.03053829\n",
      "  0.01537052 0.05563315 0.02293091 0.02043654 0.027087   0.07111022\n",
      "  0.03851597 0.03426884 0.01703838 0.08102949 0.03102075 0.06261591\n",
      "  0.03421747 0.04425204 0.02590984 0.02820272 0.08610929 0.03233725\n",
      "  0.02636837 0.08349344 0.03381198 0.04168712 0.06527253 0.03689956\n",
      "  0.03786632 0.06183144 0.04054528 0.03096379 0.07175195 0.01772305\n",
      "  0.02721021 0.11071463 0.0321226  0.16455676]\n",
      " [1.28219624 1.14429696 0.79982214 0.97826725 1.21876196 1.04884591\n",
      "  1.07830553 0.90445179 0.86341437 1.07742418 0.88235563 1.23049425\n",
      "  0.93374265 0.87576965 0.98332768 1.05329956 1.64347616 1.17143708\n",
      "  0.89298338 0.96515735 0.7034334  0.98383654 0.82400188 0.60991848\n",
      "  1.05224201 0.85538655 1.27990868 0.79288418 1.39296292 1.01418843\n",
      "  1.03752295 1.37791219 0.86055719 1.21245564 0.85295598 0.84291744\n",
      "  0.69908473 1.02310662 1.07111701 0.7034334  1.09424702 1.01985267\n",
      "  0.79332366 0.83894598 1.04389535 3.60693009 0.83439704 1.25670265\n",
      "  0.91215504 0.90274991 1.12624054 0.995468   1.19495992 0.94989528\n",
      "  0.79099017 0.63927746 0.93506191 1.24580837 0.98210072 0.84348993\n",
      "  0.97440773 1.27679146 1.37372911 0.93229533 1.41842939 0.86672694\n",
      "  0.89252931 1.05008803 0.89705485 4.33114783]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #4\n",
      "[[0.04688752 0.03147962 0.06047759 0.03086086 0.03302256 0.07624072\n",
      "  0.07148047 0.05007405 0.03629547 0.01670463 0.07864298 0.04139173\n",
      "  0.03237491 0.03263014 0.06196366 0.01939893 0.0393618  0.02368365\n",
      "  0.01930003 0.1420482  0.04115472 0.09568242 0.02381889 0.07798636\n",
      "  0.13231185 0.08706598 0.0548675  0.01553411 0.0288053  0.04283138\n",
      "  0.05343631 0.07489463 0.06117492 0.03993723 0.01698938 0.0238145\n",
      "  0.01600821 0.04539603 0.01922039 0.04115472 0.03672469 0.04232125\n",
      "  0.02267463 0.12053407 0.01258668 0.07391698 0.02349856 0.06202202\n",
      "  0.05603945 0.03192976 0.02892927 0.0136237  0.02724642 0.0161312\n",
      "  0.01243448 0.0811952  0.0524471  0.03757632 0.06224086 0.02371026\n",
      "  0.03037146 0.05714685 0.05285426 0.05845573 0.08961251 0.01028113\n",
      "  0.03781655 0.07735124 0.02180478 0.15604291]\n",
      " [1.12905303 1.14757958 0.72306713 1.23785086 1.21500739 0.99339126\n",
      "  1.11594754 0.79229138 0.82411653 0.64861058 1.21704447 1.19867881\n",
      "  1.01301392 0.85086257 1.02428646 0.59527938 1.54489529 0.79880243\n",
      "  0.69033425 1.18300385 1.29360066 1.11726283 0.7128644  1.0598596\n",
      "  1.16615565 1.27135519 1.23851951 0.62551896 1.12272667 0.86781908\n",
      "  0.88119935 1.21519122 0.86931665 1.15831465 0.78752782 0.85877763\n",
      "  0.86584453 1.02193298 0.99644678 1.29360066 1.28144543 0.90819214\n",
      "  0.83265742 1.0349361  0.81317833 3.28310451 0.66601114 1.2232823\n",
      "  1.26374057 0.76646805 1.20060929 0.64189836 0.6988213  0.60896677\n",
      "  0.56310288 0.80964697 1.23829632 1.12447428 1.05419256 0.77713761\n",
      "  0.97198304 1.20717265 1.52677791 0.92617602 1.22905052 0.5553473\n",
      "  1.25815262 0.98866216 0.89070391 4.36218538]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #5\n",
      "[[2.02044996e-02 2.61910834e-02 4.69547756e-02 1.71490756e-02\n",
      "  3.87011864e-03 5.49017083e-02 4.97710270e-02 3.68024197e-02\n",
      "  2.13293098e-02 1.78800695e-02 1.94847763e-02 4.18503337e-02\n",
      "  2.15073766e-02 1.85802595e-02 6.18076073e-02 2.09995282e-02\n",
      "  2.91060155e-02 1.50216229e-02 1.44433366e-02 1.76321487e-02\n",
      "  1.98356573e-02 1.59484327e-02 1.80503403e-02 4.79421389e-02\n",
      "  1.23850179e-01 2.48683475e-02 5.77688391e-02 1.85750251e-02\n",
      "  1.78945239e-02 2.00357370e-02 2.56022203e-02 3.10498385e-02\n",
      "  4.28957215e-02 2.88192734e-02 1.71135112e-02 1.55718610e-02\n",
      "  1.12376529e-02 3.50960985e-02 1.43638685e-02 1.98356573e-02\n",
      "  9.78237045e-03 4.33183492e-02 1.73855814e-02 2.12138827e-02\n",
      "  1.28277593e-02 6.32524872e-02 1.50904749e-02 4.46510739e-02\n",
      "  1.86308526e-02 1.99996487e-02 1.78347453e-02 1.67227068e-02\n",
      "  2.03083900e-02 3.68203096e-02 1.71110040e-02 7.28475498e-02\n",
      "  5.16696006e-02 1.84502793e-02 1.36589375e-02 2.22898099e-02\n",
      "  1.25314195e-02 1.96122750e-02 3.64226284e-02 1.46967595e-02\n",
      "  2.20758789e-02 1.44729603e-02 1.50450196e-02 1.67583075e-02\n",
      "  1.45895332e-02 1.49569419e-01]\n",
      " [6.88915119e-01 1.00794081e+00 7.40924149e-01 8.24373581e-01\n",
      "  4.91539820e-01 9.12087931e-01 9.36126336e-01 6.88614132e-01\n",
      "  5.53622698e-01 5.70674967e-01 1.30845563e+00 1.26364120e+00\n",
      "  7.10116048e-01 6.11854126e-01 8.82144318e-01 7.29961094e-01\n",
      "  1.89252750e+00 5.11071991e-01 4.92091397e-01 6.33773377e-01\n",
      "  1.01973467e+00 6.07301400e-01 5.92043283e-01 7.16768419e-01\n",
      "  1.11750333e+00 9.41225520e-01 1.27676989e+00 6.44304664e-01\n",
      "  1.02620311e+00 6.38534876e-01 6.72189996e-01 9.26805091e-01\n",
      "  7.25690155e-01 9.90401520e-01 7.26401665e-01 5.51772311e-01\n",
      "  8.62644024e-01 1.21213113e+00 9.22520007e-01 1.01973467e+00\n",
      "  6.44851508e-01 8.73106931e-01 6.63581150e-01 6.53868529e-01\n",
      "  9.19454126e-01 2.87671212e+00 4.79955255e-01 9.70264562e-01\n",
      "  8.36652497e-01 6.34346224e-01 7.07548428e-01 5.88202351e-01\n",
      "  5.03318013e-01 8.23809039e-01 7.07589673e-01 8.21444222e-01\n",
      "  1.09426834e+00 8.36764583e-01 4.54441983e-01 6.06956465e-01\n",
      "  4.94256716e-01 9.97889195e-01 1.66911902e+00 5.25380689e-01\n",
      "  5.97593381e-01 6.31227864e-01 5.22159086e-01 6.49002072e-01\n",
      "  7.26676954e-01 4.51167399e+00]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #6\n",
      "[[2.09923797e-02 2.12899269e-02 4.26648527e-02 8.87891536e-03\n",
      "  1.15103813e-02 4.40383563e-02 5.60670202e-02 3.81019175e-02\n",
      "  2.37432837e-02 9.28130528e-03 1.17774674e-02 2.53207414e-02\n",
      "  1.58533744e-02 3.03757207e-02 3.66789452e-02 2.07332643e-02\n",
      "  2.63698509e-02 2.17459724e-02 1.24100796e-02 8.41923052e-03\n",
      "  6.82729768e-03 1.93679572e-02 1.60553407e-02 2.94809028e-02\n",
      "  6.62060099e-02 2.03766550e-02 3.19625541e-02 1.16042261e-02\n",
      "  1.10652970e-02 1.56329011e-02 4.55432609e-02 3.07084645e-02\n",
      "  2.39909180e-02 2.67437674e-02 1.36567431e-02 8.81123979e-03\n",
      "  8.10571396e-03 3.14838600e-02 8.87385895e-03 6.82729765e-03\n",
      "  1.05184835e-02 2.21550305e-02 1.29318225e-02 3.41838734e-02\n",
      "  5.90171010e-03 6.32017715e-02 9.64678631e-03 3.77992373e-02\n",
      "  1.19619897e-02 1.30439750e-02 9.68529866e-03 1.02060589e-02\n",
      "  5.17535443e-02 1.50599684e-02 9.77406327e-03 4.56927443e-02\n",
      "  5.19641106e-02 3.58298467e-03 1.56912629e-02 1.60639532e-02\n",
      "  1.07460123e-02 1.18368223e-02 3.24504736e-02 1.80397773e-02\n",
      "  1.68832143e-02 6.60061222e-03 6.96847932e-03 2.11004345e-02\n",
      "  1.46040353e-02 1.44795133e-01]\n",
      " [6.06913607e-01 8.86321561e-01 5.61221761e-01 3.55115177e-01\n",
      "  7.50434725e-01 9.43860083e-01 9.64529931e-01 6.96745844e-01\n",
      "  6.06593553e-01 2.85798587e-01 5.96848088e-01 1.12845049e+00\n",
      "  6.12717309e-01 7.92568551e-01 6.79357865e-01 5.65721321e-01\n",
      "  1.61407191e+00 5.95766613e-01 4.89029278e-01 3.30230321e-01\n",
      "  3.51033079e-01 5.16831513e-01 5.80908991e-01 3.61472607e-01\n",
      "  9.95063186e-01 5.57213842e-01 1.17372546e+00 4.61365086e-01\n",
      "  4.92834630e-01 5.55224360e-01 8.64064582e-01 1.08555009e+00\n",
      "  5.77265366e-01 8.67985935e-01 6.53073253e-01 3.96381147e-01\n",
      "  4.58866942e-01 8.50030470e-01 4.78023236e-01 3.51033078e-01\n",
      "  5.51492148e-01 7.43966827e-01 6.49159358e-01 7.29766056e-01\n",
      "  4.34421558e-01 2.35322310e+00 3.75880516e-01 1.09928168e+00\n",
      "  4.79702352e-01 4.03606180e-01 5.23051215e-01 4.19406169e-01\n",
      "  8.74026960e-01 5.66445175e-01 4.00417392e-01 5.00202796e-01\n",
      "  1.39103617e+00 1.40490242e-01 5.27275859e-01 5.17471432e-01\n",
      "  3.72994851e-01 4.19520849e-01 1.16993783e+00 5.80671837e-01\n",
      "  4.62687287e-01 4.02615675e-01 2.92769179e-01 6.87291594e-01\n",
      "  7.88036539e-01 4.80305313e+00]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #7\n",
      "[[4.58245672e-02 2.95545249e-02 5.72841919e-02 8.87219756e-03\n",
      "  1.02418527e-02 4.14294469e-02 6.81301175e-02 3.17880119e-02\n",
      "  2.01108370e-02 1.25031157e-02 4.05706168e-03 3.85601631e-02\n",
      "  1.09186193e-02 1.69996064e-02 6.97965942e-02 1.07349114e-02\n",
      "  2.55885392e-02 2.58678939e-02 1.62672661e-02 7.65072716e-03\n",
      "  1.02046977e-02 1.29686635e-02 1.92003569e-02 4.98781531e-02\n",
      "  5.33567108e-02 1.14369190e-02 5.15934704e-02 9.11378899e-03\n",
      "  8.96555751e-03 8.40981577e-03 5.82044910e-02 3.92961696e-02\n",
      "  2.78145212e-02 3.97307329e-02 1.22292921e-02 9.00162132e-03\n",
      "  4.53020041e-03 3.18562890e-02 5.09841911e-03 1.02046977e-02\n",
      "  6.13798740e-03 3.14601054e-02 7.64011439e-03 4.43679357e-02\n",
      "  4.32657479e-03 6.98828735e-02 2.62721210e-02 5.71312003e-02\n",
      "  6.99999042e-03 2.03468420e-02 1.23398183e-02 8.52566445e-03\n",
      "  8.94694144e-02 1.30922959e-02 9.20627674e-03 4.33621665e-02\n",
      "  4.25627130e-02 5.96207237e-03 3.40299269e-02 1.63688693e-02\n",
      "  1.64921622e-02 6.56552559e-03 3.20949481e-02 1.21526168e-02\n",
      "  1.69467905e-02 7.32155016e-03 1.19859585e-02 2.96373625e-02\n",
      "  1.94524743e-02 1.47756537e-01]\n",
      " [1.13759953e+00 1.09243752e+00 8.72537998e-01 3.96509810e-01\n",
      "  7.22434373e-01 9.09101648e-01 1.01525889e+00 6.43096924e-01\n",
      "  5.57260352e-01 4.04170522e-01 2.08268842e-01 1.25073253e+00\n",
      "  4.09807723e-01 6.03641008e-01 9.28828637e-01 3.30313187e-01\n",
      "  1.54058360e+00 7.49674424e-01 5.59851371e-01 3.28165200e-01\n",
      "  3.93467479e-01 4.45626352e-01 6.52689826e-01 7.38279376e-01\n",
      "  9.78664661e-01 3.48487014e-01 1.27156305e+00 3.89045637e-01\n",
      "  4.36364837e-01 3.35973522e-01 9.66768117e-01 1.15605428e+00\n",
      "  6.09673719e-01 9.31658350e-01 6.03581995e-01 3.36706819e-01\n",
      "  3.08556482e-01 7.71391762e-01 3.05667554e-01 3.93467478e-01\n",
      "  3.53404845e-01 8.60387997e-01 3.41336988e-01 8.27709618e-01\n",
      "  3.04267342e-01 3.22109926e+00 7.23253143e-01 1.24412224e+00\n",
      "  2.97169403e-01 6.06129863e-01 5.67109598e-01 3.81977669e-01\n",
      "  1.01704873e+00 4.62587273e-01 3.83525205e-01 4.20689935e-01\n",
      "  1.32038071e+00 2.63580663e-01 7.77083583e-01 5.21256797e-01\n",
      "  5.53037975e-01 2.56979311e-01 1.22674733e+00 4.90518019e-01\n",
      "  4.90756472e-01 4.23127960e-01 4.84504960e-01 7.61171682e-01\n",
      "  9.00921337e-01 4.66530882e+00]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #8\n",
      "[[0.04005506 0.0320846  0.07585664 0.03308555 0.02667562 0.08947539\n",
      "  0.0541566  0.06150252 0.01762927 0.02234923 0.03355007 0.03149275\n",
      "  0.03803328 0.03669841 0.05241104 0.02008565 0.03667104 0.06924138\n",
      "  0.02060811 0.11598227 0.03701999 0.03591016 0.01764093 0.07634103\n",
      "  0.07864135 0.08465639 0.05598965 0.01392238 0.02036083 0.01278263\n",
      "  0.04691949 0.05832203 0.04956474 0.04576094 0.02555865 0.02106174\n",
      "  0.01470228 0.05117223 0.01703639 0.03701999 0.02853892 0.03352256\n",
      "  0.02159093 0.01400703 0.00709712 0.07543438 0.03698892 0.03574387\n",
      "  0.03721212 0.02915107 0.01648202 0.01702613 0.12871062 0.02250409\n",
      "  0.01298138 0.07903602 0.06002383 0.03926974 0.02460233 0.03174554\n",
      "  0.02168524 0.0324766  0.0429456  0.02500569 0.09155826 0.00943501\n",
      "  0.03765227 0.01530672 0.02254996 0.15789311]\n",
      " [1.29333868 1.24893093 0.973829   1.28756536 1.28914694 1.22776513\n",
      "  1.15946315 1.07224347 0.71914003 0.82517563 1.62371607 1.22286204\n",
      "  1.4113019  0.98873271 1.12002633 0.76411264 2.0257605  1.17184804\n",
      "  0.82274674 1.25127091 1.58717719 0.99764495 0.71399812 0.98903727\n",
      "  1.12041801 1.26271301 1.30893087 0.64910626 1.04278625 0.59089019\n",
      "  0.92142239 1.43870326 1.08241515 1.19425053 1.12297198 0.97112649\n",
      "  1.03008436 1.53806401 1.26012076 1.58717719 1.38097045 0.93052085\n",
      "  1.06090505 0.57118498 0.57555099 4.0251123  1.07579072 1.22298047\n",
      "  1.65356854 0.91790834 0.79251515 0.76840552 1.43995974 0.83185554\n",
      "  0.61689636 0.91887105 1.20814448 1.37450713 1.00898067 1.22539888\n",
      "  0.83397679 1.23105254 2.01083012 0.96261109 1.22535236 0.58491387\n",
      "  1.64957867 0.70479817 1.31813372 4.85826585]]\n",
      "Serie fuzzification\n",
      "Creating for lag values\n",
      "Step 1 - Fuzzification\n",
      "Step 2 - Formulation\n",
      "Step 3 - Split\n",
      "Step 4 - Filter\n",
      "Step 5 - Reweight\n",
      "Step 6 - Defuzzification\n",
      "Predict on validation set - #9\n",
      "[[0.0431074  0.03644213 0.09668545 0.0436818  0.03151225 0.1016923\n",
      "  0.03818253 0.03899718 0.04159168 0.03953077 0.03159421 0.04386469\n",
      "  0.04602027 0.03514162 0.04583248 0.03928198 0.03836805 0.06914163\n",
      "  0.02270214 0.05605487 0.02460706 0.04535556 0.04227873 0.09943552\n",
      "  0.09345229 0.07159495 0.06700756 0.02634066 0.03623605 0.0290687\n",
      "  0.03406912 0.07273687 0.05223    0.04825924 0.03151799 0.02591767\n",
      "  0.01866875 0.05358797 0.02308175 0.02460706 0.02793272 0.07176854\n",
      "  0.02900156 0.02573191 0.01740575 0.07512478 0.02859958 0.06138694\n",
      "  0.05000185 0.0396632  0.03068749 0.02801511 0.10336501 0.03119524\n",
      "  0.02422996 0.129485   0.06336455 0.04474822 0.0314382  0.03613519\n",
      "  0.03749721 0.04577609 0.04469374 0.03764982 0.08058368 0.02089433\n",
      "  0.05042589 0.02891498 0.02254353 0.15266827]\n",
      " [1.10588947 1.27242129 2.38083596 1.26455705 1.37182259 1.0688449\n",
      "  1.18222159 1.61370741 0.93733633 1.3476456  1.15808083 1.29640429\n",
      "  1.27886641 0.96386242 1.31403864 1.37311285 2.19455547 1.11075969\n",
      "  0.90775071 1.07170152 1.07286501 1.18498598 1.00142388 1.66845269\n",
      "  1.06284331 1.31844396 1.33667087 1.16782915 1.43492775 1.44401766\n",
      "  1.20806384 1.41388994 0.99367239 1.26405974 1.02781806 1.27114468\n",
      "  1.38754265 2.21673756 1.26078    1.07286501 1.18618767 1.05865728\n",
      "  1.57875224 1.59626679 1.41594363 4.25428901 1.38424941 1.31061277\n",
      "  1.19501351 1.24168417 1.21551741 1.31294906 1.1340794  1.12087501\n",
      "  1.28860496 2.81643398 1.38017829 1.32865101 1.31679052 1.08246048\n",
      "  1.09064137 1.22965823 1.7630969  1.15380494 1.36092691 1.00855946\n",
      "  1.29021955 1.31001792 1.84126069 4.04207243]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 23 is out of bounds for axis 0 with size 14",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 258\u001b[0m\n\u001b[0;32m    253\u001b[0m wd_ \u001b[39m=\u001b[39m list_rules[k]\u001b[39m.\u001b[39mwd_\n\u001b[0;32m    255\u001b[0m initial_values \u001b[39m=\u001b[39m all_lagged[yp_lagged\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39mh_p,:]\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 258\u001b[0m yt_totest, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(initial_values, \n\u001b[0;32m    259\u001b[0m                              data\u001b[39m=\u001b[39;49mtrain_values, \n\u001b[0;32m    260\u001b[0m                              in_sample \u001b[39m=\u001b[39;49m yt, \n\u001b[0;32m    261\u001b[0m                              out_sample\u001b[39m=\u001b[39;49mout_sample, \n\u001b[0;32m    262\u001b[0m                              agg_training\u001b[39m=\u001b[39;49magg_training,\n\u001b[0;32m    263\u001b[0m                              h_prev\u001b[39m=\u001b[39;49m\u001b[39m24\u001b[39;49m,\n\u001b[0;32m    264\u001b[0m                              n_attempt\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mp_subsample_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    265\u001b[0m                              wd_\u001b[39m=\u001b[39;49mwd_,\n\u001b[0;32m    266\u001b[0m                              ensemble_antecedents\u001b[39m=\u001b[39;49mensemble_antecedents,\n\u001b[0;32m    267\u001b[0m                              ensemble_rules\u001b[39m=\u001b[39;49mensemble_rules, \n\u001b[0;32m    268\u001b[0m                              filepath\u001b[39m=\u001b[39;49mfilepath, \n\u001b[0;32m    269\u001b[0m                              lim\u001b[39m=\u001b[39;49mmin_error, \n\u001b[0;32m    270\u001b[0m                              fig_axis\u001b[39m=\u001b[39;49m[num_series,\u001b[39m2\u001b[39;49m],\n\u001b[0;32m    271\u001b[0m                              ndata\u001b[39m=\u001b[39;49mdataset,\n\u001b[0;32m    272\u001b[0m                              show\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    274\u001b[0m \u001b[39m# print(k)\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m (h_p\u001b[39m+\u001b[39m\u001b[39m24\u001b[39m \u001b[39m>\u001b[39m predicted_values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[1;32md:\\Users\\lemos\\Dissertacao\\Traffic_Rate\\eautoMFIS_V2.py:356\u001b[0m, in \u001b[0;36mautoMFIS.predict\u001b[1;34m(self, initial_values, lags_used, ndata, data, in_sample, out_sample, agg_training, h_prev, n_attempt, wd_, ensemble_antecedents, ensemble_rules, not_used_lag, filepath, lim, fig_axis, show, plot_image)\u001b[0m\n\u001b[0;32m    354\u001b[0m         rule \u001b[39m=\u001b[39m ensemble_rules[j,i]\n\u001b[0;32m    355\u001b[0m         consequent \u001b[39m=\u001b[39m rule[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 356\u001b[0m         agg_test[j,consequent[\u001b[39m1\u001b[39;49m],i] \u001b[39m=\u001b[39m prem_activated[j,]\n\u001b[0;32m    358\u001b[0m weight_agg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(agg_test,wd_)\n\u001b[0;32m    359\u001b[0m weight_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((weight_agg\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],weight_agg\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]))\n",
      "\u001b[1;31mIndexError\u001b[0m: index 23 is out of bounds for axis 0 with size 14"
     ]
    }
   ],
   "source": [
    "predicted_values = np.zeros((h_test, dataset.shape[1]))\n",
    "\n",
    "train_values = training_values[:,:num_series]\n",
    "test_values = test_data.values[:,:num_series]\n",
    "\n",
    "# train_values = data_[:, :num_series]\n",
    "# test_values = test_data_2.values[:,:num_series]\n",
    "\n",
    "print('Initialization')\n",
    "preprocess_data, training_set, val_set, yt, yp, yp_lagged, all_yt, all_yp, all_lagged = preprocess_external(train_values,h_val,num_series, train_values, test_values, lag)\n",
    "# preprocess_data, training_set, val_set, yt, yp, yp_lagged, all_yt, all_yp, all_lagged = preprocess_external(train_values,h_val,num_series, train_values, test_values, lag, all_data= all_data_2)\n",
    "# print('Initialization')\n",
    "\n",
    "_Fuzzyfy, _mX_, _mY_, _mf_params_, _mX_lagged_ = fuzzy_external(fuzzy_method, num_series, training_set, num_groups, yp_lagged, lag)\n",
    "\n",
    "linear_auto_corr = preprocess_data.linear_acf_weights(in_sample = train_values)\n",
    "\n",
    "linear_cross_corr = preprocess_data.spearman_corr_weights(in_sample = train_values)\n",
    "\n",
    "\n",
    "#Initialization of model\n",
    "manual_pattern = 7\n",
    "print('Start')\n",
    "#Creation a list of rule object. \n",
    "list_rules = [rule_object(None,None,None,None,i) for i in range(7)]\n",
    "\n",
    "list_best_rules = [rule_object(None,None,None,None,i) for i in range(7)]\n",
    "\n",
    "best_t_mX_lagged_list = [None]*manual_pattern\n",
    "\n",
    "best_agg_training_list = [None]*manual_pattern\n",
    "\n",
    "for n_pattern in range(manual_pattern):\n",
    "\n",
    "    min_error = 300.0\n",
    "\n",
    "    bres = min_error\n",
    "\n",
    "    j = 0\n",
    "\n",
    "    print('='*89)\n",
    "    print(f'Starting Pattern {n_pattern}')\n",
    "    print('='*89)\n",
    "    #Select a sample pattern for our problem. In that case, we apply a manual pattern on dataset\n",
    "    t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "    t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "    \n",
    "    t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "    \n",
    "    yp1 = deepcopy(yp[t_lagged,:])\n",
    "    \n",
    "    yt1 = deepcopy(yt[t_lagged,:])\n",
    "    \n",
    "    yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "    input_sample = training_set[t,:]\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(in_sample)\n",
    "    #plt.show()\n",
    "    out_sample = val_set[t_val,:]\n",
    "    \n",
    "    #Iintial values for prediction\n",
    "    initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\n",
    "    \n",
    "    #Always checking if initial values are correct by asserting it's target\n",
    "    #assert (all_yt[yp_lagged.shape[0] + t_val[0],:] == out_sample[0,:]).all(), 'Target mismatch. Verify initial values lag.'\n",
    "\n",
    "    #print(f'Shape of in-sample is {in_sample.shape[0]}')\n",
    "    #assert in_sample.shape[0] == h_train//7\n",
    "    #print(f'Shape of lagged data is {yp_lagged1.shape[0]}')\n",
    "    #assert yp_lagged1.shape[0] == h_train//manual_pattern\n",
    "    #print(f'Shape of validation set is {out_sample.shape[0]}')\n",
    "    #assert out_sample.shape[0] == h_val//manual_pattern\n",
    "    #data1 = deepcopy(data_[t[len(t)-len(t_lagged):],:])\n",
    "    #in_sample = data1[:data1.shape[0]-h_prev,:]\n",
    "    #out_sample = data1[data1.shape[0]-h_prev:,:]\n",
    "    #ensemble_rules = list_rules[n_pattern].complete_rules \n",
    "    #ensemble_prem_terms = list_rules[n_pattern].prem_terms\n",
    "    #ensemble_antecedents = list_rules[n_pattern].rules\n",
    "\n",
    "    #Concatenate rules\n",
    "    for i in range(num_predictors):\n",
    "        \n",
    "        _, _, yp_lagged_ = preprocess_data.generate_subsamples(correlation_array=linear_cross_corr,\n",
    "                                                               autocorrelation_matrix=linear_auto_corr,\n",
    "                                                               num_inputs=num_input, \n",
    "                                                               in_sample=train_values, \n",
    "                                                               yt = yt, \n",
    "                                                               yp = yp, \n",
    "                                                               yp_lagged = deepcopy(yp_lagged))\n",
    "    \n",
    "        Fuzzyfy, mX_, mY_, mf_params_, mX_lagged_ = fuzzy_external(fuzzy_method, num_series, training_set, num_groups, yp, yt, deepcopy(yp_lagged_), lag)\n",
    "    \n",
    "        # not_select_subsample = np.random.choice(total_number,total_number-num_input,replace=False)\n",
    "        n_mX = deepcopy(mX_lagged_)\n",
    "        # n_mX[:,:,not_select_subsample] = 0\n",
    "        model = autoMFIS(diff_series=diff_series,\n",
    "                         detrend_series=detrend_series,\n",
    "                         fuzzy_method=fuzzy_method,\n",
    "                         solve_method='mqr',\n",
    "                         defuzz_method=defuzz_method, \n",
    "                         num_groups = num_groups, \n",
    "                         h_prev = h_val, \n",
    "                         num_series = num_series, \n",
    "                         max_rulesize = max_rulesize, \n",
    "                         min_activation = min_activation, \n",
    "                         lag = lag,\n",
    "                         target_position = 1,\n",
    "                         hide_values = False, \n",
    "                         form_method = 'nmean', \n",
    "                         split_method = 'FCD')\n",
    "\n",
    "        model.set_fuzzification(Fuzzyfy, mf_params_, mX_, mY_, n_mX)\n",
    "\n",
    "        try:\n",
    "            \n",
    "            t_mX_lagged, complete_rules, prem_terms, rules, agg_training, wd_ = model.train(data = train_values,\n",
    "                                                                                            yt=yt1,\n",
    "                                                                                            yp=yp1,\n",
    "                                                                                            yp_lagged=yp_lagged1,\n",
    "                                                                                            correlation_array = linear_cross_corr, \n",
    "                                                                                            autocorrelation_matrix = linear_auto_corr,\n",
    "                                                                                            in_sample=input_sample,\n",
    "                                                                                            out_sample=out_sample,\n",
    "                                                                                            lag_notused=[],\n",
    "                                                                                            debug=True)\n",
    "\n",
    "\n",
    "            #complete_rules, prem_terms, rules, agg_training, wd_ = autoMFIS(data_,lag=lag, lag_notused=lag_notused, not_used_lag=not_used_lag,not_select_subsample=not_select_subsample, h_prev = out_sample.shape[0], diff_series=diff_series, detrend_series=detrend_series, num_series=num_series, max_rulesize=max_rulesize, min_activation=min_activation, fuzzy_method=fuzzy_method, num_groups=num_groups,solve_method='mqr',defuzz_method=defuzz_method,yt=yt1,yp=yp1,yp_lagged=yp_lagged1,in_sample=in_sample,out_sample=out_sample)\n",
    "            print(f'Predict on validation set - #{i}')\n",
    "            #Prediction of a single subset\n",
    "            yt_totest, errors = model.predict(initial_values,\n",
    "                                              data=train_values,\n",
    "                                              in_sample=input_sample, \n",
    "                                              out_sample=out_sample, \n",
    "                                              agg_training=agg_training,\n",
    "                                              h_prev=out_sample.shape[0],\n",
    "                                              n_attempt=f'p_{n_pattern}_subsample_{i}',\n",
    "                                              wd_=wd_,\n",
    "                                              ensemble_antecedents=rules,\n",
    "                                              ensemble_rules=complete_rules, \n",
    "                                              filepath=filepath, \n",
    "                                              lim=3.0, \n",
    "                                              fig_axis=[num_series,1],\n",
    "                                              ndata=dataset)\n",
    "\n",
    "            #errors = predict(Fuzzyfy, lags_used = [], num_groups=num_groups, ndata=dataset, data=data_,in_sample=in_sample,out_sample=out_sample, lag = lag, mf_params_=mf_params_,num_series=num_series,agg_training=agg_training,yp_lagged=yp_lagged1,h_prev=out_sample.shape[0],not_used_lag=not_used_lag,n_attempt=f'p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules,filepath=filepath,lim=3.0,defuzz_method=defuzz_method,fig_axis=[2,2])\n",
    "            print(errors)\n",
    "            #print(complete_rules)\n",
    "            '''\n",
    "            if errors[1,0] < 0.6:\n",
    "                if ensemble_rules is None:\n",
    "                    ensemble_rules = complete_rules\n",
    "                    ensemble_prem_terms = prem_terms\n",
    "                    ensemble_antecedents = rules\n",
    "                    #print(ensemble_rules.shape)\n",
    "                else:\n",
    "                    ensemble_rules = np.concatenate((ensemble_rules, complete_rules))\n",
    "\n",
    "                    ensemble_prem_terms = np.concatenate((ensemble_prem_terms,prem_terms))\n",
    "                    ensemble_antecedents = np.concatenate((ensemble_antecedents,rules))\n",
    "                    #print(ensemble_rules.shape)\n",
    "                    #print(ensemble_prem_terms.shape)\n",
    "                #print(ensemble_rules[:,0])\n",
    "            elif ensemble_rules is None and i == num_predictors - 1:\n",
    "                ensemble_rules = complete_rules\n",
    "                ensemble_prem_terms = prem_terms\n",
    "                ensemble_antecedents = rules\n",
    "                print('No rules match criteria. Using rules to fill the gap')\n",
    "            #print('RMSE Errors = {}'.format(errors[0,:]))\n",
    "            print('RRSE Errors = {}'.format(errors[1,:]))\n",
    "            #print('Mean RRSE Error = {}'.format(np.mean(errors[1,:])))\n",
    "            '''\n",
    "\n",
    "            if errors[1,0] < bres:\n",
    "                bres = errors[1,0] \n",
    "                list_best_rules[n_pattern].complete_rules = deepcopy(complete_rules)\n",
    "                list_best_rules[n_pattern].prem_terms = deepcopy(prem_terms)\n",
    "                list_best_rules[n_pattern].rules = deepcopy(rules) \n",
    "                list_best_rules[n_pattern].wd_ = deepcopy(wd_)\n",
    "                best_agg_training_list[n_pattern] = deepcopy(agg_training)\n",
    "                best_t_mX_lagged_list[n_pattern] = deepcopy(t_mX_lagged)\n",
    "\n",
    "            if errors[1,0] < 0.7:\n",
    "                if j == 0:\n",
    "                    print(errors[1,0])\n",
    "                    ensemble_rules = deepcopy(complete_rules)\n",
    "                    ensemble_prem_terms = deepcopy(prem_terms)\n",
    "                    ensemble_antecedents = deepcopy(rules)\n",
    "                    wd__ = deepcopy(wd_)\n",
    "                    min_error = errors[1,0]\n",
    "                    j += 1\n",
    "                    #print(f'Min error found = {min_error}')\n",
    "                else:\n",
    "                    ensemble_rules = np.concatenate((deepcopy(ensemble_rules), deepcopy(complete_rules)))\n",
    "                \n",
    "                    ensemble_prem_terms = np.concatenate((deepcopy(ensemble_prem_terms),deepcopy(prem_terms)))\n",
    "                    ensemble_antecedents = np.concatenate((deepcopy(ensemble_antecedents),deepcopy(rules)))\n",
    "            elif ensemble_rules is None and i == num_predictors - 1:\n",
    "                ensemble_rules = deepcopy(complete_rules)\n",
    "                ensemble_prem_terms = deepcopy(prem_terms)\n",
    "                ensemble_antecedents = deepcopy(rules)\n",
    "                print('No rules match criteria. Using rules to fill the gap')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    list_rules[n_pattern].complete_rules = deepcopy(ensemble_rules)\n",
    "    list_rules[n_pattern].prem_terms = deepcopy(ensemble_prem_terms)\n",
    "    list_rules[n_pattern].rules = deepcopy(ensemble_antecedents)\n",
    "    list_rules[n_pattern].wd_ = deepcopy(wd__)\n",
    "\n",
    "\n",
    "\n",
    "# init = input_sample.shape[0]\n",
    "# for h_p in range(0,h_test,24):\n",
    "\n",
    "#     rem = h_p % 168\n",
    "\n",
    "#     k = rem // 24\n",
    "\n",
    "#     #print(f'Debug only, rem = {rem} and k = {k}')\n",
    "#     #print('='*89)\n",
    "#     ensemble_antecedents = list_rules[k].rules\n",
    "#     ensemble_rules = list_rules[k].complete_rules\n",
    "#     wd_ = list_rules[k].wd_\n",
    "\n",
    "#     initial_values = all_lagged[yp_lagged.shape[0]+h_p,:num_series].reshape(1,-1)\n",
    "\n",
    "\n",
    "#     yt_totest, _ = model.predict(initial_values, data=train_values, in_sample = yt, out_sample=out_sample, agg_training=agg_training, h_prev=24,n_attempt=f'p_subsample_{i}',wd_=wd_,ensemble_antecedents=ensemble_antecedents,ensemble_rules=ensemble_rules, filepath=filepath, lim=min_error, fig_axis=[num_series,2],ndata=dataset,show=False)\n",
    "\n",
    "#     #print(k)\n",
    "#     if (h_p+24 > predicted_values.shape[0]):\n",
    "#         bb = predicted_values.shape[0] - h_p\n",
    "#         predicted_values[h_p:h_p+bb,:] = yt_totest[0:bb]\n",
    "#     else:\n",
    "#         predicted_values[h_p:h_p+24,:] = yt_totest\n",
    "\n",
    "# model.set_fuzzification(_Fuzzyfy, _mX_, _mY_, _mf_params_, _mX_lagged_)\n",
    "# predicted_values = np.zeros((h_test, num_series))\n",
    "# init = input_sample.shape[0]\n",
    "# for h_p in range(0,h_test,24):\n",
    "\n",
    "#     rem = h_p % 168\n",
    "\n",
    "#     k = rem // 24\n",
    "\n",
    "#     #print(f'Debug only, rem = {rem} and k = {k}')\n",
    "#     #print('='*89)\n",
    "#     ensemble_antecedents = list_rules[k].rules\n",
    "#     ensemble_prem_terms = list_rules[k].prem_terms\n",
    "#     ensemble_rules = list_rules[k].complete_rules\n",
    "#     # wd_ = list_rules[k].wd_\n",
    "\n",
    "#     ensemble_wd_, ensemble_agg_training = model.reweight_mf(_mY_,ensemble_rules,ensemble_prem_terms)\n",
    "\n",
    "#     initial_values = all_lagged[yp_lagged.shape[0]+h_p,:].reshape(1,-1)\n",
    "\n",
    "\n",
    "#     yt_totest, _ = model.predict(initial_values, \n",
    "#                                  data=train_values, \n",
    "#                                  in_sample = yt, \n",
    "#                                  out_sample=out_sample, \n",
    "#                                  agg_training=agg_training,\n",
    "#                                  h_prev=24,\n",
    "#                                  n_attempt=f'p_subsample_{i}',\n",
    "#                                  wd_=wd_,\n",
    "#                                  ensemble_antecedents=ensemble_antecedents,\n",
    "#                                  ensemble_rules=ensemble_rules, \n",
    "#                                  filepath=filepath, \n",
    "#                                  lim=min_error, \n",
    "#                                  fig_axis=[num_series,2],\n",
    "#                                  ndata=dataset,\n",
    "#                                  show=False)\n",
    "\n",
    "#     # print(k)\n",
    "#     if (h_p+24 > predicted_values.shape[0]):\n",
    "#         bb = predicted_values.shape[0] - h_p\n",
    "#         predicted_values[h_p:h_p+bb,:] = yt_totest[0:bb]\n",
    "#     else:\n",
    "#         predicted_values[h_p:h_p+24,:] = yt_totest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predicted_values = np.zeros((h_test, num_series))\n",
    "init = input_sample.shape[0]\n",
    "for h_p in range(0,h_test,24):\n",
    "\n",
    "    rem = h_p % 168\n",
    "\n",
    "    k = rem // 24\n",
    "\n",
    "    best_t_mX_lagged = best_t_mX_lagged_list[k]\n",
    "\n",
    "    model.set_fuzzification(_Fuzzyfy, _mX_, _mY_, _mf_params_, deepcopy(best_t_mX_lagged))\n",
    "\n",
    "    #print(f'Debug only, rem = {rem} and k = {k}')\n",
    "    #print('='*89)\n",
    "    best_antecedents = list_best_rules[k].rules\n",
    "    best_rules = list_best_rules[k].complete_rules\n",
    "    best_wd_ = list_rules[k].wd_\n",
    "    best_agg_training = best_agg_training_list[k]\n",
    "\n",
    "\n",
    "    initial_values = all_lagged[yp_lagged.shape[0]+h_p,:].reshape(1,-1)\n",
    "\n",
    "\n",
    "    yt_totest, _ = model.predict(initial_values, \n",
    "                                 data=train_values, \n",
    "                                 in_sample = yt, \n",
    "                                 out_sample=out_sample, \n",
    "                                 agg_training=best_agg_training,\n",
    "                                 h_prev=24,\n",
    "                                 n_attempt=f'p_subsample_{i}',\n",
    "                                 wd_=best_wd_,\n",
    "                                 ensemble_antecedents=best_antecedents,\n",
    "                                 ensemble_rules=best_rules, \n",
    "                                 filepath=filepath, \n",
    "                                 lim=min_error, \n",
    "                                 fig_axis=[num_series,2],\n",
    "                                 ndata=dataset,\n",
    "                                 show=False)\n",
    "\n",
    "    # print(k)\n",
    "    if (h_p+24 > best_predicted_values.shape[0]):\n",
    "        bb = best_predicted_values.shape[0] - h_p\n",
    "        best_predicted_values[h_p:h_p+bb,:] = yt_totest[0:bb]\n",
    "    else:\n",
    "        best_predicted_values[h_p:h_p+24,:] = yt_totest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 30 is out of bounds for axis 0 with size 21",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m wd_ \u001b[39m=\u001b[39m list_rules[k]\u001b[39m.\u001b[39mwd_\n\u001b[0;32m     15\u001b[0m initial_values \u001b[39m=\u001b[39m all_lagged[yp_lagged\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39mh_p,:]\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m yt_totest, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(initial_values, data\u001b[39m=\u001b[39;49mtrain_values, in_sample \u001b[39m=\u001b[39;49m yt, out_sample\u001b[39m=\u001b[39;49mout_sample, agg_training\u001b[39m=\u001b[39;49magg_training,h_prev\u001b[39m=\u001b[39;49m\u001b[39m24\u001b[39;49m,n_attempt\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mp_subsample_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m,wd_\u001b[39m=\u001b[39;49mwd_,ensemble_antecedents\u001b[39m=\u001b[39;49mensemble_antecedents,ensemble_rules\u001b[39m=\u001b[39;49mensemble_rules, filepath\u001b[39m=\u001b[39;49mfilepath, lim\u001b[39m=\u001b[39;49mmin_error, fig_axis\u001b[39m=\u001b[39;49m[num_series,\u001b[39m2\u001b[39;49m],ndata\u001b[39m=\u001b[39;49mdataset,show\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(k)\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m (h_p\u001b[39m+\u001b[39m\u001b[39m24\u001b[39m \u001b[39m>\u001b[39m predicted_values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[1;32md:\\Users\\lemos\\Dissertacao\\Traffic_Rate\\eautoMFIS_V2.py:356\u001b[0m, in \u001b[0;36mautoMFIS.predict\u001b[1;34m(self, initial_values, lags_used, ndata, data, in_sample, out_sample, agg_training, h_prev, n_attempt, wd_, ensemble_antecedents, ensemble_rules, not_used_lag, filepath, lim, fig_axis, show, plot_image)\u001b[0m\n\u001b[0;32m    354\u001b[0m         rule \u001b[39m=\u001b[39m ensemble_rules[j,i]\n\u001b[0;32m    355\u001b[0m         consequent \u001b[39m=\u001b[39m rule[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 356\u001b[0m         agg_test[j,consequent[\u001b[39m1\u001b[39;49m],i] \u001b[39m=\u001b[39m prem_activated[j,]\n\u001b[0;32m    358\u001b[0m weight_agg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(agg_test,wd_)\n\u001b[0;32m    359\u001b[0m weight_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((weight_agg\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],weight_agg\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]))\n",
      "\u001b[1;31mIndexError\u001b[0m: index 30 is out of bounds for axis 0 with size 21"
     ]
    }
   ],
   "source": [
    "model.set_fuzzification(_Fuzzyfy, _mX_, _mY_, _mf_params_, _mX_lagged_)\n",
    "\n",
    "ensemble_predicted_values = np.zeros((h_test, num_series))\n",
    "init = input_sample.shape[0]\n",
    "for h_p in range(0,h_test,24):\n",
    "\n",
    "    rem = h_p % 168\n",
    "\n",
    "    k = rem // 24\n",
    "\n",
    "    #print(f'Debug only, rem = {rem} and k = {k}')\n",
    "    #print('='*89)\n",
    "    ensemble_antecedents = list_rules[k].rules\n",
    "    ensemble_rules = list_rules[k].complete_rules\n",
    "    ensemble_prem_terms = list_rules[k].prem_terms\n",
    "    # wd_ = list_rules[k].wd_\n",
    "\n",
    "    ensemble_wd_, ensemble_agg_training = model.reweight_mf(_mY_,ensemble_rules,ensemble_prem_terms)\n",
    "\n",
    "    initial_values = all_lagged[yp_lagged.shape[0]+h_p,:].reshape(1,-1)\n",
    "\n",
    "\n",
    "    yt_totest, _ = model.predict(initial_values, \n",
    "                                 data=train_values, \n",
    "                                 in_sample = yt,\n",
    "                                 out_sample=out_sample, \n",
    "                                 agg_training=ensemble_agg_training,\n",
    "                                 h_prev=24,\n",
    "                                 n_attempt=f'p_subsample_{i}',\n",
    "                                 wd_=ensemble_wd_,\n",
    "                                 ensemble_antecedents=ensemble_antecedents,\n",
    "                                 ensemble_rules=ensemble_rules, \n",
    "                                 filepath=filepath, \n",
    "                                 lim=min_error, \n",
    "                                 fig_axis=[num_series,2],\n",
    "                                 ndata=dataset,\n",
    "                                 show=False)\n",
    "\n",
    "    print(k)\n",
    "    if (h_p+24 > ensemble_predicted_values.shape[0]):\n",
    "        bb = ensemble_predicted_values.shape[0] - h_p\n",
    "        ensemble_predicted_values[h_p:h_p+bb,:] = yt_totest[0:bb]\n",
    "    else:\n",
    "        ensemble_predicted_values[h_p:h_p+24,:] = yt_totest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization\n"
     ]
    }
   ],
   "source": [
    "train_values = training_values[:,:num_series]\n",
    "test_values = test_data.values[:,:num_series]\n",
    "\n",
    "print('Initialization')\n",
    "preprocess_data, training_set, val_set, yt, yp, yp_lagged, all_yt, all_yp, all_lagged = preprocess_external(train_values,h_val,num_series, train_values, test_values, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "F = predicted_values[:2016,:47]\n",
    "A = test_data.values[:2016,:47]     \n",
    "num = sqrt(np.sum((F-A)**2))\n",
    "den = sqrt(np.sum((A-0)**2))\n",
    "rrse = num/(den+0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5716890772322513"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted_values[600:700,7],color='g')\n",
    "plt.plot(test_data.values[600:700,7],color='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lagged[yp_lagged.shape[0]+h_p,:num_series].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fft\n",
    "from scipy import signal as sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_values[:334,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_output = fft.fft(training_values[:334,0])\n",
    "power = np.abs(fft_output)\n",
    "freq = fft.fftfreq(len(training_values[:334,0]))\n",
    "\n",
    "mask = freq >= 0\n",
    "freq = freq[mask]\n",
    "power = power[mask]\n",
    "\n",
    "plt.figure( figsize=(10, 4) )\n",
    "\n",
    "ax1 = plt.subplot( 1, 2, 1 )\n",
    "ax1.plot(freq, power, label='signal')\n",
    "ax1.set_title('All Frequencies')\n",
    "ax1.set_ylabel( 'Amplitude' )\n",
    "ax1.set_xlabel( 'Frequency [1 / Hour]' )\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "ax2 = plt.subplot( 1, 2, 2 )\n",
    "mask = (freq > 0) & (freq <= 0.25)\n",
    "ax2.plot(freq[mask], power[mask])\n",
    "ax2.set_title('Frequencies in (0, 0.25]')\n",
    "ax2.set_ylabel( 'Amplitude' )\n",
    "ax2.set_xlabel( 'Frequency [1 / Hour]' )\n",
    "\n",
    "peaks = sig.find_peaks(power[freq >=0], prominence=3)[0]\n",
    "peak_freq =  freq[peaks]\n",
    "peak_power = power[peaks]\n",
    "plt.plot(peak_freq, peak_power, 'ro')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "output['index'] = peaks\n",
    "output['freq (1/hour)'] = peak_freq\n",
    "output['amplitude'] = peak_power\n",
    "output['period (days)'] = 1 / peak_freq / 24\n",
    "output['fft'] = fft_output[peaks]\n",
    "output = output.sort_values('amplitude', ascending=False)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0.041916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_fft_output = np.array([f if i == 14 or i == 0 else 0 for i, f in enumerate(fft_output)])\n",
    "filtered_sig = fft.ifft(filtered_fft_output)\n",
    "n_filtered_sig = fft.ifft(fft_output)\n",
    "\n",
    "N = 334\n",
    "plt.plot(np.linspace(0,N,N), training_values[:N,0], linewidth=1, label='Original serie')\n",
    "plt.plot(np.linspace(0,N,N), filtered_sig[:N].real, linewidth=1, label='Filtered serie')\n",
    "#plt.plot(np.linspace(0,N,N), n_filtered_sig[:N].real, linewidth=1, label='Non Filtered signal')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "ax2.set_title('First 5 Days')\n",
    "plt.grid()\n",
    "#plt.ylim((-25, 25))\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Time(h)')\n",
    "plt.ylabel('Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_values = training_values[:N,0] - filtered_sig[:N].real\n",
    "fft_output = fft.fft(new_values)\n",
    "power = np.abs(fft_output)\n",
    "freq = fft.fftfreq(len(new_values))\n",
    "\n",
    "mask = freq >= 0\n",
    "freq = freq[mask]\n",
    "power = power[mask]\n",
    "\n",
    "plt.figure( figsize=(10, 4) )\n",
    "\n",
    "ax1 = plt.subplot( 1, 2, 1 )\n",
    "ax1.plot(freq, power, label='signal')\n",
    "ax1.set_title('All Frequencies')\n",
    "ax1.set_ylabel( 'Amplitude' )\n",
    "ax1.set_xlabel( 'Frequency [1 / Hour]' )\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "ax2 = plt.subplot( 1, 2, 2 )\n",
    "mask = (freq > 0) & (freq <= 0.25)\n",
    "ax2.plot(freq[mask], power[mask])\n",
    "ax2.set_title('Frequencies in (0, 0.25]')\n",
    "ax2.set_ylabel( 'Amplitude' )\n",
    "ax2.set_xlabel( 'Frequency [1 / Hour]' )\n",
    "\n",
    "peaks = sig.find_peaks(power[freq >=0], prominence=3)[0]\n",
    "peak_freq =  freq[peaks]\n",
    "peak_power = power[peaks]\n",
    "plt.plot(peak_freq, peak_power, 'ro')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "output['index'] = peaks\n",
    "output['freq (1/hour)'] = peak_freq\n",
    "output['amplitude'] = peak_power\n",
    "output['period (days)'] = 1 / peak_freq / 24\n",
    "output['fft'] = fft_output[peaks]\n",
    "output = output.sort_values('amplitude', ascending=False)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0.006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rules[0].complete_rules[a[15:],0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "35/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "init = 0\n",
    "for i,a in enumerate(list_rules):\n",
    "    try:\n",
    "        ensemble_rules = a.complete_rules\n",
    "        ensemble_prem_terms = a.prem_terms\n",
    "        ensemble_antecedents = a.rules\n",
    "        \n",
    "        new_ensemble_rules = correct_bug(ensemble_rules,max_rulesize=max_rulesize)\n",
    "\n",
    "        new_rules, new_prem_terms, new_antecedents = remove_duplicates(new_ensemble_rules,ensemble_prem_terms,            ensemble_antecedents)\n",
    "\n",
    "        wd_, _ = model.reweight_mf(mY_[init:init+ensemble_prem_terms.shape[1],:,:], new_rules, new_prem_terms)\n",
    "        \n",
    "        list_rules[i].complete_rules = new_rules\n",
    "        list_rules[i].prem_terms = new_prem_terms\n",
    "        list_rules[i].rules = new_antecedents\n",
    "        list_rules[i].wd_ = wd_\n",
    "\n",
    "        init += ensemble_prem_terms.shape[1]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_totest[0:4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pattern = 0\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "#Iintial values for prediction\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0] - 2*168,:].reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import plot_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_values = yp_lagged[0,:].reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppp(initial_values, lags_used = [], ndata=[''], data=[], out_sample=[],h_prev=0,n_attempt=0,not_used_lag = False, filepath='',lim=0, defuzz_method='cog',fig_axis=[3,2], n_patterns=0, list_rules=None, wd_given=True,offset=0):\n",
    "        '''\n",
    "        Function for pattern prediction. \n",
    "        \\n Important features: \n",
    "        \\n - n_pattern: Number of seasonal patterns.\n",
    "        \\n - list_rules: list of rules for each pattern.\n",
    "        '''\n",
    "\n",
    "        #preprocess_data = Preprocess(data,h_prev=h_prev,num_series=num_series)\n",
    "        \n",
    "        #in_sample, out_sample = preprocess_data.split_data()\n",
    "        \n",
    "        #yt, yp, yp_lagged = preprocess_data.delay_input(in_sample = in_sample, lag = lag)\n",
    "\n",
    "\n",
    "        defuzz = Defuzzification(model.mf_params,num_series)\n",
    "\n",
    "        yp_totest = initial_values\n",
    "        yt_totest = np.zeros((h_prev,num_series))\n",
    "\n",
    "        for h_p in range(h_prev):\n",
    "            #print('='*89)\n",
    "            #Select which ruleset use now.\n",
    "\n",
    "            rem = h_p % 168\n",
    "\n",
    "            k = (rem + offset) // 24\n",
    "            k = k % 7\n",
    "\n",
    "            #print(f'Debug only, rem = {rem} and k = {k}')\n",
    "            #print('='*89)\n",
    "            ensemble_antecedents = list_rules[k].rules\n",
    "            ensemble_rules = list_rules[k].complete_rules\n",
    "\n",
    "            #If weight matrix is not given, just fill with ones.\n",
    "            if not wd_given:\n",
    "                wd_ = np.ones((ensemble_rules.shape[0], num_groups, ensemble_rules.shape[1]))\n",
    "            else:\n",
    "                wd_ = list_rules[k].wd_\n",
    "\n",
    "\n",
    "\n",
    "            #print(f'Shape of ensemble rules is {ensemble_rules.shape}')\n",
    "\n",
    "            mX_values_in = np.zeros((1,model.mf_params.shape[0],yp_totest.shape[1]))\n",
    "            antecedents_activated = []\n",
    "            it = 0\n",
    "            for i in range(num_series):\n",
    "                mf_params = model.mf_params[:,i]\n",
    "                for j in range(lag):\n",
    "\n",
    "                    mX, _ = model.Fuzzify.fuzzify(np.array([yp_totest[0,i*lag+j]]),mf_params,num_groups=num_groups)\n",
    "                    mX_values_in[:,:,i*lag+j] = mX\n",
    "\n",
    "\n",
    "                    idx_nonzero = np.where(mX[0,:] > 0)\n",
    "                    idx_nonzero = idx_nonzero[0]\n",
    "\n",
    "                    if not_used_lag:\n",
    "                        for k in range(idx_nonzero.shape[0]):\n",
    "                            if j in lags_used[i]:\n",
    "                                antecedents_activated.append((it,idx_nonzero[k]))\n",
    "                            else:\n",
    "                                pass\n",
    "                        it += 1\n",
    "                    \n",
    "                    else:\n",
    "                        for k in range(idx_nonzero.shape[0]):\n",
    "                            antecedents_activated.append((i*lag+j,idx_nonzero[k]))\n",
    "\n",
    "            '''\n",
    "            if not_used_lag:\n",
    "                mX_values_in, _ = remove_lags(mX_values_in,lag_notused,num_series,lag)\n",
    "\n",
    "\n",
    "            prem_terms_test = np.zeros((ensemble_antecedents.shape[0],1))\n",
    "            '''\n",
    "            rules_idx = []\n",
    "            check_idx = 0\n",
    "            \n",
    "            #Checking for every rule in dataset if it's activated\n",
    "            #TODO - Check if we can modify this into enumerate, avoiding check_idx += 1 every time.\n",
    "            for n_rule in ensemble_antecedents:\n",
    "                #print('Rule {} is {}'.format(check_idx,test(n_rule,antecedents_activated)))\n",
    "                if test(n_rule,antecedents_activated):\n",
    "                    rules_idx.append(check_idx)\n",
    "                check_idx += 1\n",
    "                \n",
    "            prem_activated = np.zeros((ensemble_antecedents.shape[0],))\n",
    "            for i in rules_idx:\n",
    "                prem_activated[i,] = prem_term(ensemble_antecedents[i,0],mX_values_in)\n",
    "            \n",
    "            agg_test = np.zeros((wd_.shape))\n",
    "            for i in range(num_series):\n",
    "                for j in rules_idx:\n",
    "                    rule = ensemble_rules[j,i]\n",
    "                    consequent = rule[-1]\n",
    "                    agg_test[j,consequent[1],i] = prem_activated[j,]\n",
    "                    \n",
    "                    \n",
    "            weight_agg = np.multiply(agg_test,wd_)\n",
    "            weight_ = np.zeros((weight_agg.shape[1],weight_agg.shape[2]))\n",
    "\n",
    "            for i in range(weight_.shape[1]):\n",
    "                weight_[:,i] = weight_agg[:,:,i].max(axis=0)\n",
    "\n",
    "            w_todefuzz = np.reshape(weight_,(1,weight_.shape[0],weight_.shape[1]))\n",
    "            \n",
    "            #Defuzzification in fact\n",
    "            y_pred = defuzz.run(defuzz_method,w_todefuzz,show=False)\n",
    "            \n",
    "            #Store predicted value into yt_totest.\n",
    "            yt_totest[h_p,:] = y_pred\n",
    "            \n",
    "            #Last step, we use the predicted output to compose input data.\n",
    "            y_temp = np.zeros(yp_totest.shape)\n",
    "            assert y_temp.shape == yp_totest.shape\n",
    "            y_temp[0,1:] = yp_totest[0,0:yp_totest.shape[1]-1]\n",
    "            for ii in range(num_series):\n",
    "                #print(yp_totest[0,ii*lag])\n",
    "                #print(y_pred[0][ii])\n",
    "                #yp_totest[0,ii*lag] = y_pred[0][ii]\n",
    "                y_temp[0,ii*lag] = y_pred[0][ii]\n",
    "                #print(yp_totest[0,yp_totest.shape[1]-1])\n",
    "            yp_totest = y_temp\n",
    "\n",
    "        k = 1\n",
    "        for i in range(num_series):\n",
    "            plt.subplot(fig_axis[0],fig_axis[1],k)\n",
    "            plt.title('Serie {}'.format(ndata.columns[i]),fontsize=30)\n",
    "            plt.plot(yt_totest[:,i],color='blue')\n",
    "            plt.plot(out_sample[:,i],color='red')\n",
    "            plt.legend(['Predicted','Target'])\n",
    "            plt.xlabel('Time(h)',fontsize=15)\n",
    "            plt.ylabel('Value',fontsize=15)\n",
    "            k += 1\n",
    "    \n",
    "\n",
    "\n",
    "        errors = plot_predict(lim=500,yt_totest=yt_totest,num_series=num_series,data=data,out_sample=out_sample,trends=[],ndata=ndata,filename='{}/Outsample {}'.format(filepath,n_attempt), fig_axis=fig_axis)\n",
    "        return errors, yt_totest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = training_values[:,0:1]\n",
    "preprocess_data = Preprocess(data_,h_prev=h_val,num_series=num_series)\n",
    "training_set, val_set = preprocess_data.split_data()\n",
    "yt, yp, yp_lagged = preprocess_data.delay_input(in_sample = training_set, lag = lag)\n",
    "\n",
    "#For all set. This will be useful for initial values of prediction\n",
    "all_yt, all_yp, all_lagged = preprocess_data.delay_input(in_sample = data_, lag = lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_values = all_lagged[0,:].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errors1, yt_totest1 = ppp(initial_values, ndata=dataset, data=data_, out_sample=yt,h_prev=yt.shape[0],n_attempt='_predict', filepath='traffic',lim=0, defuzz_method=defuzz_method,fig_axis=[1,1], n_patterns=7, list_rules=list_rules,offset=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('traffic.rules','wb') as traffic_rules:\n",
    "    pickle.dump(list_rules, traffic_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(yt_totest.shape[0]-166)/168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('best_list.rules','rb') as read_file:\n",
    "\n",
    "    #blah = pickle.load(read_file)\n",
    "    #print(blah.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st += yt_totest1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yt)\n",
    "plt.plot(st/5)\n",
    "print(rrse(st/5,yt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initial_values = all_lagged[yp_lagged.shape[0]-168*2-1,:].reshape(1,-1)\n",
    "#initial_values = all_lagged[yp_lagged.shape[0],:].reshape(1,-1)\n",
    "\n",
    "test_values = test_data.values\n",
    "#test_set = test_values[:,[0, 61, 147, 241]]\n",
    "test_set = test_values[:,0:1]\n",
    "\n",
    "errors1 = model.predict_pattern(initial_values, ndata=dataset, data=data_, out_sample=yt[2:,:],mf_params_=mf_params_,h_prev=yt.shape[0]-2,n_attempt='_predict', filepath='traffic',lim=0, defuzz_method=defuzz_method,fig_axis=[1,1], n_patterns=7, list_rules=list_rules)\n",
    "\n",
    "print(errors1[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(initial_values, lags_used = [], ndata=[''], data=[], in_sample=[], out_sample=[], agg_training=None,h_prev=0,n_attempt=0,wd_=[],ensemble_antecedents=[],ensemble_rules=[],not_used_lag = False, filepath='',lim=0, fig_axis=[3,2]):\n",
    "    '''\n",
    "    Module to time series forecasting. It uses multi-stepping in order to evaluate the model.\n",
    "    INPUTS:\n",
    "    \\n - Fuzzyfy: Object containing informations about Fuzzification.\n",
    "    \\n - lags_used: If not_used_lags is true, masks series that isn't in list.\n",
    "    \\n - num_groups: Number of fuzzy sets.\n",
    "    \\n - ndata: name of data (e.g. column header)\n",
    "    \\n - data: data of the problem\n",
    "    \\n - in_sample: in_sample set of data\n",
    "    \\n - out_sample: out_sample set of data\n",
    "    \\n - lag:\n",
    "    \\n - mf_params: Membership function parameters\n",
    "    \\n - agg_training: Aggregation terms in training set. Used to simplify deffuzification of training set.\n",
    "    \\n - yp_lagged\n",
    "    \\n - h_prev:\n",
    "    #TODO - Continue this list\n",
    "\n",
    "    VARIABLES:\n",
    "    \\n - y_predict_: Training set prediction\n",
    "    \\n - yp_totest: Input pattern to evaluate prediction\n",
    "    \\n - yt_totest: Output data, for each horizon and serie.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    print(f'Shape of ensemble rules is {ensemble_rules.shape}')\n",
    "\n",
    "\n",
    "    defuzz = Defuzzification(model.mf_params,num_series)\n",
    "    if agg_training is not None:\n",
    "        y_predict_ = defuzz.run(defuzz_method,agg_training)\n",
    "\n",
    "    yp_totest = initial_values\n",
    "    yt_totest = np.zeros((h_prev,num_series))\n",
    "\n",
    "    #Prediction - Multi-step\n",
    "    for h_p in range(h_prev):\n",
    "\n",
    "        #Check activated terms.\n",
    "        mX_values_in = np.zeros((1,model.mf_params.shape[0],yp_totest.shape[1]))\n",
    "\n",
    "        antecedents_activated = []\n",
    "        it = 0\n",
    "        for i in range(num_series):\n",
    "            mf_params = model.mf_params[:,i]\n",
    "            for j in range(lag):\n",
    "\n",
    "                mX, _ = Fuzzyfy.fuzzify(np.array([yp_totest[0,i*lag+j]]),mf_params,num_groups=num_groups)\n",
    "                mX_values_in[:,:,i*lag+j] = mX\n",
    "\n",
    "\n",
    "                idx_nonzero = np.where(mX[0,:] > 0)\n",
    "                idx_nonzero = idx_nonzero[0]\n",
    "\n",
    "                if not_used_lag:\n",
    "                    for k in range(idx_nonzero.shape[0]):\n",
    "                        if j in lags_used[i]:\n",
    "                            antecedents_activated.append((it,idx_nonzero[k]))\n",
    "                        else:\n",
    "                            pass\n",
    "                    it += 1\n",
    "                \n",
    "                else:\n",
    "                    for k in range(idx_nonzero.shape[0]):\n",
    "                        antecedents_activated.append((i*lag+j,idx_nonzero[k]))\n",
    "\n",
    "        '''\n",
    "        if not_used_lag:\n",
    "            mX_values_in, _ = remove_lags(mX_values_in,lag_notused,num_series,lag)\n",
    "\n",
    "\n",
    "        prem_terms_test = np.zeros((ensemble_antecedents.shape[0],1))\n",
    "        '''\n",
    "        rules_idx = []\n",
    "        check_idx = 0\n",
    "        #Checking for every rule in dataset if it's activated\n",
    "        #TODO - Check if we can modify this into enumerate, avoiding check_idx += 1 every time.\n",
    "        for n_rule in ensemble_antecedents:\n",
    "            #print('Rule {} is {}'.format(check_idx,test(n_rule,antecedents_activated)))\n",
    "            if test(n_rule,antecedents_activated):\n",
    "                rules_idx.append(check_idx)\n",
    "            check_idx += 1\n",
    "            \n",
    "        prem_activated = np.zeros((ensemble_antecedents.shape[0],))\n",
    "        for i in rules_idx:\n",
    "            prem_activated[i,] = prem_term(ensemble_antecedents[i,0],mX_values_in)\n",
    "        \n",
    "        agg_test = np.zeros((wd_.shape))\n",
    "        for i in range(num_series):\n",
    "            for j in rules_idx:\n",
    "                rule = ensemble_rules[j,i]\n",
    "                consequent = rule[-1]\n",
    "                agg_test[j,consequent[1],i] = prem_activated[j,]\n",
    "                \n",
    "\n",
    "        weight_agg = np.multiply(agg_test,wd_)\n",
    "        weight_ = np.zeros((weight_agg.shape[1],weight_agg.shape[2]))\n",
    "        for i in range(weight_.shape[1]):\n",
    "            weight_[:,i] = weight_agg[:,:,i].max(axis=0)\n",
    "\n",
    "        w_todefuzz = np.reshape(weight_,(1,weight_.shape[0],weight_.shape[1]))\n",
    "        \n",
    "        #Defuzzification in fact\n",
    "        y_pred = defuzz.run(defuzz_method,w_todefuzz,show=False)\n",
    "        \n",
    "        #Store predicted value into yt_totest.\n",
    "        yt_totest[h_p,:] = y_pred\n",
    "        \n",
    "        #Last step, we use the predicted output to compose input data.\n",
    "        y_temp = np.zeros(yp_totest.shape)\n",
    "        assert y_temp.shape == yp_totest.shape\n",
    "        y_temp[0,1:] = yp_totest[0,0:yp_totest.shape[1]-1]\n",
    "        for ii in range(num_series):\n",
    "            #print(yp_totest[0,ii*lag])\n",
    "            #print(y_pred[0][ii])\n",
    "            #yp_totest[0,ii*lag] = y_pred[0][ii]\n",
    "            y_temp[0,ii*lag] = y_pred[0][ii]\n",
    "            #print(yp_totest[0,yp_totest.shape[1]-1])\n",
    "        yp_totest = y_temp\n",
    "\n",
    "    k = 1\n",
    "    for i in range(num_series):\n",
    "        plt.subplot(fig_axis[0],fig_axis[1],k)\n",
    "        plt.title('Serie {}'.format(ndata.columns[i]),fontsize=30)\n",
    "        plt.plot(yt_totest[:,i],color='blue')\n",
    "        plt.plot(out_sample[:,i],color='red')\n",
    "        plt.legend(['Predicted','Target'])\n",
    "        plt.xlabel('Time(h)',fontsize=15)\n",
    "        plt.ylabel('Value',fontsize=15)\n",
    "        print(rrse(yt_totest[:,i],out_sample[:,i]))\n",
    "        k += 1\n",
    "\n",
    "    return yp_totest, yt_totest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import rrse\n",
    "from defuzzification import Defuzzification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0] - 2*168,:].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend_wd = list_rules[6].wd_\n",
    "weekend_antecedents = list_rules[6].rules\n",
    "weekend_rules = list_rules[6].complete_rules\n",
    "out_sample = test_set[:24,:].reshape(-1,1)\n",
    "\n",
    "new_values__, new_results__ = pp(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'AA_p_{n_pattern}_subsample_{i}',wd_=weekend_wd,ensemble_antecedents=weekend_antecedents,ensemble_rules=weekend_rules, filepath=filepath, lim=3.0, fig_axis=[1,1],ndata=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend_wd = list_rules[0].wd_\n",
    "weekend_antecedents = list_rules[0].rules\n",
    "weekend_rules = list_rules[0].complete_rules\n",
    "out_sample = test_set[:24,:].reshape(-1,1)\n",
    "\n",
    "new_values_, new_results_ = pp(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'AA_p_{n_pattern}_subsample_{i}',wd_=weekend_wd,ensemble_antecedents=weekend_antecedents,ensemble_rules=weekend_rules, filepath=filepath, lim=3.0, fig_axis=[1,1],ndata=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weekend = (new_results_ + new_results__)/2\n",
    "mean_initial_values = (new_values_ + new_values__)/2\n",
    "plt.figure()\n",
    "plt.plot(mean_weekend)\n",
    "plt.plot(out_sample)\n",
    "print(rrse(mean_weekend,out_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pattern = 0\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "#Iintial values for prediction\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0] - 2*168,:].reshape(1,-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weekday_wd = list_rules[n_pattern].wd_\n",
    "weekday_antecedents = list_rules[n_pattern].rules\n",
    "weekday_rules = list_rules[n_pattern].complete_rules\n",
    "#out_sample = test_set[48:72,:].reshape(-1,1)\n",
    "new_values___, new_results___ = pp(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'AA_p_{n_pattern}_subsample_{i}',wd_=weekday_wd,ensemble_antecedents=weekday_antecedents,ensemble_rules=weekday_rules, filepath=filepath, lim=3.0, fig_axis=[1,1],ndata=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_values = new_results___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_values = np.concatenate((store_values,new_results___))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(store_values[24:])\n",
    "plt.plot(val_set)\n",
    "plt.legend(('Predicted','Actual'))\n",
    "plt.title('Sample of validation set')\n",
    "plt.xlabel('Timestamp(h)')\n",
    "plt.ylabel('Traffic rate')\n",
    "rrse(store_values[24:],val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#errors = predict_pattern(Fuzzyfy, lags_used = [], num_groups=num_groups, ndata=dataset, data=data_, lag = lag, mf_params_=mf_params_,num_series=num_series,h_prev=h_test,not_used_lag=not_used_lag,n_attempt=f'_predict_',wd_=wd_,filepath=filepath,lim=3.0,defuzz_method=defuzz_method,fig_axis=[2,2], n_patterns=n_pattern, list_rules = list_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "k = 2\n",
    "t = [a + n for n in range(0,data.shape[0]-168,168) for a in range(24*k,24*(k+1))]\n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "data1 = deepcopy(data[t[len(t)-len(t_lagged):],:])\n",
    "in_sample = data1[:data1.shape[0]-h_prev,:]\n",
    "out_sample = data1[data1.shape[0]-h_prev:,:]\n",
    "\n",
    "print(len(t_lagged))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ll = [rule_object(None,None,None,k) for k in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend_antecedents = \n",
    "weekend_rules = \n",
    "weekend_wd = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,training_set.shape[0]),training_set[:,0],label='Train')\n",
    "plt.plot(np.arange(training_set.shape[0],training_set.shape[0]+val_set.shape[0]),val_set[:,0],color='r',label='Validation')\n",
    "plt.plot(np.arange(training_set.shape[0]+val_set.shape[0], training_set.shape[0]+val_set.shape[0] + test_set.shape[0]),test_set[:,0],label='Test')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Traffic rate')\n",
    "plt.title('Data split')\n",
    "plt.legend(['Train','Validation','Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(a[0].values)[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.sort(a[0].values)[-5:]:\n",
    "    print(np.where(np.isclose(b,i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defuzzification import Defuzzification\n",
    "from metrics import rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_prev = h_test\n",
    "wd_given = True\n",
    "fig_axis = [2,2]\n",
    "ndata = dataset\n",
    "\n",
    "out_sample = test_set\n",
    "\n",
    "initial_values = all_lagged[yp_lagged.shape[0],:].reshape(1,-1)\n",
    "\n",
    "defuzz = Defuzzification(mf_params_,num_series)\n",
    "\n",
    "yp_totest = initial_values\n",
    "yt_totest = np.zeros((h_prev,num_series))\n",
    "\n",
    "for h_p in range(h_prev):\n",
    "    print('='*89)\n",
    "    #Select which ruleset use now.\n",
    "\n",
    "    rem = h_p % 168\n",
    "\n",
    "    k = rem // 24\n",
    "\n",
    "    print(f'Debug only, rem = {rem} and k = {k}')\n",
    "    print('='*89)\n",
    "    ensemble_antecedents = list_rules[k].rules\n",
    "    ensemble_rules = list_rules[k].complete_rules\n",
    "\n",
    "    #If weight matrix is not given, just fill with ones.\n",
    "    if not wd_given:\n",
    "        wd_ = np.ones((ensemble_rules.shape[0], num_groups, ensemble_rules.shape[1]))\n",
    "        print('Weights not given')\n",
    "    else:\n",
    "        wd_ = list_rules[k].wd_\n",
    "\n",
    "\n",
    "\n",
    "    print(f'Shape of ensemble rules is {ensemble_rules.shape}')\n",
    "\n",
    "    mX_values_in = np.zeros((1,mf_params_.shape[0],yp_totest.shape[1]))\n",
    "    antecedents_activated = []\n",
    "    it = 0\n",
    "    for i in range(num_series):\n",
    "        mf_params = mf_params_[:,i]\n",
    "        for j in range(lag):\n",
    "\n",
    "            mX, _ = Fuzzyfy.fuzzify(np.array([yp_totest[0,i*lag+j]]),mf_params,num_groups=num_groups)\n",
    "            mX_values_in[:,:,i*lag+j] = mX\n",
    "\n",
    "\n",
    "            idx_nonzero = np.where(mX[0,:] > 0)\n",
    "            idx_nonzero = idx_nonzero[0]\n",
    "\n",
    "            if not_used_lag:\n",
    "                for k in range(idx_nonzero.shape[0]):\n",
    "                    if j in lags_used[i]:\n",
    "                        antecedents_activated.append((it,idx_nonzero[k]))\n",
    "                    else:\n",
    "                        pass\n",
    "                it += 1\n",
    "            \n",
    "            else:\n",
    "                for k in range(idx_nonzero.shape[0]):\n",
    "                    antecedents_activated.append((i*lag+j,idx_nonzero[k]))\n",
    "\n",
    "    '''\n",
    "    if not_used_lag:\n",
    "        mX_values_in, _ = remove_lags(mX_values_in,lag_notused,num_series,lag)\n",
    "\n",
    "\n",
    "    prem_terms_test = np.zeros((ensemble_antecedents.shape[0],1))\n",
    "    '''\n",
    "    rules_idx = []\n",
    "    check_idx = 0\n",
    "    \n",
    "    #Checking for every rule in dataset if it's activated\n",
    "    #TODO - Check if we can modify this into enumerate, avoiding check_idx += 1 every time.\n",
    "    for n_rule in ensemble_antecedents:\n",
    "        #print('Rule {} is {}'.format(check_idx,test(n_rule,antecedents_activated)))\n",
    "        if test(n_rule,antecedents_activated):\n",
    "            rules_idx.append(check_idx)\n",
    "        check_idx += 1\n",
    "        \n",
    "    prem_activated = np.zeros((ensemble_antecedents.shape[0],))\n",
    "    for i in rules_idx:\n",
    "        prem_activated[i,] = prem_term(ensemble_antecedents[i,0],mX_values_in)\n",
    "    \n",
    "    agg_test = np.zeros((wd_.shape))\n",
    "    for i in range(num_series):\n",
    "        for j in rules_idx:\n",
    "            rule = ensemble_rules[j,i]\n",
    "            consequent = rule[-1]\n",
    "            agg_test[j,consequent[1],i] = prem_activated[j,]\n",
    "            \n",
    "            \n",
    "    weight_agg = np.multiply(agg_test,wd_)\n",
    "    weight_ = np.zeros((weight_agg.shape[1],weight_agg.shape[2]))\n",
    "\n",
    "    for i in range(weight_.shape[1]):\n",
    "        weight_[:,i] = weight_agg[:,:,i].max(axis=0)\n",
    "\n",
    "    w_todefuzz = np.reshape(weight_,(1,weight_.shape[0],weight_.shape[1]))\n",
    "    \n",
    "    #Defuzzification in fact\n",
    "    y_pred = defuzz.run(defuzz_method,w_todefuzz,show=False)\n",
    "    \n",
    "    #Store predicted value into yt_totest.\n",
    "    yt_totest[h_p,:] = y_pred\n",
    "    \n",
    "    #Last step, we use the predicted output to compose input data.\n",
    "    y_temp = np.zeros(yp_totest.shape)\n",
    "    assert y_temp.shape == yp_totest.shape\n",
    "    y_temp[0,1:] = yp_totest[0,0:yp_totest.shape[1]-1]\n",
    "    for ii in range(num_series):\n",
    "        #print(yp_totest[0,ii*lag])\n",
    "        #print(y_pred[0][ii])\n",
    "        #yp_totest[0,ii*lag] = y_pred[0][ii]\n",
    "        y_temp[0,ii*lag] = y_pred[0][ii]\n",
    "        #print(yp_totest[0,yp_totest.shape[1]-1])\n",
    "    yp_totest = y_temp\n",
    "\n",
    "k = 1\n",
    "for i in range(num_series):\n",
    "    plt.subplot(fig_axis[0],fig_axis[1],k)\n",
    "    plt.title('Serie {}'.format(ndata.columns[i]),fontsize=30)\n",
    "    plt.plot(yt_totest[:,i],color='blue')\n",
    "    plt.plot(out_sample[:,i],color='red')\n",
    "    plt.legend(['Predicted','Target'])\n",
    "    plt.xlabel('Time(h)',fontsize=15)\n",
    "    plt.ylabel('Value',fontsize=15)\n",
    "    print(rrse(yt_totest[:,i],out_sample[:,i]))\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prem_activated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = yt_totest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(out_sample[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_totest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp = np.zeros(yp_totest.shape)\n",
    "assert y_temp.shape == yp_totest.shape\n",
    "y_temp[0,1:] = yp_totest[0,0:yp_totest.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "num = np.zeros((out_sample.shape))\n",
    "den = np.zeros((out_sample.shape))\n",
    "for k in range(num_series):\n",
    "    for j in range(out_sample.shape[0]):\n",
    "        A = out_sample[j,k]\n",
    "        F = yt_totest[j,k]\n",
    "        num[j,k] = sqrt(np.sum((F-A)**2))\n",
    "        den[j,k] = sqrt(np.sum((A-np.mean(out_sample[:,k]))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_series):\n",
    "    plt.figure()\n",
    "    plt.plot(num[:,i], color='red')\n",
    "    plt.plot(den[:,i], color='green')\n",
    "    plt.plot(num[:,i]/den[:,i], color='orange')\n",
    "    print(np.sum(num[:,i])/np.sum(den[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 7\n",
    "plt.plot(yt_totest[168*b:168*(b+1),0])\n",
    "plt.plot(out_sample[168*b:168*(b+1),0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pattern = 4\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "wd_ = list_rules[n_pattern].wd_\n",
    "rules = list_rules[n_pattern].rules \n",
    "complete_rules = list_rules[n_pattern].complete_rules \n",
    "print(f'Shape of ensemble rules is {complete_rules.shape}')\n",
    "\n",
    "#Iintial values for prediction\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\n",
    "\n",
    "errors = model.predict(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'TEST_p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules, filepath=filepath, lim=3.0, fig_axis=[2,2],ndata=dataset)\n",
    "\n",
    "#errors = model.predict(initial_values, data=data_,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'TEST_p_{n_pattern}_subsample_{i}',wd_=list_rules[n_pattern].wd_,ensemble_antecedents=list_rules[n_pattern].rules,ensemble_rules=list_rules[n_pattern].complete_rules, filepath=filepath, lim=3.0, fig_axis=[2,2],ndata=dataset)\n",
    "\n",
    "print(errors[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_prev = h_test\n",
    "wd_given = True\n",
    "fig_axis = [1,1]\n",
    "ndata = dataset\n",
    "\n",
    "n_pattern = 6\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "wd_ = list_rules[5].wd_\n",
    "rules = list_rules[5].rules \n",
    "complete_rules = list_rules[5].complete_rules \n",
    "print(f'Shape of ensemble rules is {complete_rules.shape}')\n",
    "\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\n",
    "\n",
    "\n",
    "\n",
    "defuzz = Defuzzification(mf_params_,num_series)\n",
    "\n",
    "h_prev = 24\n",
    "\n",
    "yp_totest = initial_values\n",
    "yt_totest = np.zeros((h_prev,num_series))\n",
    "\n",
    "\n",
    "for h_p in range(h_prev):\n",
    "    print('='*89)\n",
    "    #Select which ruleset use now.\n",
    "\n",
    "    rem = h_p % 168\n",
    "\n",
    "    k = rem // 24\n",
    "\n",
    "    print(f'Debug only, rem = {rem} and k = {k}')\n",
    "    print('='*89)\n",
    "    ensemble_antecedents = rules\n",
    "    ensemble_rules = complete_rules\n",
    "\n",
    "    #If weight matrix is not given, just fill with ones.\n",
    "\n",
    "    print(f'Shape of ensemble rules is {ensemble_rules.shape}')\n",
    "\n",
    "    mX_values_in = np.zeros((1,mf_params_.shape[0],yp_totest.shape[1]))\n",
    "    antecedents_activated = []\n",
    "    it = 0\n",
    "    for i in range(num_series):\n",
    "        mf_params = mf_params_[:,i]\n",
    "        for j in range(lag):\n",
    "\n",
    "            mX, _ = Fuzzyfy.fuzzify(np.array([yp_totest[0,i*lag+j]]),mf_params,num_groups=num_groups)\n",
    "            mX_values_in[:,:,i*lag+j] = mX\n",
    "\n",
    "\n",
    "            idx_nonzero = np.where(mX[0,:] > 0)\n",
    "            idx_nonzero = idx_nonzero[0]\n",
    "\n",
    "            if not_used_lag:\n",
    "                for k in range(idx_nonzero.shape[0]):\n",
    "                    if j in lags_used[i]:\n",
    "                        antecedents_activated.append((it,idx_nonzero[k]))\n",
    "                    else:\n",
    "                        pass\n",
    "                it += 1\n",
    "            \n",
    "            else:\n",
    "                for k in range(idx_nonzero.shape[0]):\n",
    "                    antecedents_activated.append((i*lag+j,idx_nonzero[k]))\n",
    "\n",
    "    '''\n",
    "    if not_used_lag:\n",
    "        mX_values_in, _ = remove_lags(mX_values_in,lag_notused,num_series,lag)\n",
    "\n",
    "\n",
    "    prem_terms_test = np.zeros((ensemble_antecedents.shape[0],1))\n",
    "    '''\n",
    "    rules_idx = []\n",
    "    check_idx = 0\n",
    "    \n",
    "    #Checking for every rule in dataset if it's activated\n",
    "    #TODO - Check if we can modify this into enumerate, avoiding check_idx += 1 every time.\n",
    "    for n_rule in ensemble_antecedents:\n",
    "        #print('Rule {} is {}'.format(check_idx,test(n_rule,antecedents_activated)))\n",
    "        if test(n_rule,antecedents_activated):\n",
    "            rules_idx.append(check_idx)\n",
    "        check_idx += 1\n",
    "        \n",
    "    prem_activated = np.zeros((ensemble_antecedents.shape[0],))\n",
    "    for i in rules_idx:\n",
    "        prem_activated[i,] = prem_term(ensemble_antecedents[i,0],mX_values_in)\n",
    "    \n",
    "    agg_test = np.zeros((wd_.shape))\n",
    "    for i in range(num_series):\n",
    "        for j in rules_idx:\n",
    "            rule = ensemble_rules[j,i]\n",
    "            consequent = rule[-1]\n",
    "            agg_test[j,consequent[1],i] = prem_activated[j,]\n",
    "            \n",
    "            \n",
    "    weight_agg = np.multiply(agg_test,wd_)\n",
    "    weight_ = np.zeros((weight_agg.shape[1],weight_agg.shape[2]))\n",
    "\n",
    "    for i in range(weight_.shape[1]):\n",
    "        weight_[:,i] = weight_agg[:,:,i].max(axis=0)\n",
    "\n",
    "    w_todefuzz = np.reshape(weight_,(1,weight_.shape[0],weight_.shape[1]))\n",
    "    \n",
    "    #Defuzzification in fact\n",
    "    y_pred = defuzz.run(defuzz_method,w_todefuzz,show=False)\n",
    "    \n",
    "    #Store predicted value into yt_totest.\n",
    "    yt_totest[h_p,:] = y_pred\n",
    "    \n",
    "    #Last step, we use the predicted output to compose input data.\n",
    "    y_temp = np.zeros(yp_totest.shape)\n",
    "    assert y_temp.shape == yp_totest.shape\n",
    "    y_temp[0,1:] = yp_totest[0,0:yp_totest.shape[1]-1]\n",
    "    for ii in range(num_series):\n",
    "        #print(yp_totest[0,ii*lag])\n",
    "        #print(y_pred[0][ii])\n",
    "        #yp_totest[0,ii*lag] = y_pred[0][ii]\n",
    "        y_temp[0,ii*lag] = y_pred[0][ii]\n",
    "        #print(yp_totest[0,yp_totest.shape[1]-1])\n",
    "    yp_totest = y_temp\n",
    "\n",
    "k = 1\n",
    "for i in range(num_series):\n",
    "    plt.subplot(fig_axis[0],fig_axis[1],k)\n",
    "    plt.title('Serie {}'.format(ndata.columns[i]),fontsize=30)\n",
    "    plt.plot(yt_totest[:,i],color='blue')\n",
    "    plt.plot(out_sample[:,i],color='red')\n",
    "    plt.legend(['Predicted','Target'])\n",
    "    plt.xlabel('Time(h)',fontsize=15)\n",
    "    plt.ylabel('Value',fontsize=15)\n",
    "    print(rrse(yt_totest[:,i],out_sample[:,i]))\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_totest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_prev = h_test\n",
    "wd_given = True\n",
    "fig_axis = [1,1]\n",
    "ndata = dataset\n",
    "\n",
    "n_pattern = 4\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "wd_ = list_rules[2].wd_\n",
    "rules = list_rules[2].rules \n",
    "complete_rules = list_rules[2].complete_rules \n",
    "print(f'Shape of ensemble rules is {complete_rules.shape}')\n",
    "\n",
    "#initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\n",
    "initial_values = yp_totest\n",
    "\n",
    "\n",
    "defuzz = Defuzzification(mf_params_,num_series)\n",
    "\n",
    "h_prev = 24\n",
    "\n",
    "yp_totest = initial_values\n",
    "yt_totest = np.zeros((h_prev,num_series))\n",
    "\n",
    "\n",
    "for h_p in range(h_prev):\n",
    "    print('='*89)\n",
    "    #Select which ruleset use now.\n",
    "\n",
    "    rem = h_p % 168\n",
    "\n",
    "    k = rem // 24\n",
    "\n",
    "    print(f'Debug only, rem = {rem} and k = {k}')\n",
    "    print('='*89)\n",
    "    ensemble_antecedents = rules\n",
    "    ensemble_rules = complete_rules\n",
    "\n",
    "    #If weight matrix is not given, just fill with ones.\n",
    "\n",
    "    print(f'Shape of ensemble rules is {ensemble_rules.shape}')\n",
    "\n",
    "    mX_values_in = np.zeros((1,mf_params_.shape[0],yp_totest.shape[1]))\n",
    "    antecedents_activated = []\n",
    "    it = 0\n",
    "    for i in range(num_series):\n",
    "        mf_params = mf_params_[:,i]\n",
    "        for j in range(lag):\n",
    "\n",
    "            mX, _ = Fuzzyfy.fuzzify(np.array([yp_totest[0,i*lag+j]]),mf_params,num_groups=num_groups)\n",
    "            mX_values_in[:,:,i*lag+j] = mX\n",
    "\n",
    "\n",
    "            idx_nonzero = np.where(mX[0,:] > 0)\n",
    "            idx_nonzero = idx_nonzero[0]\n",
    "\n",
    "            if not_used_lag:\n",
    "                for k in range(idx_nonzero.shape[0]):\n",
    "                    if j in lags_used[i]:\n",
    "                        antecedents_activated.append((it,idx_nonzero[k]))\n",
    "                    else:\n",
    "                        pass\n",
    "                it += 1\n",
    "            \n",
    "            else:\n",
    "                for k in range(idx_nonzero.shape[0]):\n",
    "                    antecedents_activated.append((i*lag+j,idx_nonzero[k]))\n",
    "\n",
    "    '''\n",
    "    if not_used_lag:\n",
    "        mX_values_in, _ = remove_lags(mX_values_in,lag_notused,num_series,lag)\n",
    "\n",
    "\n",
    "    prem_terms_test = np.zeros((ensemble_antecedents.shape[0],1))\n",
    "    '''\n",
    "    rules_idx = []\n",
    "    check_idx = 0\n",
    "    \n",
    "    #Checking for every rule in dataset if it's activated\n",
    "    #TODO - Check if we can modify this into enumerate, avoiding check_idx += 1 every time.\n",
    "    for n_rule in ensemble_antecedents:\n",
    "        #print('Rule {} is {}'.format(check_idx,test(n_rule,antecedents_activated)))\n",
    "        if test(n_rule,antecedents_activated):\n",
    "            rules_idx.append(check_idx)\n",
    "        check_idx += 1\n",
    "        \n",
    "    prem_activated = np.zeros((ensemble_antecedents.shape[0],))\n",
    "    for i in rules_idx:\n",
    "        prem_activated[i,] = prem_term(ensemble_antecedents[i,0],mX_values_in)\n",
    "    \n",
    "    agg_test = np.zeros((wd_.shape))\n",
    "    for i in range(num_series):\n",
    "        for j in rules_idx:\n",
    "            rule = ensemble_rules[j,i]\n",
    "            consequent = rule[-1]\n",
    "            agg_test[j,consequent[1],i] = prem_activated[j,]\n",
    "            \n",
    "            \n",
    "    weight_agg = np.multiply(agg_test,wd_)\n",
    "    weight_ = np.zeros((weight_agg.shape[1],weight_agg.shape[2]))\n",
    "\n",
    "    for i in range(weight_.shape[1]):\n",
    "        weight_[:,i] = weight_agg[:,:,i].max(axis=0)\n",
    "\n",
    "    w_todefuzz = np.reshape(weight_,(1,weight_.shape[0],weight_.shape[1]))\n",
    "    \n",
    "    #Defuzzification in fact\n",
    "    y_pred = defuzz.run(defuzz_method,w_todefuzz,show=False)\n",
    "    \n",
    "    #Store predicted value into yt_totest.\n",
    "    yt_totest[h_p,:] = y_pred\n",
    "    \n",
    "    #Last step, we use the predicted output to compose input data.\n",
    "    y_temp = np.zeros(yp_totest.shape)\n",
    "    assert y_temp.shape == yp_totest.shape\n",
    "    y_temp[0,1:] = yp_totest[0,0:yp_totest.shape[1]-1]\n",
    "    for ii in range(num_series):\n",
    "        #print(yp_totest[0,ii*lag])\n",
    "        #print(y_pred[0][ii])\n",
    "        #yp_totest[0,ii*lag] = y_pred[0][ii]\n",
    "        y_temp[0,ii*lag] = y_pred[0][ii]\n",
    "        #print(yp_totest[0,yp_totest.shape[1]-1])\n",
    "    yp_totest = y_temp\n",
    "\n",
    "k = 1\n",
    "for i in range(num_series):\n",
    "    plt.subplot(fig_axis[0],fig_axis[1],k)\n",
    "    plt.title('Serie {}'.format(ndata.columns[i]),fontsize=30)\n",
    "    plt.plot(yt_totest[:,i],color='blue')\n",
    "    plt.plot(out_sample[:,i],color='red')\n",
    "    plt.legend(['Predicted','Target'])\n",
    "    plt.xlabel('Time(h)',fontsize=15)\n",
    "    plt.ylabel('Value',fontsize=15)\n",
    "    print(rrse(yt_totest[:,i],out_sample[:,i]))\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best for weekdays = list_rules[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_list.rules','wb') as config_list_rules:\n",
    "    pickle.dump(list_rules, config_list_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_list.rules','wb') as config_list_rules:\n",
    "    pickle.dump(list_rules, config_list_rules)\n",
    "\n",
    "with open('best_list.rules','rb') as read_file:\n",
    "\n",
    "    blah = pickle.load(read_file)\n",
    "    print(blah.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pattern = 6\n",
    "min_error = 300.0\n",
    "\n",
    "print('='*89)\n",
    "print(f'Starting Pattern {n_pattern}')\n",
    "print('='*89)\n",
    "#Select a sample pattern for our problem. In that case, we apply a manual pattern on dataset\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "#Iintial values for prediction\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\n",
    "\n",
    "#Always checking if initial values are correct by asserting it's target\n",
    "assert (all_yt[yp_lagged.shape[0] + t_val[0],:] == out_sample[0,:]).all(), 'Target mismatch. Verify initial values lag.'\n",
    "\n",
    "print(f'Shape of in-sample is {in_sample.shape[0]}')\n",
    "#assert in_sample.shape[0] == h_train//7\n",
    "print(f'Shape of lagged data is {yp_lagged1.shape[0]}')\n",
    "#assert yp_lagged1.shape[0] == h_train//manual_pattern\n",
    "print(f'Shape of validation set is {out_sample.shape[0]}')\n",
    "#assert out_sample.shape[0] == h_val//manual_pattern\n",
    "#data1 = deepcopy(data_[t[len(t)-len(t_lagged):],:])\n",
    "#in_sample = data1[:data1.shape[0]-h_prev,:]\n",
    "#out_sample = data1[data1.shape[0]-h_prev:,:]\n",
    "#ensemble_rules = list_rules[n_pattern].complete_rules \n",
    "#ensemble_prem_terms = list_rules[n_pattern].prem_terms\n",
    "#ensemble_antecedents = list_rules[n_pattern].rules\n",
    "\n",
    "#Concatenate rules\n",
    "for i in range(num_predictors):\n",
    "    not_select_subsample = np.random.choice(total_number,total_number-num_input,replace=False)\n",
    "    try:\n",
    "        \n",
    "        complete_rules, prem_terms, rules, agg_training, wd_ = model.train(data_, yt=yt1,yp=yp1,yp_lagged=yp_lagged1,in_sample=in_sample,out_sample=out_sample,not_select_subsample=not_select_subsample, lag_notused=[])\n",
    "\n",
    "\n",
    "        print(f'Predict on validation set - #{i}')\n",
    "        #Prediction of a single subset\n",
    "        errors = model.predict(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules, filepath=filepath, lim=3.0, fig_axis=[2,2],ndata=dataset)\n",
    "\n",
    "\n",
    "        print('RRSE Errors = {}'.format(errors[1,:]))\n",
    "        if errors[1,0] < min_error:\n",
    "            print('-'*89)\n",
    "            print(f'Best rules found with error = {errors[1,0]}')\n",
    "            print('-'*89)\n",
    "            ensemble_rules = deepcopy(complete_rules)\n",
    "            ensemble_prem_terms = deepcopy(prem_terms)\n",
    "            ensemble_antecedents = deepcopy(rules)\n",
    "            wd__ = deepcopy(wd_)\n",
    "            min_error = errors[1,0]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = ensemble_rules\n",
    "bb = ensemble_prem_terms\n",
    "cc = ensemble_antecedents\n",
    "dd = wd__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_prev = h_test\n",
    "wd_given = True\n",
    "fig_axis = [1,1]\n",
    "ndata = dataset\n",
    "\n",
    "n_pattern = 0\n",
    "#t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "#t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "#t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "#yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "#yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "#yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "#in_sample = training_set[t,:]\n",
    "#out_sample = val_set[t_val,:]\n",
    "\n",
    "wd_ = dd\n",
    "rules = cc\n",
    "complete_rules = aa\n",
    "print(f'Shape of ensemble rules is {complete_rules.shape}')\n",
    "\n",
    "#initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\n",
    "\n",
    "\n",
    "\n",
    "defuzz = Defuzzification(mf_params_,num_series)\n",
    "\n",
    "h_prev = 24\n",
    "\n",
    "yp_totest = initial_values\n",
    "yt_totest = np.zeros((h_prev,num_series))\n",
    "\n",
    "\n",
    "for h_p in range(h_prev):\n",
    "    print('='*89)\n",
    "    #Select which ruleset use now.\n",
    "\n",
    "    rem = h_p % 168\n",
    "\n",
    "    k = rem // 24\n",
    "\n",
    "    print(f'Debug only, rem = {rem} and k = {k}')\n",
    "    print('='*89)\n",
    "    ensemble_antecedents = rules\n",
    "    ensemble_rules = complete_rules\n",
    "\n",
    "    #If weight matrix is not given, just fill with ones.\n",
    "\n",
    "    print(f'Shape of ensemble rules is {ensemble_rules.shape}')\n",
    "\n",
    "    mX_values_in = np.zeros((1,mf_params_.shape[0],yp_totest.shape[1]))\n",
    "    antecedents_activated = []\n",
    "    it = 0\n",
    "    for i in range(num_series):\n",
    "        mf_params = mf_params_[:,i]\n",
    "        for j in range(lag):\n",
    "\n",
    "            mX, _ = Fuzzyfy.fuzzify(np.array([yp_totest[0,i*lag+j]]),mf_params,num_groups=num_groups)\n",
    "            mX_values_in[:,:,i*lag+j] = mX\n",
    "\n",
    "\n",
    "            idx_nonzero = np.where(mX[0,:] > 0)\n",
    "            idx_nonzero = idx_nonzero[0]\n",
    "\n",
    "            if not_used_lag:\n",
    "                for k in range(idx_nonzero.shape[0]):\n",
    "                    if j in lags_used[i]:\n",
    "                        antecedents_activated.append((it,idx_nonzero[k]))\n",
    "                    else:\n",
    "                        pass\n",
    "                it += 1\n",
    "            \n",
    "            else:\n",
    "                for k in range(idx_nonzero.shape[0]):\n",
    "                    antecedents_activated.append((i*lag+j,idx_nonzero[k]))\n",
    "\n",
    "    '''\n",
    "    if not_used_lag:\n",
    "        mX_values_in, _ = remove_lags(mX_values_in,lag_notused,num_series,lag)\n",
    "\n",
    "\n",
    "    prem_terms_test = np.zeros((ensemble_antecedents.shape[0],1))\n",
    "    '''\n",
    "    rules_idx = []\n",
    "    check_idx = 0\n",
    "    \n",
    "    #Checking for every rule in dataset if it's activated\n",
    "    #TODO - Check if we can modify this into enumerate, avoiding check_idx += 1 every time.\n",
    "    for n_rule in ensemble_antecedents:\n",
    "        #print('Rule {} is {}'.format(check_idx,test(n_rule,antecedents_activated)))\n",
    "        if test(n_rule,antecedents_activated):\n",
    "            rules_idx.append(check_idx)\n",
    "        check_idx += 1\n",
    "    print(f'{len(rules_idx)} rules activated')    \n",
    "    prem_activated = np.zeros((ensemble_antecedents.shape[0],))\n",
    "    for i in rules_idx:\n",
    "        prem_activated[i,] = prem_term(ensemble_antecedents[i,0],mX_values_in)\n",
    "    \n",
    "    agg_test = np.zeros((wd_.shape))\n",
    "    for i in range(num_series):\n",
    "        for j in rules_idx:\n",
    "            rule = ensemble_rules[j,i]\n",
    "            consequent = rule[-1]\n",
    "            agg_test[j,consequent[1],i] = prem_activated[j,]\n",
    "            \n",
    "            \n",
    "    weight_agg = np.multiply(agg_test,wd_)\n",
    "    weight_ = np.zeros((weight_agg.shape[1],weight_agg.shape[2]))\n",
    "\n",
    "    for i in range(weight_.shape[1]):\n",
    "        weight_[:,i] = weight_agg[:,:,i].max(axis=0)\n",
    "\n",
    "    w_todefuzz = np.reshape(weight_,(1,weight_.shape[0],weight_.shape[1]))\n",
    "    \n",
    "    #Defuzzification in fact\n",
    "    y_pred = defuzz.run(defuzz_method,w_todefuzz,show=True)\n",
    "    \n",
    "    #Store predicted value into yt_totest.\n",
    "    yt_totest[h_p,:] = y_pred\n",
    "    \n",
    "    #Last step, we use the predicted output to compose input data.\n",
    "    y_temp = np.zeros(yp_totest.shape)\n",
    "    assert y_temp.shape == yp_totest.shape\n",
    "    y_temp[0,1:] = yp_totest[0,0:yp_totest.shape[1]-1]\n",
    "    for ii in range(num_series):\n",
    "        #print(yp_totest[0,ii*lag])\n",
    "        #print(y_pred[0][ii])\n",
    "        #yp_totest[0,ii*lag] = y_pred[0][ii]\n",
    "        y_temp[0,ii*lag] = y_pred[0][ii]\n",
    "        #print(yp_totest[0,yp_totest.shape[1]-1])\n",
    "    yp_totest = y_temp\n",
    "\n",
    "k = 1\n",
    "for i in range(num_series):\n",
    "    plt.subplot(fig_axis[0],fig_axis[1],k)\n",
    "    plt.title('Serie {}'.format(ndata.columns[i]),fontsize=30)\n",
    "    plt.plot(yt_totest[:,i],color='blue')\n",
    "    plt.plot(out_sample[:,i],color='red')\n",
    "    plt.legend(['Predicted','Target'])\n",
    "    plt.xlabel('Time(h)',fontsize=15)\n",
    "    plt.ylabel('Value',fontsize=15)\n",
    "    print(rrse(yt_totest[:,i],out_sample[:,i]))\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = model.predict(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'AA_p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules, filepath=filepath, lim=3.0, fig_axis=[1,1],ndata=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(initial_values, lags_used = [], ndata=[''], data=[], in_sample=[], out_sample=[], agg_training=None,h_prev=0,n_attempt=0,wd_=[],ensemble_antecedents=[],ensemble_rules=[],not_used_lag = False, filepath='',lim=0, fig_axis=[3,2]):\n",
    "    '''\n",
    "    Module to time series forecasting. It uses multi-stepping in order to evaluate the model.\n",
    "    INPUTS:\n",
    "    \\n - Fuzzyfy: Object containing informations about Fuzzification.\n",
    "    \\n - lags_used: If not_used_lags is true, masks series that isn't in list.\n",
    "    \\n - num_groups: Number of fuzzy sets.\n",
    "    \\n - ndata: name of data (e.g. column header)\n",
    "    \\n - data: data of the problem\n",
    "    \\n - in_sample: in_sample set of data\n",
    "    \\n - out_sample: out_sample set of data\n",
    "    \\n - lag:\n",
    "    \\n - mf_params: Membership function parameters\n",
    "    \\n - agg_training: Aggregation terms in training set. Used to simplify deffuzification of training set.\n",
    "    \\n - yp_lagged\n",
    "    \\n - h_prev:\n",
    "    #TODO - Continue this list\n",
    "\n",
    "    VARIABLES:\n",
    "    \\n - y_predict_: Training set prediction\n",
    "    \\n - yp_totest: Input pattern to evaluate prediction\n",
    "    \\n - yt_totest: Output data, for each horizon and serie.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    print(f'Shape of ensemble rules is {ensemble_rules.shape}')\n",
    "\n",
    "\n",
    "    defuzz = Defuzzification(model.mf_params_,num_series)\n",
    "    if agg_training is not None:\n",
    "        y_predict_ = defuzz.run(defuzz_method,agg_training)\n",
    "\n",
    "    yp_totest = initial_values\n",
    "    yt_totest = np.zeros((h_prev,num_series))\n",
    "\n",
    "    #Prediction - Multi-step\n",
    "    for h_p in range(h_prev):\n",
    "\n",
    "        #Check activated terms.\n",
    "        mX_values_in = np.zeros((1,model.mf_params_.shape[0],yp_totest.shape[1]))\n",
    "\n",
    "        antecedents_activated = []\n",
    "        it = 0\n",
    "        for i in range(num_series):\n",
    "            mf_params = model.mf_params_[:,i]\n",
    "            for j in range(lag):\n",
    "\n",
    "                mX, _ = Fuzzyfy.fuzzify(np.array([yp_totest[0,i*lag+j]]),model.mf_params,num_groups=num_groups)\n",
    "                mX_values_in[:,:,i*lag+j] = mX\n",
    "\n",
    "\n",
    "                idx_nonzero = np.where(mX[0,:] > 0)\n",
    "                idx_nonzero = idx_nonzero[0]\n",
    "\n",
    "                if not_used_lag:\n",
    "                    for k in range(idx_nonzero.shape[0]):\n",
    "                        if j in lags_used[i]:\n",
    "                            antecedents_activated.append((it,idx_nonzero[k]))\n",
    "                        else:\n",
    "                            pass\n",
    "                    it += 1\n",
    "                \n",
    "                else:\n",
    "                    for k in range(idx_nonzero.shape[0]):\n",
    "                        antecedents_activated.append((i*lag+j,idx_nonzero[k]))\n",
    "\n",
    "        '''\n",
    "        if not_used_lag:\n",
    "            mX_values_in, _ = remove_lags(mX_values_in,lag_notused,num_series,lag)\n",
    "\n",
    "\n",
    "        prem_terms_test = np.zeros((ensemble_antecedents.shape[0],1))\n",
    "        '''\n",
    "        rules_idx = []\n",
    "        check_idx = 0\n",
    "        #Checking for every rule in dataset if it's activated\n",
    "        #TODO - Check if we can modify this into enumerate, avoiding check_idx += 1 every time.\n",
    "        for n_rule in ensemble_antecedents:\n",
    "            #print('Rule {} is {}'.format(check_idx,test(n_rule,antecedents_activated)))\n",
    "            if test(n_rule,antecedents_activated):\n",
    "                rules_idx.append(check_idx)\n",
    "            check_idx += 1\n",
    "            \n",
    "        prem_activated = np.zeros((ensemble_antecedents.shape[0],))\n",
    "        for i in rules_idx:\n",
    "            prem_activated[i,] = prem_term(ensemble_antecedents[i,0],mX_values_in)\n",
    "        \n",
    "        agg_test = np.zeros((wd_.shape))\n",
    "        for i in range(num_series):\n",
    "            for j in rules_idx:\n",
    "                rule = ensemble_rules[j,i]\n",
    "                consequent = rule[-1]\n",
    "                agg_test[j,consequent[1],i] = prem_activated[j,]\n",
    "                \n",
    "\n",
    "        weight_agg = np.multiply(agg_test,wd_)\n",
    "        weight_ = np.zeros((weight_agg.shape[1],weight_agg.shape[2]))\n",
    "        for i in range(weight_.shape[1]):\n",
    "            weight_[:,i] = weight_agg[:,:,i].max(axis=0)\n",
    "\n",
    "        w_todefuzz = np.reshape(weight_,(1,weight_.shape[0],weight_.shape[1]))\n",
    "        \n",
    "        #Defuzzification in fact\n",
    "        y_pred = defuzz.run(defuzz_method,w_todefuzz,show=False)\n",
    "        \n",
    "        #Store predicted value into yt_totest.\n",
    "        yt_totest[h_p,:] = y_pred\n",
    "        \n",
    "        #Last step, we use the predicted output to compose input data.\n",
    "        y_temp = np.zeros(yp_totest.shape)\n",
    "        assert y_temp.shape == yp_totest.shape\n",
    "        y_temp[0,1:] = yp_totest[0,0:yp_totest.shape[1]-1]\n",
    "        for ii in range(num_series):\n",
    "            #print(yp_totest[0,ii*lag])\n",
    "            #print(y_pred[0][ii])\n",
    "            #yp_totest[0,ii*lag] = y_pred[0][ii]\n",
    "            y_temp[0,ii*lag] = y_pred[0][ii]\n",
    "            #print(yp_totest[0,yp_totest.shape[1]-1])\n",
    "        yp_totest = y_temp\n",
    "\n",
    "    k = 1\n",
    "    for i in range(num_series):\n",
    "        plt.subplot(fig_axis[0],fig_axis[1],k)\n",
    "        plt.title('Serie {}'.format(ndata.columns[i]),fontsize=30)\n",
    "        plt.plot(yt_totest[:,i],color='blue')\n",
    "        plt.plot(out_sample[:,i],color='red')\n",
    "        plt.legend(['Predicted','Target'])\n",
    "        plt.xlabel('Time(h)',fontsize=15)\n",
    "        plt.ylabel('Value',fontsize=15)\n",
    "        print(rrse(yt_totest[:,i],out_sample[:,i]))\n",
    "        k += 1\n",
    "\n",
    "    return yp_totest, yt_totest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aslib = initial_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_values, new_results = pp(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'AA_p_{n_pattern}_subsample_{i}',wd_=wd__,ensemble_antecedents=ensemble_antecedents,ensemble_rules=ensemble_rules, filepath=filepath, lim=3.0, fig_axis=[1,1],ndata=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pattern = 0\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "#Iintial values for prediction\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_ = list_rules[3].wd_\n",
    "rules = list_rules[3].rules \n",
    "complete_rules = list_rules[3].complete_rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_values_, new_results_ = pp(new_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'AA_p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules, filepath=filepath, lim=3.0, fig_axis=[1,1],ndata=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pattern = 2\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_prev = h_test\n",
    "wd_given = True\n",
    "fig_axis = [1,1]\n",
    "ndata = dataset\n",
    "\n",
    "n_pattern = 3\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "wd_ = list_rules[2].wd_\n",
    "rules = list_rules[2].rules\n",
    "complete_rules = list_rules[2].complete_rules\n",
    "print(f'Shape of ensemble rules is {complete_rules.shape}')\n",
    "\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\n",
    "\n",
    "\n",
    "\n",
    "defuzz = Defuzzification(model.mf_params_,num_series)\n",
    "\n",
    "h_prev = 24\n",
    "\n",
    "yp_totest = initial_values\n",
    "yt_totest = np.zeros((h_prev,num_series))\n",
    "\n",
    "\n",
    "for h_p in range(h_prev):\n",
    "    #print('='*89)\n",
    "    #Select which ruleset use now.\n",
    "\n",
    "    rem = h_p % 168\n",
    "\n",
    "    k = rem // 24\n",
    "\n",
    "    #print(f'Debug only, rem = {rem} and k = {k}')\n",
    "    #print('='*89)\n",
    "    ensemble_antecedents = rules\n",
    "    ensemble_rules = complete_rules\n",
    "\n",
    "    #If weight matrix is not given, just fill with ones.\n",
    "\n",
    "    #print(f'Shape of ensemble rules is {ensemble_rules.shape}')\n",
    "\n",
    "    mX_values_in = np.zeros((1,mf_params_.shape[0],yp_totest.shape[1]))\n",
    "    antecedents_activated = []\n",
    "    it = 0\n",
    "    for i in range(num_series):\n",
    "        mf_params = model.mf_params_[:,i]\n",
    "        for j in range(lag):\n",
    "\n",
    "            mX, _ = Fuzzyfy.fuzzify(np.array([yp_totest[0,i*lag+j]]),mf_params,num_groups=num_groups)\n",
    "            mX_values_in[:,:,i*lag+j] = mX\n",
    "\n",
    "\n",
    "            idx_nonzero = np.where(mX[0,:] > 0)\n",
    "            idx_nonzero = idx_nonzero[0]\n",
    "\n",
    "            if not_used_lag:\n",
    "                for k in range(idx_nonzero.shape[0]):\n",
    "                    if j in lags_used[i]:\n",
    "                        antecedents_activated.append((it,idx_nonzero[k]))\n",
    "                    else:\n",
    "                        pass\n",
    "                it += 1\n",
    "            \n",
    "            else:\n",
    "                for k in range(idx_nonzero.shape[0]):\n",
    "                    antecedents_activated.append((i*lag+j,idx_nonzero[k]))\n",
    "\n",
    "    '''\n",
    "    if not_used_lag:\n",
    "        mX_values_in, _ = remove_lags(mX_values_in,lag_notused,num_series,lag)\n",
    "\n",
    "\n",
    "    prem_terms_test = np.zeros((ensemble_antecedents.shape[0],1))\n",
    "    '''\n",
    "    rules_idx = []\n",
    "    check_idx = 0\n",
    "    \n",
    "    #Checking for every rule in dataset if it's activated\n",
    "    #TODO - Check if we can modify this into enumerate, avoiding check_idx += 1 every time.\n",
    "    for n_rule in ensemble_antecedents:\n",
    "        #print('Rule {} is {}'.format(check_idx,test(n_rule,antecedents_activated)))\n",
    "        if test(n_rule,antecedents_activated):\n",
    "            rules_idx.append(check_idx)\n",
    "        check_idx += 1\n",
    "    #print(f'{len(rules_idx)} rules activated')    \n",
    "    prem_activated = np.zeros((ensemble_antecedents.shape[0],))\n",
    "    for i in rules_idx:\n",
    "        prem_activated[i,] = prem_term(ensemble_antecedents[i,0],mX_values_in)\n",
    "    \n",
    "    agg_test = np.zeros((wd_.shape))\n",
    "    for i in range(num_series):\n",
    "        for j in rules_idx:\n",
    "            rule = ensemble_rules[j,i]\n",
    "            consequent = rule[-1]\n",
    "            agg_test[j,consequent[1],i] = prem_activated[j,]\n",
    "            \n",
    "            \n",
    "    weight_agg = np.multiply(agg_test,wd_)\n",
    "    weight_ = np.zeros((weight_agg.shape[1],weight_agg.shape[2]))\n",
    "\n",
    "    for i in range(weight_.shape[1]):\n",
    "        weight_[:,i] = weight_agg[:,:,i].max(axis=0)\n",
    "\n",
    "    w_todefuzz = np.reshape(weight_,(1,weight_.shape[0],weight_.shape[1]))\n",
    "    \n",
    "    #Defuzzification in fact\n",
    "    y_pred = defuzz.run(defuzz_method,w_todefuzz,show=False)\n",
    "    \n",
    "    #Store predicted value into yt_totest.\n",
    "    yt_totest[h_p,:] = y_pred\n",
    "    \n",
    "    #Last step, we use the predicted output to compose input data.\n",
    "    y_temp = np.zeros(yp_totest.shape)\n",
    "    assert y_temp.shape == yp_totest.shape\n",
    "    y_temp[0,1:] = yp_totest[0,0:yp_totest.shape[1]-1]\n",
    "    for ii in range(num_series):\n",
    "        #print(yp_totest[0,ii*lag])\n",
    "        #print(y_pred[0][ii])\n",
    "        #yp_totest[0,ii*lag] = y_pred[0][ii]\n",
    "        y_temp[0,ii*lag] = y_pred[0][ii]\n",
    "        #print(yp_totest[0,yp_totest.shape[1]-1])\n",
    "    yp_totest = y_temp\n",
    "\n",
    "k = 1\n",
    "for i in range(num_series):\n",
    "    plt.subplot(fig_axis[0],fig_axis[1],k)\n",
    "    plt.title('Serie {}'.format(ndata.columns[i]),fontsize=30)\n",
    "    plt.plot(yt_totest[:,i],color='blue')\n",
    "    plt.plot(out_sample[:,i],color='red')\n",
    "    plt.legend(['Predicted','Target'])\n",
    "    plt.xlabel('Time(h)',fontsize=15)\n",
    "    plt.ylabel('Value',fontsize=15)\n",
    "    print(rrse(yt_totest[:,i],out_sample[:,i]))\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_ = list_rules[4].wd_\n",
    "rules = list_rules[4].rules\n",
    "complete_rules = list_rules[4].complete_rules\n",
    "\n",
    "new_values_, new_results_ = pp(new_values_, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'AA_p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules, filepath=filepath, lim=3.0, fig_axis=[1,1],ndata=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pattern = 6\n",
    "min_error = 300.0\n",
    "\n",
    "print('='*89)\n",
    "print(f'Starting Pattern {n_pattern}')\n",
    "print('='*89)\n",
    "#Select a sample pattern for our problem. In that case, we apply a manual pattern on dataset\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "#Iintial values for prediction\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\n",
    "\n",
    "#Always checking if initial values are correct by asserting it's target\n",
    "assert (all_yt[yp_lagged.shape[0] + t_val[0],:] == out_sample[0,:]).all(), 'Target mismatch. Verify initial values lag.'\n",
    "\n",
    "print(f'Shape of in-sample is {in_sample.shape[0]}')\n",
    "#assert in_sample.shape[0] == h_train//7\n",
    "print(f'Shape of lagged data is {yp_lagged1.shape[0]}')\n",
    "#assert yp_lagged1.shape[0] == h_train//manual_pattern\n",
    "print(f'Shape of validation set is {out_sample.shape[0]}')\n",
    "#assert out_sample.shape[0] == h_val//manual_pattern\n",
    "#data1 = deepcopy(data_[t[len(t)-len(t_lagged):],:])\n",
    "#in_sample = data1[:data1.shape[0]-h_prev,:]\n",
    "#out_sample = data1[data1.shape[0]-h_prev:,:]\n",
    "#ensemble_rules = list_rules[n_pattern].complete_rules \n",
    "#ensemble_prem_terms = list_rules[n_pattern].prem_terms\n",
    "#ensemble_antecedents = list_rules[n_pattern].rules\n",
    "\n",
    "#Concatenate rules\n",
    "for i in range(num_predictors):\n",
    "    not_select_subsample = np.random.choice(total_number,total_number-num_input,replace=False)\n",
    "    try:\n",
    "        \n",
    "        complete_rules, prem_terms, rules, agg_training, wd_ = model.train(data_, yt=yt1,yp=yp1,yp_lagged=yp_lagged1,in_sample=in_sample,out_sample=out_sample,not_select_subsample=not_select_subsample, lag_notused=[])\n",
    "\n",
    "\n",
    "        print(f'Predict on validation set - #{i}')\n",
    "        #Prediction of a single subset\n",
    "        errors = model.predict(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules, filepath=filepath, lim=3.0, fig_axis=[2,2],ndata=dataset)\n",
    "\n",
    "\n",
    "        print('RRSE Errors = {}'.format(errors[1,:]))\n",
    "        if errors[1,0] < min_error:\n",
    "            print('-'*89)\n",
    "            print(f'Best rules found with error = {errors[1,0]}')\n",
    "            print('-'*89)\n",
    "            weekend_ensemble_rules = deepcopy(complete_rules)\n",
    "            weekend_ensemble_prem_terms = deepcopy(prem_terms)\n",
    "            weekend_ensemble_antecedents = deepcopy(rules)\n",
    "            weekend_wd__ = deepcopy(wd_)\n",
    "            min_error = errors[1,0]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pattern = 2\n",
    "min_error = 300.0\n",
    "\n",
    "print('='*89)\n",
    "print(f'Starting Pattern {n_pattern}')\n",
    "print('='*89)\n",
    "#Select a sample pattern for our problem. In that case, we apply a manual pattern on dataset\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "#Iintial values for prediction\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\n",
    "\n",
    "#Always checking if initial values are correct by asserting it's target\n",
    "assert (all_yt[yp_lagged.shape[0] + t_val[0],:] == out_sample[0,:]).all(), 'Target mismatch. Verify initial values lag.'\n",
    "\n",
    "print(f'Shape of in-sample is {in_sample.shape[0]}')\n",
    "#assert in_sample.shape[0] == h_train//7\n",
    "print(f'Shape of lagged data is {yp_lagged1.shape[0]}')\n",
    "#assert yp_lagged1.shape[0] == h_train//manual_pattern\n",
    "print(f'Shape of validation set is {out_sample.shape[0]}')\n",
    "#assert out_sample.shape[0] == h_val//manual_pattern\n",
    "#data1 = deepcopy(data_[t[len(t)-len(t_lagged):],:])\n",
    "#in_sample = data1[:data1.shape[0]-h_prev,:]\n",
    "#out_sample = data1[data1.shape[0]-h_prev:,:]\n",
    "#ensemble_rules = list_rules[n_pattern].complete_rules \n",
    "#ensemble_prem_terms = list_rules[n_pattern].prem_terms\n",
    "#ensemble_antecedents = list_rules[n_pattern].rules\n",
    "\n",
    "#Concatenate rules\n",
    "for i in range(num_predictors):\n",
    "    not_select_subsample = np.random.choice(total_number,total_number-num_input,replace=False)\n",
    "    try:\n",
    "        \n",
    "        complete_rules, prem_terms, rules, agg_training, wd_ = model.train(data_, yt=yt1,yp=yp1,yp_lagged=yp_lagged1,in_sample=in_sample,out_sample=out_sample,not_select_subsample=not_select_subsample, lag_notused=[])\n",
    "\n",
    "\n",
    "        print(f'Predict on validation set - #{i}')\n",
    "        #Prediction of a single subset\n",
    "        errors = model.predict(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules, filepath=filepath, lim=3.0, fig_axis=[2,2],ndata=dataset)\n",
    "\n",
    "\n",
    "        print('RRSE Errors = {}'.format(errors[1,:]))\n",
    "        if errors[1,0] < min_error:\n",
    "            print('-'*89)\n",
    "            print(f'Best rules found with error = {errors[1,0]}')\n",
    "            print('-'*89)\n",
    "            weekday_ensemble_rules = deepcopy(complete_rules)\n",
    "            weekday_ensemble_prem_terms = deepcopy(prem_terms)\n",
    "            weekday_ensemble_antecedents = deepcopy(rules)\n",
    "            weekday_wd__ = deepcopy(wd_)\n",
    "            min_error = errors[1,0]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bac = new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bac = np.concatenate((bac,new_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pattern = 1\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "#Iintial values for prediction\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_values = all_lagged[yp_lagged.shape[0]-168,:].reshape(1,-1)\n",
    "\n",
    "\n",
    "#out_sample = test_set[:24,0].reshape(-1,1)\n",
    "new_values_, new_results_ = pp(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'AA_p_{n_pattern}_subsample_{i}',wd_=weekend_wd__,ensemble_antecedents=weekend_ensemble_antecedents,ensemble_rules=weekend_ensemble_rules, filepath=filepath, lim=3.0, fig_axis=[1,1],ndata=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list_rules[2].wd_\n",
    "l = list_rules[2].rules\n",
    "p = list_rules[2].complete_rules\n",
    "out_sample = test_set[24:48,:].reshape(-1,1)\n",
    "\n",
    "new_values__, new_results__ = pp(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'AA_p_{n_pattern}_subsample_{i}',wd_=k,ensemble_antecedents=l,ensemble_rules=p, filepath=filepath, lim=3.0, fig_axis=[1,1],ndata=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_ = list_rules[4].wd_\n",
    "rules = list_rules[4].rules\n",
    "complete_rules = list_rules[4].complete_rules\n",
    "\n",
    "new_values_, new_results_ = pp(new_values_, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'AA_p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules, filepath=filepath, lim=3.0, fig_axis=[1,1],ndata=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.mf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pattern = 6\n",
    "min_error = 300.0\n",
    "\n",
    "print('='*89)\n",
    "print(f'Starting Pattern {n_pattern}')\n",
    "print('='*89)\n",
    "#Select a sample pattern for our problem. In that case, we apply a manual pattern on dataset\n",
    "t = [a + n + lag for n in range(0,training_set.shape[0]+1,168) for a in range(24*n_pattern,24*(n_pattern+1)) if a + n + lag < h_train] \n",
    "t_lagged = [v - lag for v in t if (v-lag) > 0 and (v-lag) < yp.shape[0]]\n",
    "\n",
    "t_val = [a + n for n in range(0,val_set.shape[0],168) for a in range(24*n_pattern,24*(n_pattern+1))]\n",
    "\n",
    "\n",
    "yp1 = deepcopy(yp[t_lagged,:])\n",
    "\n",
    "yt1 = deepcopy(yt[t_lagged,:])\n",
    "\n",
    "yp_lagged1 = deepcopy(yp_lagged[t_lagged,:])\n",
    "\n",
    "in_sample = training_set[t,:]\n",
    "out_sample = val_set[t_val,:]\n",
    "\n",
    "#Iintial values for prediction\n",
    "initial_values = all_lagged[yp_lagged.shape[0] + t_val[0],:].reshape(1,-1)\n",
    "\n",
    "#Always checking if initial values are correct by asserting it's target\n",
    "assert (all_yt[yp_lagged.shape[0] + t_val[0],:] == out_sample[0,:]).all(), 'Target mismatch. Verify initial values lag.'\n",
    "\n",
    "print(f'Shape of in-sample is {in_sample.shape[0]}')\n",
    "#assert in_sample.shape[0] == h_train//7\n",
    "print(f'Shape of lagged data is {yp_lagged1.shape[0]}')\n",
    "#assert yp_lagged1.shape[0] == h_train//manual_pattern\n",
    "print(f'Shape of validation set is {out_sample.shape[0]}')\n",
    "#assert out_sample.shape[0] == h_val//manual_pattern\n",
    "#data1 = deepcopy(data_[t[len(t)-len(t_lagged):],:])\n",
    "#in_sample = data1[:data1.shape[0]-h_prev,:]\n",
    "#out_sample = data1[data1.shape[0]-h_prev:,:]\n",
    "#ensemble_rules = list_rules[n_pattern].complete_rules \n",
    "#ensemble_prem_terms = list_rules[n_pattern].prem_terms\n",
    "#ensemble_antecedents = list_rules[n_pattern].rules\n",
    "\n",
    "#Concatenate rules\n",
    "for i in range(num_predictors):\n",
    "    not_select_subsample = np.random.choice(total_number,total_number-num_input,replace=False)\n",
    "    try:\n",
    "        \n",
    "        complete_rules, prem_terms, rules, agg_training, wd_ = model.train(data_, yt=yt1,yp=yp1,yp_lagged=yp_lagged1,in_sample=in_sample,out_sample=out_sample,not_select_subsample=not_select_subsample, lag_notused=[])\n",
    "\n",
    "\n",
    "        print(f'Predict on validation set - #{i}')\n",
    "        #Prediction of a single subset\n",
    "        errors = model.predict(initial_values, data=data_,in_sample=in_sample,out_sample=out_sample, agg_training=agg_training,h_prev=out_sample.shape[0],n_attempt=f'p_{n_pattern}_subsample_{i}',wd_=wd_,ensemble_antecedents=rules,ensemble_rules=complete_rules, filepath=filepath, lim=3.0, fig_axis=[2,2],ndata=dataset)\n",
    "\n",
    "\n",
    "        print('RRSE Errors = {}'.format(errors[1,:]))\n",
    "        if errors[1,0] < min_error:\n",
    "            print('-'*89)\n",
    "            print(f'Best rules found with error = {errors[1,0]}')\n",
    "            print('-'*89)\n",
    "            weekend_ensemble_rules = deepcopy(complete_rules)\n",
    "            weekend_ensemble_prem_terms = deepcopy(prem_terms)\n",
    "            weekend_ensemble_antecedents = deepcopy(rules)\n",
    "            weekend_wd__ = deepcopy(wd_)\n",
    "            min_error = errors[1,0]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_params_.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
